[{"content":"1.LightRAG 数据集 使用MemoRAG提出的Benchmark。\n在UltraDomain里，包含多个领域的数据，每个数据包括多本书。以cs为例，共含有100本书和100个对应的问题。该领域专注于计算机科学，涵盖数据科学和软件工程的关键领域。它特别强调机器学习和大数据处理，内容涉及推荐系统、分类算法以及使用Spark进行实时分析。：\n{ input: How does Spark Streaming enable real-time data processing? answers: [\u0026#39;Spark Streaming extends ...... \u0026#39;] context: \u0026#34;Whole Book......\u0026#34; length: 131651 context_id: 7bcef8714a477fd61fc8fb0d499b2cc3 _id: b2fd8d9c6d1499d521d778ce3d6d06fa label: cs meta: {\u0026#39;title\u0026#39;: \u0026#39;Machine Learning With Spark\u0026#39;, \u0026#39;authors\u0026#39;: \u0026#39;Nick Pentreath\u0026#39;} } 数据集地址：TommyChien/UltraDomain · Datasets at Hugging Face\n问题生成 生成问题的方法来自于From Local to Global: A Graph RAG Approach to Query-Focused Summarization\n提供文本，让大模型生成K个使用该数据集的用户身份（比如数据集是财经新闻，user就可能是收集金融市场趋势的财经记者），对于每个用户再生成N个任务，每个用户-任务提出M个高层次问题（理解整个数据集、无需提取具体事实）\nUser: A tech journalist looking for insights and trends in the tech industry Task: Understanding how tech leaders view the role of policy and regulation Questions: 1. Which episodes deal primarily with tech policy and government regulation? 2. How do guests perceive the impact of privacy laws on technology development? 3. Do any guests discuss the balance between innovation and ethical considerations? 4. What are the suggested changes to current policies mentioned by the guests? 5. Are collaborations between tech companies and governments discussed and how? 评价标准 不使用黄金标准答案，使用LLM评价。包括\n• Comprehensiveness. How much detail does the answer provide to cover all aspects and details of the question?\n• Diversity. How varied and rich is the answer in providing different perspectives and insights on the question?\n• Empowerment. How well does the answer help the reader understand and make informed judgments about the topic?\n","permalink":"https://Rook1eChan.github.io/posts/rag-datasetsevaluation/","summary":"\u003ch3 id=\"1lightrag\"\u003e1.LightRAG\u003c/h3\u003e\n\u003ch4 id=\"数据集\"\u003e数据集\u003c/h4\u003e\n\u003cp\u003e使用\u003ca href=\"https://arxiv.org/abs/2409.05591\"\u003eMemoRAG\u003c/a\u003e提出的Benchmark。\u003c/p\u003e\n\u003cp\u003e在UltraDomain里，包含多个领域的数据，每个数据包括多本书。以cs为例，共含有100本书和100个对应的问题。该领域专注于计算机科学，涵盖数据科学和软件工程的关键领域。它特别强调机器学习和大数据处理，内容涉及推荐系统、分类算法以及使用Spark进行实时分析。：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-gdscript3\" data-lang=\"gdscript3\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\t\u003cspan class=\"n\"\u003einput\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"n\"\u003eHow\u003c/span\u003e \u003cspan class=\"n\"\u003edoes\u003c/span\u003e \u003cspan class=\"n\"\u003eSpark\u003c/span\u003e \u003cspan class=\"n\"\u003eStreaming\u003c/span\u003e \u003cspan class=\"n\"\u003eenable\u003c/span\u003e \u003cspan class=\"n\"\u003ereal\u003c/span\u003e\u003cspan class=\"o\"\u003e-\u003c/span\u003e\u003cspan class=\"n\"\u003etime\u003c/span\u003e \u003cspan class=\"n\"\u003edata\u003c/span\u003e \u003cspan class=\"n\"\u003eprocessing\u003c/span\u003e\u003cspan class=\"err\"\u003e?\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\t\u003cspan class=\"n\"\u003eanswers\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;Spark Streaming extends ...... \u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \t\u003cspan class=\"n\"\u003econtext\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;Whole Book......\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\t\u003cspan class=\"n\"\u003elength\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mi\"\u003e131651\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003econtext_id\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mi\"\u003e7\u003c/span\u003e\u003cspan class=\"n\"\u003ebcef8714a477fd61fc8fb0d499b2cc3\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003e_id\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"n\"\u003eb2fd8d9c6d1499d521d778ce3d6d06fa\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003elabel\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"n\"\u003ecs\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003emeta\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;title\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;Machine Learning With Spark\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;authors\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;Nick Pentreath\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e数据集地址：\u003ca href=\"https://huggingface.co/datasets/TommyChien/UltraDomain\"\u003eTommyChien/UltraDomain · Datasets at Hugging Face\u003c/a\u003e\u003c/p\u003e\n\u003ch4 id=\"问题生成\"\u003e问题生成\u003c/h4\u003e\n\u003cp\u003e生成问题的方法来自于\u003ca href=\"https://arxiv.org/abs/2404.16130\"\u003eFrom Local to Global: A Graph RAG Approach to Query-Focused Summarization\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e提供文本，让大模型生成K个使用该数据集的用户身份（比如数据集是财经新闻，user就可能是收集金融市场趋势的财经记者），对于每个用户再生成N个任务，每个用户-任务提出M个高层次问题（理解整个数据集、无需提取具体事实）\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-fallback\" data-lang=\"fallback\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e User: A tech journalist looking for insights and trends in the tech industry\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e Task: Understanding how tech leaders view the role of policy and regulation\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e Questions:\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e 1. Which episodes deal primarily with tech policy and government regulation?\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e 2. How do guests perceive the impact of privacy laws on technology development?\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e 3. Do any guests discuss the balance between innovation and ethical considerations?\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e 4. What are the suggested changes to current policies mentioned by the guests?\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e 5. Are collaborations between tech companies and governments discussed and how?\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch4 id=\"评价标准\"\u003e评价标准\u003c/h4\u003e\n\u003cp\u003e不使用黄金标准答案，使用LLM评价。包括\u003c/p\u003e","title":"RAG 数据集及评价标准"},{"content":"CDF-RAG: Causal Dynamic Feedback for Adaptive Retrieval-Augmented Generation\n只挂了arxiv，粗看，了解一下各模块的实现方式。\n1.Motivation 现有的RAG框架主要是静态检索，且依赖于语义相似性和关联性，这些方法优先考虑主题相关的文档，而并非提供解释或因果关系的文档。这导致响应结果是基于事实的，但是没能理解因果关系。\n此外，基于大规模观察语料库训练的语言模型倾向于建模共现模式而非因果依赖，这使得它们容易将相关性与因果关系混淆——尤其是在存在不完整或模糊证据的情况下。这些局限性在多跳检索中尤为明显。\n另外，用户的提问可能是模糊的，现有机制缺乏动态适应和因果机制。\n2.Contributions 本文提出了CDFRAG框架，将强化学习查询优化、多跳因果图检索和基于对齐的幻觉检测整合到一个推理循环中。\n证明了基于强化学习的查询重写显著提升了多跳因果推理和检索质量，优于先前的细化方法。\n本方法在四个数据集中均sota，在因果正确性、一致性和可解释性方面均有所改进。\n3.Method 1.构建因果知识图谱 使用UniCausal提取因果对（Causal，Effect）。经过GPT4验证后，编码为（C，E，Relation）并存入有向图G。\n2.根据强化学习进行查询重写 给定用户初始查询q，重写q的过程是一个马尔可夫决策过程（MDP），有三种操作：\n扩展：添加相关的因果因素 简化：去除多余的细节 分解：复杂查询拆解为子查询 策略通过SFT微调生成，然后使用PPO优化。\n监督微调（Supervised Fine-Tuning, SFT） 目的：用标注的示范数据（如人工修正的样本）初始化策略 $$\\pi_\\theta(a|s)$$，使其初步具备期望的行为模式。 方法：通过最大化对数似然来微调模型参数，损失函数为： $$L_{\\text{SFT}} = -\\sum_{t=1}^{T} \\log P_\\phi(y_t \\mid y_{","permalink":"https://Rook1eChan.github.io/posts/cdf-rag-causal-dynamic-feedback-for-adaptive-retrieval-augmented-generation/","summary":"\u003cp\u003e\u003ca href=\"https://arxiv.org/abs/2504.12560\"\u003eCDF-RAG: Causal Dynamic Feedback for Adaptive Retrieval-Augmented Generation\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e只挂了arxiv，粗看，了解一下各模块的实现方式。\u003c/p\u003e\n\u003ch2 id=\"1motivation\"\u003e1.Motivation\u003c/h2\u003e\n\u003cp\u003e现有的RAG框架主要是静态检索，且依赖于语义相似性和关联性，这些方法优先考虑主题相关的文档，而并非提供解释或因果关系的文档。这导致响应结果是基于事实的，但是没能理解因果关系。\u003c/p\u003e\n\u003cp\u003e此外，基于大规模观察语料库训练的语言模型倾向于建模共现模式而非因果依赖，这使得它们容易将相关性与因果关系混淆——尤其是在存在不完整或模糊证据的情况下。这些局限性在多跳检索中尤为明显。\u003c/p\u003e\n\u003cp\u003e另外，用户的提问可能是模糊的，现有机制缺乏动态适应和因果机制。\u003c/p\u003e\n\u003ch2 id=\"2contributions\"\u003e2.Contributions\u003c/h2\u003e\n\u003cp\u003e本文提出了CDFRAG框架，将强化学习查询优化、多跳因果图检索和基于对齐的幻觉检测整合到一个推理循环中。\u003c/p\u003e\n\u003cp\u003e证明了基于强化学习的查询重写显著提升了多跳因果推理和检索质量，优于先前的细化方法。\u003c/p\u003e\n\u003cp\u003e本方法在四个数据集中均sota，在因果正确性、一致性和可解释性方面均有所改进。\u003c/p\u003e\n\u003ch2 id=\"3method\"\u003e3.Method\u003c/h2\u003e\n\u003ch3 id=\"1构建因果知识图谱\"\u003e1.构建因果知识图谱\u003c/h3\u003e\n\u003cp\u003e使用UniCausal提取因果对（Causal，Effect）。经过GPT4验证后，编码为（C，E，Relation）并存入有向图G。\u003c/p\u003e\n\u003ch3 id=\"2根据强化学习进行查询重写\"\u003e2.根据强化学习进行查询重写\u003c/h3\u003e\n\u003cp\u003e给定用户初始查询q，重写q的过程是一个马尔可夫决策过程（MDP），有三种操作：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e扩展：添加相关的因果因素\u003c/li\u003e\n\u003cli\u003e简化：去除多余的细节\u003c/li\u003e\n\u003cli\u003e分解：复杂查询拆解为子查询\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e策略通过SFT微调生成，然后使用PPO优化。\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003e监督微调（Supervised Fine-Tuning, SFT）\u003c/strong\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e目的\u003c/strong\u003e：用标注的示范数据（如人工修正的样本）初始化策略 $$\\pi_\\theta(a|s)$$，使其初步具备期望的行为模式。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e方法\u003c/strong\u003e：通过最大化对数似然来微调模型参数，损失函数为：\n$$L_{\\text{SFT}} = -\\sum_{t=1}^{T} \\log P_\\phi(y_t \\mid y_{\u003ct}, x)$$\n\u003cul\u003e\n\u003cli\u003e$$y_t$$ 是时间步 $$t$$ 的正确动作（或词元）。\u003c/li\u003e\n\u003cli\u003e$$y_{\u003ct}$$ 表示历史信息（之前的动作或上下文）。\u003c/li\u003e\n\u003cli\u003e$$x$$ 是输入状态（如提示或环境状态）。\u003c/li\u003e\n\u003cli\u003e核心是让模型输出的概率分布贴近人工标注的数据。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003col start=\"2\"\u003e\n\u003cli\u003e\u003cstrong\u003e近端策略优化（Proximal Policy Optimization, PPO）\u003c/strong\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e目的\u003c/strong\u003e：在SFT的基础上，通过与环境交互进一步优化策略，平衡探索与利用，同时避免训练不稳定。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e损失函数\u003c/strong\u003e：\n$$L_{\\text{PPO}}(\\theta) = \\mathbb{E}_t \\left[ \\min\\left( \\text{比率项} \\cdot A_t, \\text{截断后的比率项} \\cdot A_t \\right) \\right]$$\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e比率项\u003c/strong\u003e：新策略与旧策略的概率比\u003c/li\u003e\n\u003cli\u003e$$\\frac{\\pi_\\theta(a|s)}{\\pi_{\\theta_{old}}(at|st)}$$，衡量策略变化程度。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e优势函数 $$A_t$$\u003c/strong\u003e：评估动作 $$a$$ 在状态 $$s$$ 下比平均表现好多少（由评论家模型或蒙特卡洛估计）。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e截断机制\u003c/strong\u003e：限制比率项在 $$[1-\\epsilon, 1+\\epsilon]$$ 之间，防止单步更新过大，确保训练稳定。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"3语义因果双路径检索\"\u003e3.语义+因果双路径检索\u003c/h3\u003e\n\u003cp\u003e使用MiniLM对优化后的查询进行编码，在向量数据库进行相似性搜索。（整句话编码的稠密检索）\u003c/p\u003e","title":"CDF-RAG: Causal Dynamic Feedback for Adaptive Retrieval-Augmented Generation"},{"content":"1.Motivation 现有的神经检索（neural retrieval）的方法主要集中在短文本排序，在长篇文章中做检索效果并不好（由于自注意力机制token数量的限制；或者返回的文档过长，不便于用户使用）。另外，作者发现在先进检索器的检索错误中，半数错误与缺少上下文有关。\n比如：在A剧场中演出过的演员有哪些？如果只检索关键字“A剧场”，可能找不到答案，需要结合上下文找到“……在这里演出过……”的内容才是真正答案。\n因此，作者针对上下文强关联的任务建立了一个数据集，使用两类方法（hybrid retrieval with BM25、 contextualized passage representations）进行实验，并详细解释了实验结果。\n2.Related work Document Question Answering（DocQA）：要求模型回答关于输入文档的问题，通常假设文档在提问前就已给出。本文提出的(Document-Awarepassage Retrieval, DAPR)与DocQA类似，区别在于DAPR希望用户提问时不知道目标文档，由模型来寻找目标文档。 Long-document retrieval（长文档检索）：对于长文档检索有一些简单的方法：将文档中段落相关性的最大值作为文档的相关性（MaxP）；仅编码文档中的第一个段落（FirstP）……与DAPR相比，所有这些先前的工作都没有研究如何在考虑文档上下文的情况下检索段落。 Hybrid retrieval（混合检索）：对于一个查询使用多个检索系统（常常是BM25+神经检索） rank fusion（排名融合）——通过凸组合、互逆排名等方法将不同检索系统的个体排名合并为一个。 hierarchical retrieval（层次检索）——首先检索文档，然后从这些文档中检索段落。只适用于段落本身足以对查询做出响应的情况。 本文探讨了段落排名和文档排名结合的有效性。 Relation to pre-training tasks（和预训练任务的关系）：有的研究在预训练中加入上下文。但推理时仍然只关注独立的段落。 补充： NQ：谷歌的一个问答数据集 NDCG：评价检索序列的相关性和位置 共指信息：描述文本中不同表达式指向同一实体或概念的语言现象，如*“玛丽打开了门，她随后拿起包。”* → “她”与“玛丽”共指同一人。 共指消解（Coreference Resolution）：自动识别文本中所有指向同一实体的表达式并分组。 3.Method DAPR任务要求系统提取+排序。给出段落集合$C$，文档集合$D$，对于查询集合$q \\in Q$，检索系统$s$应该提取出最好的$K$个段落集合$R$。\n3.1NQ-Hard 对SOTA的检索器（DRAGON+,SPLADEv2, and ColBERTv2)使用NQ数据集，发现一半的错误来自于不了解上下文。将这些数据命名为NQ-hard，并分为4类：\n共指消解（CR）：关键的共指信息需要通过特定文档上下文来解析； 主要主题（MT）：只有了解文档的背景主题（通常是标题），才能回答查询； 多跳推理（MHR）：连接查询和查询相关段落中的实体的推理路径包括文档上下文中的其他节点； 缩写（AC）：在相关段落（或查询）中出现一个缩写，该缩写对应于查询（或相关段落）中的全称，文档上下文解释了这种映射； 3.2Datasets MS MARCO、Natural Questions、MIRACL、Genomics 和 ConditionalQA（具体处理方式见附录A）\n3.3Evaluation 使用nDCG@10和recall@100做指标。\n将binary/3-scale转换为0-1/0-1-2，然后使用pytrec_eval计算指标。\n考虑到现实世界中的检索系统多用于零样本、跨领域的情景，本文进行了一项测试：在MS MARCO训练集训练，然后在MS MARCO测试集测试，作为域内评估；在其它四个数据集上测试，作为域外评估。\n4.Experiments 4.1基础检索器 BM25（使用PySerini的默认配置） neural retrievers：DRAGON+、SPLADEv2、ColBERTv2（在MS MARCO上训练） 4.2两种将上下文引入神经检索器的方法 4.2.1加入BM25的混合检索 （1）Rank fusion融合检索\n由于神经网络适合于检测512tokens内的段落，而BM25无长度限制，所以使用BM25检索整个文档，而使用神经检索器检索段落。\n相关性分数为：\n$$s_{convex}(q,p,d)=\\alpha\\hat s_{BM25}(q,p) + (1-\\alpha)\\hat s_{nueral}(q,d)$$（公式有误）\n$\\hat s_{BM25},\\hat s_{nueral}$的分数都是归一化的。归一化公式为：\n$$\\hat{s}(q, c) = \\frac{s(q, c) - m_q}{M_q - m_q}$$​\n$s(q, c)$：检索器对查询(q)和候选文本(c)（段落或文档）的原始分数。 $m_q和M_q$：当前查询(q)的Top候选结果中分数的最小值和最大值。 若候选文本(c)在某一检索器的结果中缺失（未进入Top列表），则其分数视为0。 分数计算示例：\n输入数据:\n5篇文章，每篇2个段落： 文章D1：段落P1, P2 文章D2：段落P3, P4 文章D3：段落P5, P6 文章D4：段落P7, P8 文章D5：段落P9, P10 文档级检索结果 (topk=2)： 得分：D1=0.8, D2=0.6（其他文档得分低于这两个） 段落级检索结果 (topk=2)： 得分：P3=0.9, P5=0.7（其他段落得分低于这两个） 段落到文档映射： pid2did = { \u0026#39;P1\u0026#39;:\u0026#39;D1\u0026#39;, \u0026#39;P2\u0026#39;:\u0026#39;D1\u0026#39;, \u0026#39;P3\u0026#39;:\u0026#39;D2\u0026#39;, \u0026#39;P4\u0026#39;:\u0026#39;D2\u0026#39;, \u0026#39;P5\u0026#39;:\u0026#39;D3\u0026#39;, \u0026#39;P6\u0026#39;:\u0026#39;D3\u0026#39;, \u0026#39;P7\u0026#39;:\u0026#39;D4\u0026#39;, \u0026#39;P8\u0026#39;:\u0026#39;D4\u0026#39;, \u0026#39;P9\u0026#39;:\u0026#39;D5\u0026#39;, \u0026#39;P10\u0026#39;:\u0026#39;D5\u0026#39; } 段落权重：假设passage_weight=0.4（文档权重自动为0.6） 计算过程:\n构建得分映射： did2score = {\u0026#39;D1\u0026#39;:0.8, \u0026#39;D2\u0026#39;:0.6} # 文档级top2 pid2score = {\u0026#39;P3\u0026#39;:0.9, \u0026#39;P5\u0026#39;:0.7} # 段落级top2 传播文档得分到段落： doc_pid2score = { \u0026#39;P3\u0026#39;: did2score[\u0026#39;D2\u0026#39;], # P3属于D2 → 0.6 \u0026#39;P5\u0026#39;: did2score[\u0026#39;D3\u0026#39;] # 但D3不在did2score中(文档级只返回了D1,D2) } 实际结果只有{'P3':0.6}，因为D3不在文档级top2中\nM2C2融合（假设是线性加权）： 对P3： 文档得分：0.6 段落得分：0.9 融合得分 = 0.6*0.6 + 0.9*0.4 = 0.36 + 0.36 = 0.72 对P5： 文档得分：无 → 可能视为0或忽略 段落得分：0.7 如果忽略文档部分：0.7*0.4 = 0.28 最终融合结果： fused = {\u0026#39;P3\u0026#39;:0.72, \u0026#39;P5\u0026#39;:0.28} （2）Hierarchical retrieval层次检索\n第一步先BM25检索文档，第二步神经检索搜索段落，并在第二步应用带有分数归一化的排名融合。\n4.2.2上下文化的段落表示 （1）**Prepending titles：**将文章标题放在每个段落的开头，并用特殊标记分割。可能会出现文档无标题或标题无意义。\n（2）**Prepending document keyphrases：**使用TopicRank算法（不知道在RAG中，和大模型抽取关键词相比如何）提取出文档的十个关键词，放在每个段落之前。\n（3）**Coreference resolution（共指消解）：**使用SpanBERT-large model，采用c2f-coref方法，在OntoNotes上微调。然后用模型对文档生成代词-先行词映射。将代词与文档中最早出现的先行词关联。将先行词放入括号，附在对应的代词后面。比如 “曾在该场地（xx剧场）”\n5.result 5.1混合检索\nrank fusion略好于hierarchical，但都不能解决NQ-Hard问题。说明这两种方法都只能提高自包含问题的表现。\n统计了检索性能随融合权重变化的曲线。发现NQ上的最佳融合权重不能直接转移到NQ-hard上。\n5.2上下文化段落表示\n添加标题和关键词都相当于添加摘要，提升效果相当；共指消解表现最差。\n在NQ-Hard问题（需要连接上下文的问题）的表现显著优于混合检索。\n6.Disscution 1.为什么混合检索在Hard问题上表现不佳\n通过MaxP方法将查询-段落的指标转为查询-文档的指标，作者发现rank fusion和hierarchical检索出的文档大都正确，说明它能找到相关文档，但段落排序表现非常差，说明这两种方法不能够有效的对段落进行排序。\n另外，作者提到fusion weight 在 NQ-Hard和普通问题中的变化趋势不同。所以使用混合检索不能同时在两类问题上达到最佳表现。\n2.为什么在Genomics上上下文表示结果变差\n计算了加/不加标题的文档与query的Jaccard相似度，只有Genomics加标题后值减小。说明添加标题引入了更多不相关的内容，帮倒忙。\nJaccard 相似度公式：$\\text{Jaccard}(A, B) = \\frac{|A \\cap B|}{|A \\cup B|}$\n$A $ 和$B $：两个文本的词集合（或更广义的集合）。 $|A \\cap B|$: A 和 B 中**共同词（交集）**的数量。 $|A \\cup B| $: A 和 B 中**所有唯一词（并集）**的数量。 取值范围 $[0, 1]$（0 表示无重叠，1 表示完全一致）。\n优点：\n简单直观，适用于短文本或集合型数据 不依赖词序或语义（仅统计词重叠） 缺点：\n忽略语义：同义词（如“电脑”和“计算机”）会被视为不同词。 敏感于词频：未考虑词的重要性（如TF-IDF），可以给词添加权重作为改进。 长文本效果差：并集会急剧增大，导致相似度被低估。 3.错误分析\n在两种融合检索、三种上下文化的方法下，多跳推理MHR最难解决，缩写最易解决。使用共指消解不如直接添加标题，因为标题往往含有核心词，而共指消解多次在段落中插入内容，反而干扰了匹配。\n该文章中了ACL2024。在连接上下文方面使用的方法比较淳朴。主要是定义了NQ-Hard数据集，并在5个数据集、原始方法+2个混合检索+3个上下文检索上做了一系列实验，并很好的解释了现象。\n复现 把README里的loaddata和evaluation的代码复制到dapr根目录load.py和eval.py下\npip install -r requirements.txt\n有setup.py，在根目录下python setup.py build python setup.py install 解决module\u0026rsquo;dapr\u0026rsquo; not found\nsudo apt-get update\nConditionalQA数据集 ConditionalQA给定提问者特定情况下的情景，回答与英国政策相关的问题。每个问答实例都标注了来自英国政府政策网页的证据。我们将原始数据集中的所有此类网页作为语料库。每个网页最初被解析为HTML标签，我们将其视为段落，移除HTML标签，仅保留纯自然语言。对于每个问答实例，我们将情景和问题连接起来形成一个查询，并将相应的证据视为黄金相关段落。\n预处理后的train\n{ \u0026#34;query\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;train-0\u0026#34;, //train条目编号 \u0026#34;text\u0026#34;: \u0026#34;My father, who was a widower and the owner of several large properties in Wales, died recently and apparently intestate. My paternal uncle is applying for probate, but I believe that I have a stronger claim. Do I have a greater right to probate in respect of my late father\u0026#39;s estate?\u0026#34; }, \u0026#34;judged_chunks\u0026#34;: [ //判断点，一个问题可能有多个黄金段落 { \u0026#34;chunk\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;74-24\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;\u0026lt;p\u0026gt;You can apply to become the estate’s administrator if you are 18 or over and you are the most ‘entitled’ inheritor of the deceased’s estate. This is usually the deceased’s closest living relative.\u0026lt;/p\u0026gt;\u0026#34; }, \u0026#34;judgement\u0026#34;: 1, //都为1 \u0026#34;belonging_doc\u0026#34;: { //每个chunk都把\u0026#34;belonging_doc\u0026#34;详细写了一遍，导致文件很大 \u0026#34;id\u0026#34;: \u0026#34;74\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;Applying for probate\u0026#34;, \u0026#34;chunks\u0026#34;: [ { \u0026#34;id\u0026#34;: \u0026#34;74-0\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;Overview\u0026#34; }, ... { \u0026#34;id\u0026#34;: \u0026#34;74-138\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;Once you have probate you can start dealing with the estate.\u0026#34; } ], \u0026#34;candidate_chunk_ids\u0026#34;: [ \u0026#34;74-5\u0026#34;, ... \u0026#34;74-51\u0026#34; ] } } ... ] } 预处理后的test\n{ \u0026#34;query\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;dev-0\u0026#34;, //问题编号 \u0026#34;text\u0026#34;: \u0026#34;My brother and his wife are in prison for carrying out a large fraud scheme. Their 7 and 8 year old children have been living with me for the last 4 years. I want to become their Special Guardian to look after them permanently How long will it be before I hear back from the court?\u0026#34; }, //具体问题 \u0026#34;judged_chunks\u0026#34;: [ { \u0026#34;chunk\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;86-41\u0026#34;, //黄金匹配段落 \u0026#34;text\u0026#34;: \u0026#34;\u0026lt;p\u0026gt;Within 10 days of receiving your application the court will send you a case number and a date for a meeting to set out:\u0026lt;/p\u0026gt;\u0026#34; }, \u0026#34;judgement\u0026#34;: 1, //不知道什么意思，取值应该全部为1 \u0026#34;belonging_doc\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;86\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;Become a special guardian\u0026#34;, \u0026#34;chunks\u0026#34;: [ //chunks是该问题相关的法条界面的文本分割后的结果。一段话设置为一个chunk { \u0026#34;id\u0026#34;: \u0026#34;86-0\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;What is a special guardian\u0026#34; }, { \u0026#34;id\u0026#34;: \u0026#34;86-1\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;You can apply to be a child’s special guardian when they cannot live with their birth parents and adoption is not right for them.\u0026#34; }, ... { \u0026#34;id\u0026#34;: \u0026#34;86-62\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;You might be able to get a special guardian allowance from the children’s services department of your local council.\u0026#34; } ], \u0026#34;candidate_chunk_ids\u0026#34;: [ //把chunkid重新排了一遍，不知道按照什么要求排的 \u0026#34;86-6\u0026#34;, \u0026#34;86-52\u0026#34;, ... \u0026#34;86-57\u0026#34;, \u0026#34;86-14\u0026#34;, \u0026#34;86-2\u0026#34;, \u0026#34;86-16\u0026#34; ] } } ] } ","permalink":"https://Rook1eChan.github.io/posts/dapr-a-benchmark-on-document-aware-passage-retrieval/","summary":"\u003ch2 id=\"1motivation\"\u003e1.Motivation\u003c/h2\u003e\n\u003cp\u003e现有的神经检索（neural retrieval）的方法主要集中在短文本排序，在长篇文章中做检索效果并不好（由于自注意力机制token数量的限制；或者返回的文档过长，不便于用户使用）。另外，作者发现在先进检索器的检索错误中，半数错误与缺少上下文有关。\u003c/p\u003e\n\u003cp\u003e比如：在A剧场中演出过的演员有哪些？如果只检索关键字“A剧场”，可能找不到答案，需要结合上下文找到“……在这里演出过……”的内容才是真正答案。\u003c/p\u003e\n\u003cp\u003e因此，作者针对上下文强关联的任务建立了一个数据集，使用两类方法（hybrid retrieval with BM25、 contextualized passage representations）进行实验，并详细解释了实验结果。\u003c/p\u003e\n\u003cBR\u003e\n\u003ch2 id=\"2related-work\"\u003e2.Related work\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eDocument Question Answering（DocQA）\u003c/strong\u003e：要求模型回答关于输入文档的问题，通常假设文档在提问前就已给出。本文提出的(Document-Awarepassage Retrieval, DAPR)与DocQA类似，区别在于DAPR希望用户提问时不知道目标文档，由模型来寻找目标文档。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eLong-document retrieval（长文档检索）\u003c/strong\u003e：对于长文档检索有一些简单的方法：将文档中段落相关性的最大值作为文档的相关性（MaxP）；仅编码文档中的第一个段落（FirstP）……与DAPR相比，所有这些先前的工作都没有研究如何在考虑文档上下文的情况下检索段落。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eHybrid retrieval（混合检索）\u003c/strong\u003e：对于一个查询使用多个检索系统（常常是BM25+神经检索）\n\u003cul\u003e\n\u003cli\u003erank fusion（排名融合）——通过凸组合、互逆排名等方法将不同检索系统的个体排名合并为一个。\u003c/li\u003e\n\u003cli\u003ehierarchical retrieval（层次检索）——首先检索文档，然后从这些文档中检索段落。只适用于段落本身足以对查询做出响应的情况。\u003c/li\u003e\n\u003cli\u003e本文探讨了段落排名和文档排名结合的有效性。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eRelation to pre-training tasks（和预训练任务的关系）\u003c/strong\u003e：有的研究在预训练中加入上下文。但推理时仍然只关注独立的段落。\u003c/li\u003e\n\u003cli\u003e补充：\n\u003cul\u003e\n\u003cli\u003eNQ：谷歌的一个问答数据集\u003c/li\u003e\n\u003cli\u003eNDCG：评价检索序列的相关性和位置\u003c/li\u003e\n\u003cli\u003e共指信息：描述文本中不同表达式指向同一实体或概念的语言现象，如*“玛丽打开了门，\u003cstrong\u003e她\u003c/strong\u003e随后拿起包。”* → “她”与“玛丽”共指同一人。\u003c/li\u003e\n\u003cli\u003e共指消解（Coreference Resolution）：自动识别文本中所有指向同一实体的表达式并分组。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cBR\u003e\n\u003ch2 id=\"3method\"\u003e3.Method\u003c/h2\u003e\n\u003cp\u003eDAPR任务要求系统提取+排序。给出段落集合$C$，文档集合$D$，对于查询集合$q \\in Q$，检索系统$s$应该提取出最好的$K$个段落集合$R$。\u003c/p\u003e\n\u003ch3 id=\"31nq-hard\"\u003e3.1NQ-Hard\u003c/h3\u003e\n\u003cp\u003e对SOTA的检索器（DRAGON+,SPLADEv2, and ColBERTv2)使用NQ数据集，发现一半的错误来自于不了解上下文。将这些数据命名为\u003cstrong\u003eNQ-hard\u003c/strong\u003e，并分为4类：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e共指消解（CR）：关键的共指信息需要通过特定文档上下文来解析；\u003c/li\u003e\n\u003cli\u003e主要主题（MT）：只有了解文档的背景主题（通常是标题），才能回答查询；\u003c/li\u003e\n\u003cli\u003e多跳推理（MHR）：连接查询和查询相关段落中的实体的推理路径包括文档上下文中的其他节点；\u003c/li\u003e\n\u003cli\u003e缩写（AC）：在相关段落（或查询）中出现一个缩写，该缩写对应于查询（或相关段落）中的全称，文档上下文解释了这种映射；\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cimg alt=\"nqques\" loading=\"lazy\" src=\"/DAPR/NQques.png\"\u003e\u003c/p\u003e\n\u003cBR\u003e\n\u003ch3 id=\"32datasets\"\u003e3.2Datasets\u003c/h3\u003e\n\u003cp\u003eMS MARCO、Natural Questions、MIRACL、Genomics 和 ConditionalQA（具体处理方式见附录A）\u003c/p\u003e\n\u003cBR\u003e\n\u003ch3 id=\"33evaluation\"\u003e3.3Evaluation\u003c/h3\u003e\n\u003cp\u003e使用\u003cstrong\u003enDCG@10\u003c/strong\u003e和recall@100做指标。\u003c/p\u003e\n\u003cp\u003e将binary/3-scale转换为0-1/0-1-2，然后使用pytrec_eval计算指标。\u003c/p\u003e\n\u003cp\u003e考虑到现实世界中的检索系统多用于零样本、跨领域的情景，本文进行了一项测试：在MS MARCO训练集训练，然后在MS MARCO测试集测试，作为域内评估；在其它四个数据集上测试，作为域外评估。\u003c/p\u003e\n\u003cBR\u003e\n\u003ch2 id=\"4experiments\"\u003e4.Experiments\u003c/h2\u003e\n\u003ch3 id=\"41基础检索器\"\u003e4.1基础检索器\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eBM25（使用PySerini的默认配置）\u003c/li\u003e\n\u003cli\u003eneural retrievers：DRAGON+、SPLADEv2、ColBERTv2（在MS MARCO上训练）\u003c/li\u003e\n\u003c/ul\u003e\n\u003cBR\u003e\n\u003ch3 id=\"42两种将上下文引入神经检索器的方法\"\u003e4.2两种将上下文引入神经检索器的方法\u003c/h3\u003e\n\u003ch4 id=\"421加入bm25的混合检索\"\u003e4.2.1加入BM25的混合检索\u003c/h4\u003e\n\u003cp\u003e\u003cstrong\u003e（1）Rank fusion融合检索\u003c/strong\u003e\u003c/p\u003e","title":"DAPR A Benchmark on Document-Aware Passage Retrieval"},{"content":"github提供给每个用户一个网址，用户可以建立自己的静态网站。\n一、Hugo hugo是一个快速搭建网站的工具，由go语言编写。\n1.安装hugo 到hugo的github标签页Tags · gohugoio/hugo选择一个版本，下载对应的安装包。比如hugo_extended_withdeploy_0.147.0_windows-amd64.zip。\n解压后，在根目录打开cmd，输入\nhugo new site YourSiteName 为你的网站建立文件夹。YourSiteName更改为你的网站的名字。 根目录会出现YourSiteName文件夹。\n3.将根目录的hugo.exe复制到YourSiteName里。 在YourSiteName文件夹里打开cmd，输入\nhugo server -D 会返回如下信息：\n| EN -------------------+----- Pages | 11 Paginator pages | 0 Non-page files | 0 Static files | 0 Processed images | 0 Aliases | 2 Cleaned | 0 Built in 79 ms Environment: \u0026#34;development\u0026#34; Serving pages from disk Running in Fast Render Mode. For full rebuilds on change: hugo server --disableFastRender Web Server is available at http://localhost:1313/ (bind address 127.0.0.1) Press Ctrl+C to stop 在浏览器中输入http://localhost:1313/，显示Page Not Found，说明服务器正常运行，但是此时网站还没有页面。\n2.选择网站主题 在Hugo Themes选择你想要的theme，然后根据theme的安装说明操作就行了。 在此以PaperMod为例。官方安装教程界面：Installation · adityatelange/hugo-PaperMod Wiki\n安装PaperMod，可以：\n在你的网站的theme文件夹使用：\ngit clone https://github.com/adityatelange/hugo-PaperMod themes/PaperMod --depth=1 或者，在Tags · adityatelange/hugo-PaperMod选择版本，下载zip并解压到theme文件夹。\n在你的网站的根文件夹里的hugo.yml文件里添加\ntheme: [\u0026#34;PaperMod\u0026#34;] 3.新建一个笔记 在你的网站的根页面下使用cmd：\nhugo new posts/first.md YourSiteName/content/posts/first.md 就会建立，打开后，内容为：\n--- date: \u0026#39;2025-05-01T18:41:05+08:00\u0026#39; draft: true title: \u0026#39;first\u0026#39; --- 这三条短线围起来的是该笔记的属性。第一行是创建时间；第二行为false时表示草稿状态，改为true才会显示在网站中；第三行为该笔记的标题。之后还可以添加其他的属性。\n打开http://localhost:1313/，刷新后就能看到刚才创建的笔记了。如果没有就重新hugo server -D。\n你可以通过cmd，或者直接新建md文件来添加笔记。\n4.定制个人博客 4.1添加菜单 在hugo.yml文件中添加：\nmenu: main: - identifier: categories name: categories url: /categories/ weight: 10 - identifier: tags name: tags url: /tags/ weight: 20 - identifier: example name: example.org url: https://example.org weight: 30 在网站的右上角就能看到菜单了\n4.2置顶帖子 在笔记的md文件里添加：\n--- ... weight: 1 --- weight为正整数，表示笔记顺序。放到最顶上就设为1。\n4.3hugo.yaml的可选项 hugo.yaml是网站根目录的配置文件\n# 基础配置 baseURL: https://Rook1eChan.github.io # 网站部署的根URL（GitHub Pages地址） languageCode: zh-cn # 网站语言代码（简体中文） title: Chan\u0026#39;s Blog # 网站标题（ theme: [\u0026#34;PaperMod\u0026#34;] # 使用的主题（Hugo PaperMod主题） buildDrafts: false # 构建时是否包含草稿（false表示不构建草稿） # 主题参数配置 params: # 布局控制 ShowBreadCrumbs: true # 显示面包屑导航 ShowReadingTime: false # 隐藏文章阅读时间 ShowShareButtons: false # 隐藏分享按钮 ShowCodeCopyButtons: true # 显示代码复制按钮 # 搜索功能配置（使用Fuse.js） fuseOpts: isCaseSensitive: false # 搜索不区分大小写 shouldSort: true # 对搜索结果排序 location: 0 # 匹配位置权重 distance: 1000 # 匹配距离阈值 threshold: 0.4 # 匹配相似度阈值 minMatchCharLength: 0 # 最小匹配字符长度 keys: [\u0026#34;title\u0026#34;, \u0026#34;permalink\u0026#34;, \u0026#34;summary\u0026#34;, \u0026#34;content\u0026#34;] # 搜索的字段范围 # 首页欢迎信息 homeInfoParams: Title: \u0026#34;你好，欢迎来到我的博客 \\U0001F44B\u0026#34; # 标题 Content: \u0026#34;welcome!\u0026#34; # 内容 # 社交媒体图标 socialIcons: - name: github # GitHub图标 url: \u0026#34;https://github.com/Rook1eChan\u0026#34; # GitHub个人主页 # 其他社交平台（已注释掉） # - name: twitter # url: \u0026#34;twitter.com\u0026#34; # 网站图标配置 assets: favicon: \u0026#34;/apple-touch-icon.png\u0026#34; # favicon路径 # 导航栏图标 label: icon: /apple-touch-icon.png # 导航栏图标路径 iconHeight: 35 # 图标高度（像素） # 输出格式配置 outputs: home: - HTML # 生成HTML页面 - RSS # 生成RSS订阅 - JSON # 生成JSON数据（可能用于搜索） # 内容标记配置 markup: highlight: codeFences: true # 启用代码块高亮 guessSyntax: true # 自动检测代码语言 hl_Lines: \u0026#39;\u0026#39; # 高亮指定行（未设置） lineNos: false # 不显示行号（与下面配置冲突） lineNumbersInTable: true # 用表格布局行号（避免复制时带行号） noClasses: false # 使用CSS类（必须为false） style: github # 代码高亮主题（github、monokai、solarized-dark、dracula） tabWidth: 4 # 代码缩进空格数 goldmark: renderer: unsafe: true # 允许渲染原始HTML/LaTeX math: true # 支持数学公式 # 导航菜单配置 menu: main: # 已注释的分类和标签菜单 # - identifier: categories # name: categories # url: /categories/ # weight: 10 - identifier: search # 搜索菜单项 name: search # 菜单显示名称（英文，与标识不一致） url: /search/ # 搜索页面路径 weight: 25 # 菜单项排序权重 baseURL: 网站的基础URL，这里是 \u0026ldquo;https://Rook1eChan.github.io\u0026rdquo;，必须要写，不然导航出现错误。不要写example.com\nlanguageCode: 网站语言代码，\u0026ldquo;zh-cn\u0026rdquo; 表示简体中文\ntitle: 网站标题\ntheme: 使用的主题\nbuildDrafts: false 表示不设置草稿文章，所有文章都会被展示\n显示相关:\nShowBreadCrumbs: true 显示面包屑导航 ShowReadingTime: false 不显示文章阅读时间 ShowShareButtons: false 不显示分享按钮 ShowCodeCopyButtons: true 显示代码块的复制按钮 搜索功能 (fuseOpts):\n配置了基于 Fuse.js 的搜索功能参数，包括不区分大小写、排序方式等 主页信息 (homeInfoParams):\nTitle：标题 Content：内容 主页社交媒体图标 (socialIcons):\n只启用了 GitHub 链接，指向 \u0026ldquo;https://github.com/Rook1eChan\u0026quot; Twitter 和 Facebook 链接 资源 (assets):\n设置了网站图标 (favicon) 为 \u0026ldquo;/apple-touch-icon.png\u0026rdquo; 标签 (label):\n设置了图标及其高度 指定了主页的输出格式为 HTML、RSS 和 JSON\n主菜单 (main) 中只配置了一个 \u0026ldquo;搜索\u0026rdquo; 项:\n标识符: \u0026ldquo;搜索\u0026rdquo; 名称: \u0026ldquo;search\u0026rdquo; URL: \u0026ldquo;/search/\u0026rdquo; 权重: 25 (用于菜单项排序) 分类和标签菜单项自选\n4.4更改字体 在 Hugo 项目下新建 assets/css/extended/custom.css ，写入\n/* 全局正文字体 - Noto Sans Simplified Chinese */ body, article { font-family: \u0026#34;Noto Sans SC\u0026#34;, sans-serif; } /* 代码块字体 - 保持等宽字体（如 JetBrains Mono 或系统默认） */ pre, code { font-family: \u0026#34;JetBrains Mono\u0026#34;, monospace; font-size: 0.9em; /* 可选：调整代码字体大小 */ } 在 themes/PaperMod/layouts/partials/head.html 中添加 Google Fonts 的链接\n\u0026lt;link href=\u0026#34;https://fonts.googleapis.com/css2?family=Noto+Sans+SC:wght@400;700\u0026amp;family=JetBrains+Mono\u0026amp;display=swap\u0026#34; rel=\u0026#34;stylesheet\u0026#34;\u0026gt; 可以去Browse Fonts - Google Fonts选字体。代码怎么写问AI。\n4.5启用数学公式 以下方法可以使用$...$表示行内公式，$$...$$表示行间公式\n在themes\\PaperMod\\layouts\\partials\\math.html\u0026quot; 里加上：\n{{ if .Page.Params.math }} \u0026lt;script\u0026gt; MathJax = { tex: { inlineMath: [[\u0026#39;$\u0026#39;, \u0026#39;$\u0026#39;], [\u0026#39;\\\\(\u0026#39;, \u0026#39;\\\\)\u0026#39;]], // 行内公式：$...$ 或 \\(...\\) displayMath: [[\u0026#39;$$\u0026#39;, \u0026#39;$$\u0026#39;], [\u0026#39;\\\\[\u0026#39;, \u0026#39;\\\\]\u0026#39;]] // 块级公式：$$...$$ 或 \\[...\\] } }; \u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; {{ end }} 在themes\\PaperMod\\layouts\\_default\\baseof.html\u0026quot; 里加上：\n\u0026lt;head\u0026gt; ... {{ if .Param \u0026#34;math\u0026#34; }} {{ partialCached \u0026#34;math.html\u0026#34; . }} {{ end }} ... \u0026lt;/head\u0026gt; 在hugo.yaml里加上：\n# 内容标记配置 markup: goldmark: renderer: unsafe: true # 允许原始 HTML（某些数学公式需要） extensions: passthrough: enable: true delimiters: block: - [\u0026#39;$$\u0026#39;, \u0026#39;$$\u0026#39;] # 块级公式：$$...$$ - [\u0026#39;\\\\[\u0026#39;, \u0026#39;\\\\]\u0026#39;] # 或者 \\[...\\] inline: - [\u0026#39;$\u0026#39;, \u0026#39;$\u0026#39;] # 行内公式：$...$ - [\u0026#39;\\\\(\u0026#39;, \u0026#39;\\\\)\u0026#39;] # 或者 \\(...\\) hugo.yaml不要加math: true，在每篇文章开头的参数里加上：\nparams: math: true 4.6侧边目录 在config.yml中，添加或修改params对应的配置为以下内容：\nparams: ShowToc: true TocOpen: true 虽然PaperMod原生就有目录，但是却是在顶部，便捷性几乎为0，放在侧边就会方便许多。\n在项目目录layouts/partials下添加toc.html文件，内容如下：\n{{- $headers := findRE \u0026#34;\u0026lt;h[1-6].*?\u0026gt;(.|\\n])+?\u0026lt;/h[1-6]\u0026gt;\u0026#34; .Content -}} {{- $has_headers := ge (len $headers) 1 -}} {{- if $has_headers -}} \u0026lt;aside id=\u0026#34;toc-container\u0026#34; class=\u0026#34;toc-container wide\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;toc\u0026#34;\u0026gt; \u0026lt;details {{if (.Param \u0026#34;TocOpen\u0026#34;) }} open{{ end }}\u0026gt; \u0026lt;summary accesskey=\u0026#34;c\u0026#34; title=\u0026#34;(Alt + C)\u0026#34;\u0026gt; \u0026lt;span class=\u0026#34;details\u0026#34;\u0026gt;{{- i18n \u0026#34;toc\u0026#34; | default \u0026#34;Table of Contents\u0026#34; }}\u0026lt;/span\u0026gt; \u0026lt;/summary\u0026gt; \u0026lt;div class=\u0026#34;inner\u0026#34;\u0026gt; {{- $largest := 6 -}} {{- range $headers -}} {{- $headerLevel := index (findRE \u0026#34;[1-6]\u0026#34; . 1) 0 -}} {{- $headerLevel := len (seq $headerLevel) -}} {{- if lt $headerLevel $largest -}} {{- $largest = $headerLevel -}} {{- end -}} {{- end -}} {{- $firstHeaderLevel := len (seq (index (findRE \u0026#34;[1-6]\u0026#34; (index $headers 0) 1) 0)) -}} {{- $.Scratch.Set \u0026#34;bareul\u0026#34; slice -}} \u0026lt;ul\u0026gt; {{- range seq (sub $firstHeaderLevel $largest) -}} \u0026lt;ul\u0026gt; {{- $.Scratch.Add \u0026#34;bareul\u0026#34; (sub (add $largest .) 1) -}} {{- end -}} {{- range $i, $header := $headers -}} {{- $headerLevel := index (findRE \u0026#34;[1-6]\u0026#34; . 1) 0 -}} {{- $headerLevel := len (seq $headerLevel) -}} {{/* get id=\u0026#34;xyz\u0026#34; */}} {{- $id := index (findRE \u0026#34;(id=\\\u0026#34;(.*?)\\\u0026#34;)\u0026#34; $header 9) 0 }} {{- /* strip id=\u0026#34;\u0026#34; to leave xyz, no way to get regex capturing groups in hugo */ -}} {{- $cleanedID := replace (replace $id \u0026#34;id=\\\u0026#34;\u0026#34; \u0026#34;\u0026#34;) \u0026#34;\\\u0026#34;\u0026#34; \u0026#34;\u0026#34; }} {{- $header := replaceRE \u0026#34;\u0026lt;h[1-6].*?\u0026gt;((.|\\n])+?)\u0026lt;/h[1-6]\u0026gt;\u0026#34; \u0026#34;$1\u0026#34; $header -}} {{- if ne $i 0 -}} {{- $prevHeaderLevel := index (findRE \u0026#34;[1-6]\u0026#34; (index $headers (sub $i 1)) 1) 0 -}} {{- $prevHeaderLevel := len (seq $prevHeaderLevel) -}} {{- if gt $headerLevel $prevHeaderLevel -}} {{- range seq $prevHeaderLevel (sub $headerLevel 1) -}} \u0026lt;ul\u0026gt; {{/* the first should not be recorded */}} {{- if ne $prevHeaderLevel . -}} {{- $.Scratch.Add \u0026#34;bareul\u0026#34; . -}} {{- end -}} {{- end -}} {{- else -}} \u0026lt;/li\u0026gt; {{- if lt $headerLevel $prevHeaderLevel -}} {{- range seq (sub $prevHeaderLevel 1) -1 $headerLevel -}} {{- if in ($.Scratch.Get \u0026#34;bareul\u0026#34;) . -}} \u0026lt;/ul\u0026gt; {{/* manually do pop item */}} {{- $tmp := $.Scratch.Get \u0026#34;bareul\u0026#34; -}} {{- $.Scratch.Delete \u0026#34;bareul\u0026#34; -}} {{- $.Scratch.Set \u0026#34;bareul\u0026#34; slice}} {{- range seq (sub (len $tmp) 1) -}} {{- $.Scratch.Add \u0026#34;bareul\u0026#34; (index $tmp (sub . 1)) -}} {{- end -}} {{- else -}} \u0026lt;/ul\u0026gt; \u0026lt;/li\u0026gt; {{- end -}} {{- end -}} {{- end -}} {{- end }} \u0026lt;li\u0026gt; \u0026lt;a href=\u0026#34;#{{- $cleanedID -}}\u0026#34; aria-label=\u0026#34;{{- $header | plainify -}}\u0026#34;\u0026gt;{{- $header | safeHTML -}}\u0026lt;/a\u0026gt; {{- else }} \u0026lt;li\u0026gt; \u0026lt;a href=\u0026#34;#{{- $cleanedID -}}\u0026#34; aria-label=\u0026#34;{{- $header | plainify -}}\u0026#34;\u0026gt;{{- $header | safeHTML -}}\u0026lt;/a\u0026gt; {{- end -}} {{- end -}} \u0026lt;!-- {{- $firstHeaderLevel := len (seq (index (findRE \u0026#34;[1-6]\u0026#34; (index $headers 0) 1) 0)) -}} --\u0026gt; {{- $firstHeaderLevel := $largest }} {{- $lastHeaderLevel := len (seq (index (findRE \u0026#34;[1-6]\u0026#34; (index $headers (sub (len $headers) 1)) 1) 0)) }} \u0026lt;/li\u0026gt; {{- range seq (sub $lastHeaderLevel $firstHeaderLevel) -}} {{- if in ($.Scratch.Get \u0026#34;bareul\u0026#34;) (add . $firstHeaderLevel) }} \u0026lt;/ul\u0026gt; {{- else }} \u0026lt;/ul\u0026gt; \u0026lt;/li\u0026gt; {{- end -}} {{- end }} \u0026lt;/ul\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/details\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/aside\u0026gt; \u0026lt;script\u0026gt; let activeElement; let elements; window.addEventListener(\u0026#39;DOMContentLoaded\u0026#39;, function (event) { checkTocPosition(); elements = document.querySelectorAll(\u0026#39;h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]\u0026#39;); // Make the first header active activeElement = elements[0]; const id = encodeURI(activeElement.getAttribute(\u0026#39;id\u0026#39;)).toLowerCase(); document.querySelector(`.inner ul li a[href=\u0026#34;#${id}\u0026#34;]`).classList.add(\u0026#39;active\u0026#39;); }, false); window.addEventListener(\u0026#39;resize\u0026#39;, function(event) { checkTocPosition(); }, false); window.addEventListener(\u0026#39;scroll\u0026#39;, () =\u0026gt; { // Check if there is an object in the top half of the screen or keep the last item active activeElement = Array.from(elements).find((element) =\u0026gt; { if ((getOffsetTop(element) - window.pageYOffset) \u0026gt; 0 \u0026amp;\u0026amp; (getOffsetTop(element) - window.pageYOffset) \u0026lt; window.innerHeight/2) { return element; } }) || activeElement elements.forEach(element =\u0026gt; { const id = encodeURI(element.getAttribute(\u0026#39;id\u0026#39;)).toLowerCase(); if (element === activeElement){ document.querySelector(`.inner ul li a[href=\u0026#34;#${id}\u0026#34;]`).classList.add(\u0026#39;active\u0026#39;); } else { document.querySelector(`.inner ul li a[href=\u0026#34;#${id}\u0026#34;]`).classList.remove(\u0026#39;active\u0026#39;); } }) }, false); const main = parseInt(getComputedStyle(document.body).getPropertyValue(\u0026#39;--article-width\u0026#39;), 10); const toc = parseInt(getComputedStyle(document.body).getPropertyValue(\u0026#39;--toc-width\u0026#39;), 10); const gap = parseInt(getComputedStyle(document.body).getPropertyValue(\u0026#39;--gap\u0026#39;), 10); function checkTocPosition() { const width = document.body.scrollWidth; if (width - main - (toc * 2) - (gap * 4) \u0026gt; 0) { document.getElementById(\u0026#34;toc-container\u0026#34;).classList.add(\u0026#34;wide\u0026#34;); } else { document.getElementById(\u0026#34;toc-container\u0026#34;).classList.remove(\u0026#34;wide\u0026#34;); } } function getOffsetTop(element) { if (!element.getClientRects().length) { return 0; } let rect = element.getBoundingClientRect(); let win = element.ownerDocument.defaultView; return rect.top + win.pageYOffset; } \u0026lt;/script\u0026gt; {{- end }} 在项目目录assets/css/extended下添加blank.css文件，内容如下：\n:root { --nav-width: 1380px; --article-width: 650px; --toc-width: 300px; } .toc { margin: 0 2px 40px 2px; border: 1px solid var(--border); background: var(--entry); border-radius: var(--radius); padding: 0.4em; } .toc-container.wide { position: absolute; height: 100%; border-right: 1px solid var(--border); left: calc((var(--toc-width) + var(--gap)) * -1); top: calc(var(--gap) * 2); width: var(--toc-width); } .wide .toc { position: sticky; top: var(--gap); border: unset; background: unset; border-radius: unset; width: 100%; margin: 0 2px 40px 2px; } .toc details summary { cursor: zoom-in; margin-inline-start: 20px; padding: 12px 0; } .toc details[open] summary { font-weight: 500; } .toc-container.wide .toc .inner { margin: 0; } .active { font-size: 110%; font-weight: 600; } .toc ul { list-style-type: circle; } .toc .inner { margin: 0 0 0 20px; padding: 0px 15px 15px 20px; font-size: 16px; /*目录显示高度*/ max-height: 83vh; overflow-y: auto; } .toc .inner::-webkit-scrollbar-thumb { /*滚动条*/ background: var(--border); border: 7px solid var(--theme); border-radius: var(--radius); } .toc li ul { margin-inline-start: calc(var(--gap) * 0.5); list-style-type: none; } .toc li { list-style: none; font-size: 0.95rem; padding-bottom: 5px; } .toc li a:hover { color: var(--secondary); } 二、在GitHubPage部署网站 基本思路：建立两个仓库，一个网站仓库负责展示页面，另一个源仓库负责存储源码、更新内容并自动更新同步到网站仓库。\n1.建立网站仓库 在Github页面点击最上面的加号-New repository Repository name 填写 你的GitHub用户名.github.io，这样GitHub才会把它识别为网站仓库 选择Public 点击绿色的Create repository\n2.建立源仓库 同上建立仓库，随便命名，Public或Private都行 这里我命名为mywebsite\n3.GitHub 个人访问令牌 (Token) 生成\u0026amp;配置 点击右上角 头像 选择 Settings 左侧菜单选择 Developer settings 选择 Personal access tokens → Tokens (classic) 点击 Generate new token → Generate new token (classic) 设置 Token 信息： Token name：输入名称（如 mywebsite） Expiration：选择 No expiration（永不过期） 权限勾选： ✅ repo（全仓库权限） ✅ admin:repo_hook（仓库管理权限） 点击绿色按钮 Generate token 重要：立即复制生成的密钥并妥善保存（离开页面后将无法再次查看） 进入源仓库 点击settings 左侧Secrets and variables-Actions New repository secret 填写刚才的名称和密钥 Add sercet 4.配置workflow脚本 在本地网站根目录新建文件夹及文件.github/workflows/hugo.yaml 写入：\nname: github pages # 名字自取 on: push: branches: - main jobs: deploy: # 任务名自取 runs-on: ubuntu-latest\t# 在什么环境运行任务 steps: - uses: actions/checkout@v2\t# 引用actions/checkout这个action，与所在的github仓库同名 with: submodules: true # Fetch Hugo themes (true OR recursive) 获取submodule主题 fetch-depth: 0 # Fetch all history for .GitInfo and .Lastmod - name: Setup Hugo\t# 步骤名自取 uses: peaceiris/actions-hugo@v2\t# hugo官方提供的action，用于在任务环境中获取hugo with: hugo-version: \u0026#39;latest\u0026#39;\t# 获取最新版本的hugo extended: true - name: Build run: hugo --minify\t# 使用hugo构建静态网页 - name: Deploy uses: peaceiris/actions-gh-pages@v3\t# 一个自动发布github pages的action with: # github_token: ${{ secrets.GITHUB_TOKEN }} 该项适用于发布到源码相同repo的情况，不能用于发布到其他repo external_repository: Rook1eChan/Rook1eChan.github.io\t# 发布到哪个repo personal_token: ${{ secrets.MYWEBSITE2 }}\t# 发布到其他repo需要提供上面生成的personal access token publish_dir: ./public\t# 注意这里指的是要发布哪个文件夹的内容，而不是指发布到目的仓库的什么位置，因为hugo默认生成静态网页到public文件夹，所以这里发布public文件夹里的内容 publish_branch: main\t# 发布到哪个branch 只需要更改personal_token和external_repository\n5. SSH 密钥配置 检查是否已有 SSH Key\nWindows： 进入 C:\\Users\\你的用户名\\.ssh，查看是否存在 id_rsa（私钥）和 id_rsa.pub（公钥）文件。\n若有，说明已生成过 SSH Key，可直接使用。 若无，需重新生成。 Linux：\ncd ~/.ssh ls 检查是否存在 id_rsa 和 id_rsa.pub 文件。\n生成 SSH Key（若无） 运行以下命令（替换 xxx@xxx.com 为你的 GitHub 注册邮箱）：\nssh-keygen -t rsa -C \u0026#34;xxx@xxx.com\u0026#34; 连续按 3 次回车（使用默认路径，不设密码）。 生成的文件： id_rsa：私钥（切勿泄露）。 id_rsa.pub：公钥（需添加到 GitHub）。 将公钥添加到 GitHub 复制公钥内容（id_rsa.pub）： 登录 GitHub → 点击头像 → Settings → SSH and GPG Keys → New SSH Key。 测试 SSH 连接 在终端运行： ssh -T git@github.com 若显示 Hi 你的用户名!，说明配置成功。 之后clone或push时都选择SSH地址，而不是https地址。\n6.上传 本地网站根目录使用cmd，git@github.com:XXX/mywebsite.git改为源仓库地址：\ngit init git add . git remote add origin git@github.com:XXX/mywebsite.git git commit -m \u0026#34;Update\u0026#34; git push -u origin main 然后在源仓库的Action下，能看到正在Deploy，变绿色说明成功。此时网站仓库已自动更新了内容。\n进入网站仓库-settings-Pages-Build and deployment选择Deploy from a branch 刚才workflow脚本里写的是main，这里就选择main\n然后进入xxx.github.io，就可以看到你的网站了！🎉\n三、如何更新网站内容 不要在github和本地同时更改内容！不然会导致内容不同步，无法push。\n最好是一直都在本地更改，然后push到源仓库。\n1.本地更改后，比如新建了笔记，在网站根目录使用cmd： 不要复制注释！\ngit init //初始化git文件夹 git add . //添加变更内容 git remote add origin git@github.com:XXX/mywebsite.git //最后一项改为源仓库的地址，如果使用ssh连接的就复制ssh地址 git commit -m \u0026#34;new\u0026#34; //设置本次操作的名称，new可以随便改 git push -u origin main //把本地文件push到github上，增量更新 常见问题：\ngit push -u origin main的时候报错： error: src refspec master does not match any error: failed to push some refs to \u0026lsquo;github.com:Rook1eChan/mywebsite.git\u0026rsquo;\n使用git branch -a，查看branch的名称是不是main。如果是master，就把main改为master。\nTo github.com:Rook1eChan/mywebsite.git ! [rejected] main -\u0026gt; main (fetch first) error: failed to push some refs to \u0026lsquo;github.com:Rook1eChan/mywebsite.git\u0026rsquo; hint: Updates were rejected because the remote contains work that you do not\n说明你的GitHub和本地不同步。不建议强制合并，可以把GitHub整个repo clone到本地另一个文件，把变化的文件手动更改，再把新文件夹push上去。\n感谢GitHub、Hugo和Deekseek。\n","permalink":"https://Rook1eChan.github.io/posts/%E4%BB%8E0%E5%BC%80%E5%A7%8B%E5%BB%BA%E7%AB%8Bgithub%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2hugopapermod/","summary":"\u003cp\u003egithub提供给每个用户一个网址，用户可以建立自己的静态网站。\u003c/p\u003e\n\u003ch2 id=\"一hugo\"\u003e一、Hugo\u003c/h2\u003e\n\u003cp\u003ehugo是一个快速搭建网站的工具，由go语言编写。\u003c/p\u003e\n\u003ch3 id=\"1安装hugo\"\u003e1.安装hugo\u003c/h3\u003e\n\u003cp\u003e到hugo的github标签页\u003ca href=\"https://github.com/gohugoio/hugo/tags\"\u003eTags · gohugoio/hugo\u003c/a\u003e选择一个版本，下载对应的安装包。比如\u003ccode\u003ehugo_extended_withdeploy_0.147.0_windows-amd64.zip\u003c/code\u003e。\u003c/p\u003e\n\u003cp\u003e解压后，在根目录打开cmd，输入\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-cmd\" data-lang=\"cmd\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ehugo new site YourSiteName\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e为你的网站建立文件夹。\u003ccode\u003eYourSiteName\u003c/code\u003e更改为你的网站的名字。\n根目录会出现YourSiteName文件夹。\u003c/p\u003e\n\u003cp\u003e3.将根目录的hugo.exe复制到YourSiteName里。\n在YourSiteName文件夹里打开cmd，输入\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-cmd\" data-lang=\"cmd\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ehugo server -D\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e会返回如下信息：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-cmd\" data-lang=\"cmd\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                   \u003cspan class=\"p\"\u003e|\u003c/span\u003e EN\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e-------------------+-----\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  Pages            \u003cspan class=\"p\"\u003e|\u003c/span\u003e 11\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  Paginator pages  \u003cspan class=\"p\"\u003e|\u003c/span\u003e  0\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  Non-page files   \u003cspan class=\"p\"\u003e|\u003c/span\u003e  0\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  Static files     \u003cspan class=\"p\"\u003e|\u003c/span\u003e  0\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  Processed images \u003cspan class=\"p\"\u003e|\u003c/span\u003e  0\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  Aliases          \u003cspan class=\"p\"\u003e|\u003c/span\u003e  2\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  Cleaned          \u003cspan class=\"p\"\u003e|\u003c/span\u003e  0\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003eBuilt in 79 ms\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003eEnvironment: \u003cspan class=\"s2\"\u003e\u0026#34;development\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003eServing pages from disk\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003eRunning in Fast Render Mode. For full rebuilds on change: hugo server --disableFastRender\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003eWeb Server is available at http://localhost:1313/ (bind address 127.0.0.1)\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ePress Ctrl+C to stop\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e在浏览器中输入\u003ccode\u003ehttp://localhost:1313/\u003c/code\u003e，显示Page Not Found，说明服务器正常运行，但是此时网站还没有页面。\u003c/p\u003e","title":"从0开始建立Github个人博客(hugo\u0026PaperMod)"},{"content":"原文：Neural-IR Models.. Neural IR(Information Retrieval) is a… | by Muhammad Hammad Khan | Medium\n译文：【翻译】一文详解神经信息检索领域的最新进展 - 知乎\n神经信息检索(Neural Information Retrieval, Neural IR)是信息检索领域的一个重要研究课题。自从谷歌在2018年发布BERT以来，它在11个NLP任务上获得了最先进的结果，一举改变了整个NLP领域的研究范式。2019年1月，Nogueira和Cho在MS MARCO Passage Ranking测试集上首次使用BERT。从那时起，人们开始研究神经信息检索的范式，也提出了许多基于BERT的文本排序方法。这些方法用于多阶段搜索架构的重排阶段(Re-Ranker)。如下图所示。\nFigure1 展示了一个简化的多阶段搜索结构。第一步：倒排索引（Inverted Index）+BM25得分进行排序，得到topK文档，这一步也叫候选项生成（Candidates Generation）。第二步，通过基于BERT的上下文排序模型来确定前N个文档的最终排序。\n神经重排模型(Neural re-ranking models)一般可以分为以下四种，如Figure2所示：\n基于表征(representation-focused) 基于交互(interaction-focused) 全交互（也被称作交叉编码器,）(all-to-all interaction(cross encoder) ) 迟交互(late interaction) 1.基于表征——双塔模型(Bi-encoder Models) 双塔模型将Query和Doc分别表征为密集的向量嵌入，用向量相似度分数来估计Q和D的相关性。在训练时需要正负样本进行对比学习，因为如果只给模型看正样本，它会偷懒——把所有向量都变成一样的，这样“相似度”永远最高。负样本强迫模型学会区分相关和不相关的内容。\n在将模型训练好后，doc和query的表征可以独立进行，不用像交叉编码器那样每次都要把Query和Doc拼在一起重新计算。\n1.1密集段落检索器(Dense passage retriever, DPR) 论文：Dense Passage Retrieval for Open-Domain Question Answering EMNLP 2020, Facebook Research Code: github.com/facebookresearch/DPR 讲解博客：【IR 论文】DPR — 最早提出使用嵌入向量来检索文档的模型_dpr模型-CSDN博客\nDPR是一个应用于问答领域的双塔模型，旨在最大限度地提高查询与相关文档的相似度，同时最小化与非相关文档的相似度。DPR是RAG中R的经典方案。\n正样本往往数据集已给定，而负样本比较难选择。为此，DPR提出了一种Batch内负采样的技术，从同一批次的其他样本中选择样本作为负样本。这种方法是有效且高效的。\n1.2最近邻负对比估计 (Approximate nearest neighbour Negative Contrastive Estimation, ANCE) 该论文证明了强负样本能够加速模型收敛，提升模型性能。负样本分为易区别的和不易区别的，显然不易区别（即强负样本）的对模型学习帮助更大。本文使用ANN寻找强负样本。\nDPR和ANCE的结果表明，双塔编码器不如交叉编码器有效，因为丧失了查询与文档的交互。但是开销更小，因为文档可以单独预先处理。\n2.迟交互模型（Late Interaction Models） 2.1Contextualized Late Interaction over BERT, ColBERT v2论文：ColBERTv2: Effective and Efficient Retrieval via Lightweight Late Interaction ColBERT\u0026amp;ColBERTv2讲解：ColBERT和ColBERTv2:兼具Bi-encoder和cross-encoder优势的多向量排序模型-CSDN博客\nColBERT引入延迟交互机制，相比交叉编码器效率提升了很多。\n简单来说，将Query和Doc进行分词，每个token生成一个嵌入向量。计算Query中每个词与Doc所有词的向量相似度。Query每个词取最高分，所有最高分加起来得到Doc的最终得分。\n独立编码： Query向量：[如何, 治疗, 感冒] Doc向量：[感冒, 病毒, 休息, 维生素C] 计算MaxSim： 治疗 → 与Doc所有词相似度最高的是休息（得分0.7）。 感冒 → 匹配Doc中的感冒（得分1.0）。 总分：0.7 + 1.0 = 1.7 ColBERT既像双塔模型，可以单独计算Doc的向量并存储；又像交叉编码器，实现token级别的交互。\n双塔模型将整句话表征为一个向量，而ColBERT将每个token都表征为一个向量，显然后者更细粒度，对语义理解更深。但是存储Doc的每个token的向量所需的空间比传统的倒排索引大得多。这种大内存占用的特点使 ColBERT 在大型语料库情形下不占优势。\nColBERTv2在ColBERT基础上使用更先进的训练方法来微调模型，并通过残差压缩方法大幅减少存储成本。\n3.基于知识蒸馏的神经重排模型 蒸馏的主要用途是减小模型大小并降低整体推理成本。\n论文：Improving efficient neural ranking models with cross-architecture knowledge distillation.\n该作者使用MSMARCO数据集对教师模型进行微调，用它对所有训练三元组打分，构建一个新的数据集。最后，学生模型在这个新构建的数据集上使用Margin MSE Loss进行训练，该损失函数优化了查询与非相关文本及相关文本分数之间的边距(Margin)。\n论文：Efficiently Teaching an Effective Dense Retriever with Balanced Topic Aware Sampling\nTAS-B方法，在训练时把Query按照话题进行聚簇，每个Batch内均匀采样Query，防止随机采样导致一个Batch内的话题都相似。\n就目前来看，RAG的检索远没有检索领域来的复杂，只是用了关键字检索，没有微调。\n","permalink":"https://Rook1eChan.github.io/posts/neural-ir-models/","summary":"\u003cp\u003e原文：\u003ca href=\"https://medium.com/@mhammadkhan/neural-re-ranking-models-c0a67278f626\"\u003eNeural-IR Models.. Neural IR(Information Retrieval) is a… | by Muhammad Hammad Khan | Medium\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e译文：\u003ca href=\"https://zhuanlan.zhihu.com/p/545429612\"\u003e【翻译】一文详解神经信息检索领域的最新进展 - 知乎\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e神经信息检索(Neural Information Retrieval, Neural IR)是信息检索领域的一个重要研究课题。自从谷歌在2018年发布BERT以来，它在11个NLP任务上获得了最先进的结果，一举改变了整个NLP领域的研究范式。2019年1月，Nogueira和Cho在MS MARCO Passage Ranking测试集上首次使用BERT。从那时起，人们开始研究神经信息检索的范式，也提出了许多基于BERT的文本排序方法。这些方法用于\u003cstrong\u003e多阶段搜索架构的重排阶段(Re-Ranker)\u003c/strong\u003e。如下图所示。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image\" loading=\"lazy\" src=\"/Neural-IR-Models-1.jpg\"\u003e\u003c/p\u003e\n\u003cp\u003eFigure1 展示了一个简化的多阶段搜索结构。第一步：倒排索引（Inverted Index）+BM25得分进行排序，得到topK文档，这一步也叫候选项生成（Candidates Generation）。第二步，通过基于BERT的上下文排序模型来确定前N个文档的最终排序。\u003c/p\u003e\n\u003cp\u003e神经重排模型(Neural re-ranking models)一般可以分为以下四种，如Figure2所示：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e基于表征(representation-focused)\u003c/li\u003e\n\u003cli\u003e基于交互(interaction-focused)\u003c/li\u003e\n\u003cli\u003e全交互（也被称作交叉编码器,）(all-to-all interaction(cross encoder) )\u003c/li\u003e\n\u003cli\u003e迟交互(late interaction)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg alt=\"image\" loading=\"lazy\" src=\"/Neural-IR-Models-2.jpg\"\u003e\u003c/p\u003e\n\u003ch2 id=\"1基于表征双塔模型bi-encoder-models\"\u003e1.基于表征——双塔模型(Bi-encoder Models)\u003c/h2\u003e\n\u003cp\u003e双塔模型将Query和Doc分别表征为密集的向量嵌入，用向量相似度分数来估计Q和D的相关性。在训练时\u003cstrong\u003e需要正负样本进行对比学习\u003c/strong\u003e，因为如果只给模型看正样本，它会偷懒——把所有向量都变成一样的，这样“相似度”永远最高。负样本强迫模型学会区分相关和不相关的内容。\u003c/p\u003e\n\u003cp\u003e在将模型训练好后，doc和query的表征可以独立进行，不用像交叉编码器那样每次都要把Query和Doc拼在一起重新计算。\u003c/p\u003e\n\u003ch3 id=\"11密集段落检索器dense-passage-retriever-dpr\"\u003e1.1密集段落检索器(Dense passage retriever, DPR)\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003cp\u003e论文：\u003ca href=\"https://aclanthology.org/2020.emnlp-main.550\"\u003eDense Passage Retrieval for Open-Domain Question Answering\u003c/a\u003e\nEMNLP 2020, Facebook Research\nCode: \u003ca href=\"https://github.com/facebookresearch/DPR\"\u003egithub.com/facebookresearch/DPR\u003c/a\u003e\n讲解博客：\u003ca href=\"https://blog.csdn.net/qq_45668004/article/details/138256448\"\u003e【IR 论文】DPR — 最早提出使用嵌入向量来检索文档的模型_dpr模型-CSDN博客\u003c/a\u003e\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003eDPR是一个应用于问答领域的双塔模型，旨在最大限度地提高查询与相关文档的相似度，同时最小化与非相关文档的相似度。DPR是RAG中R的经典方案。\u003c/p\u003e\n\u003cp\u003e正样本往往数据集已给定，而负样本比较难选择。为此，DPR提出了一种Batch内负采样的技术，从同一批次的其他样本中选择样本作为负样本。这种方法是有效且高效的。\u003c/p\u003e\n\u003ch3 id=\"12最近邻负对比估计-approximate-nearest-neighbour-negative-contrastive-estimation-ance\"\u003e1.2最近邻负对比估计 (Approximate nearest neighbour Negative Contrastive Estimation, ANCE)\u003c/h3\u003e\n\u003cp\u003e该论文证明了强负样本能够加速模型收敛，提升模型性能。负样本分为易区别的和不易区别的，显然不易区别（即强负样本）的对模型学习帮助更大。本文使用ANN寻找强负样本。\u003c/p\u003e","title":"Neural-IR Models（博客）"}]