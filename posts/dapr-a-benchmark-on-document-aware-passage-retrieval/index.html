<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><link href="https://fonts.googleapis.com/css2?family=Noto+Sans+SC:wght@400;700&family=JetBrains+Mono&display=swap" rel=stylesheet><meta name=robots content="index, follow"><title>DAPR A Benchmark on Document-Aware Passage Retrieval | Chan's Blog</title>
<meta name=keywords content><meta name=description content="0.目标
神经检索（neural retrieval）的工作主要集中在短文本排序，无法处理需要连接上下文的问题，在长篇文章中做检索效果并不好。
比如：在A剧场中演出过的演员有哪些？如果只检索“A剧场”，可能找不到答案，需要结合上下文找到“……在这里演出过……”的内容才是真正答案。
对SOTA检索器（DRAGON+,SPLADEv2, and ColBERTv2 and BM25）的错误进行了分析，发现一般的错误是由缺乏上下文导致的（相关段落非自包含），DAPR很有必要。
1.贡献

提出DAPR（文章感知段落检索）
构建了一个基准测试数据集（benchmark），包括了5个不同领域的数据集

2.相关工作

DocQA：要求模型回答关于输入文档的问题。通常假设相关文档在提问前就已给出。
Long-document retrieval（长文档检索）：

MaxP——将文档中段落相关性的最大值作为文档相关性；
FirstP——仅编码文档中的第一个段落；
等等；
但此前的方法都未在检索的同时考虑上下文。


Hybrid retrieval（混合检索）：

rank fusion（排名融合）——通过凸组合、互逆排名等方法将不同检索系统的个体排名合并为一个。
hierarchical retrieval（层次检索）——首先检索文档，然后从这些文档中检索段落。只适用于段落本身足以对查询做出响应的情况。
本文探讨了段落排名和文档排名结合的有效性。


和预训练任务的关系：

以前的方法只关注独立的句子/段落，而不注意上下文。


补充：

NQ：谷歌的一个问答数据集
NDCG：评价检索序列的相关性和位置
共指信息：描述文本中不同表达式指向同一实体或概念的语言现象，如*“玛丽打开了门，她随后拿起包。”* → “她”与“玛丽”共指同一人。
共指消解（Coreference Resolution）：自动识别文本中所有指向同一实体的表达式并分组。



3.DAPR任务
3.1错误的主要类型
对SOTA的检索器使用NQ数据集，发现一半的错误来自于不了解上下文。将这些数据命名为NQ-hard，并分为4类：

共指消解（CR）：关键的共指信息需要通过特定文档上下文来解析；
主要主题（MT）：只有了解文档的背景主题（通常是标题），才能回答查询；
多跳推理（MHR）：连接查询和查询相关段落中的实体的推理路径包括文档上下文中的其他节点；
缩写（AC）：在相关段落（或查询）中出现一个缩写，该缩写对应于查询（或相关段落）中的全称，文档上下文解释了这种映射；

3.2本文用到的数据集
MS MARCO、Natural Questions、MIRACL、Genomics 和 ConditionalQA（具体处理方式见附录A）
对于MS MARCO和Natural Questions，我们将原始开发集视为测试集，并保留了一组采样的训练示例作为我们的开发集。对于其他7个数据集，我们保留了它们的原始数据分割。对于除MS MARCO外的数据集，段落片段是可用的（共同构成段落集合C）；而对于MS MARCO，此类信息不存在，仅提供C中相关文档内的段落跨度。
来自不同领域，经过预处理
3.3评估
使用nDCG@10和recall@100，代码中使用pytrec_eval计算nDCG@10
零样本评估：在MS MARCO训练部分训练，在MS测试部分测试，作为域内评估；在其它四个数据集上测试，作为域外评估。
4.实验
4.1基础检测器

BM25：PySerini（用于BM25的默认配置）
neural retrievers：DRAGON+、SPLADEv2、ColBERTv2，并在MS MARCO上训练

4.2两种将上下文引入神经检索器的方法
4.2.1加入BM25的混合检索
（1）融合检索
由于神经网络适合于检测512token内的段落，而BM25无限制，所以使用BM25检索整个文档，而使用神经检索器检索段落。"><meta name=author content><link rel=canonical href=https://Rook1eChan.github.io/posts/dapr-a-benchmark-on-document-aware-passage-retrieval/><link crossorigin=anonymous href=/assets/css/stylesheet.c625586be7dc30fec6f651a79a3490d1829cf0f1216ac2caaed862c64122ddd2.css integrity="sha256-xiVYa+fcMP7G9lGnmjSQ0YKc8PEhasLKrthixkEi3dI=" rel="preload stylesheet" as=style><link rel=icon href=https://Rook1eChan.github.io/apple-touch-icon.png><link rel=icon type=image/png sizes=16x16 href=https://Rook1eChan.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://Rook1eChan.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://Rook1eChan.github.io/apple-touch-icon.png><link rel=mask-icon href=https://Rook1eChan.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://Rook1eChan.github.io/posts/dapr-a-benchmark-on-document-aware-passage-retrieval/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://Rook1eChan.github.io/posts/dapr-a-benchmark-on-document-aware-passage-retrieval/"><meta property="og:site_name" content="Chan's Blog"><meta property="og:title" content="DAPR A Benchmark on Document-Aware Passage Retrieval"><meta property="og:description" content="0.目标 神经检索（neural retrieval）的工作主要集中在短文本排序，无法处理需要连接上下文的问题，在长篇文章中做检索效果并不好。
比如：在A剧场中演出过的演员有哪些？如果只检索“A剧场”，可能找不到答案，需要结合上下文找到“……在这里演出过……”的内容才是真正答案。
对SOTA检索器（DRAGON+,SPLADEv2, and ColBERTv2 and BM25）的错误进行了分析，发现一般的错误是由缺乏上下文导致的（相关段落非自包含），DAPR很有必要。
1.贡献 提出DAPR（文章感知段落检索） 构建了一个基准测试数据集（benchmark），包括了5个不同领域的数据集 2.相关工作 DocQA：要求模型回答关于输入文档的问题。通常假设相关文档在提问前就已给出。 Long-document retrieval（长文档检索）： MaxP——将文档中段落相关性的最大值作为文档相关性； FirstP——仅编码文档中的第一个段落； 等等； 但此前的方法都未在检索的同时考虑上下文。 Hybrid retrieval（混合检索）： rank fusion（排名融合）——通过凸组合、互逆排名等方法将不同检索系统的个体排名合并为一个。 hierarchical retrieval（层次检索）——首先检索文档，然后从这些文档中检索段落。只适用于段落本身足以对查询做出响应的情况。 本文探讨了段落排名和文档排名结合的有效性。 和预训练任务的关系： 以前的方法只关注独立的句子/段落，而不注意上下文。 补充： NQ：谷歌的一个问答数据集 NDCG：评价检索序列的相关性和位置 共指信息：描述文本中不同表达式指向同一实体或概念的语言现象，如*“玛丽打开了门，她随后拿起包。”* → “她”与“玛丽”共指同一人。 共指消解（Coreference Resolution）：自动识别文本中所有指向同一实体的表达式并分组。 3.DAPR任务 3.1错误的主要类型 对SOTA的检索器使用NQ数据集，发现一半的错误来自于不了解上下文。将这些数据命名为NQ-hard，并分为4类：
共指消解（CR）：关键的共指信息需要通过特定文档上下文来解析； 主要主题（MT）：只有了解文档的背景主题（通常是标题），才能回答查询； 多跳推理（MHR）：连接查询和查询相关段落中的实体的推理路径包括文档上下文中的其他节点； 缩写（AC）：在相关段落（或查询）中出现一个缩写，该缩写对应于查询（或相关段落）中的全称，文档上下文解释了这种映射； 3.2本文用到的数据集 MS MARCO、Natural Questions、MIRACL、Genomics 和 ConditionalQA（具体处理方式见附录A）
对于MS MARCO和Natural Questions，我们将原始开发集视为测试集，并保留了一组采样的训练示例作为我们的开发集。对于其他7个数据集，我们保留了它们的原始数据分割。对于除MS MARCO外的数据集，段落片段是可用的（共同构成段落集合C）；而对于MS MARCO，此类信息不存在，仅提供C中相关文档内的段落跨度。
来自不同领域，经过预处理
3.3评估 使用nDCG@10和recall@100，代码中使用pytrec_eval计算nDCG@10
零样本评估：在MS MARCO训练部分训练，在MS测试部分测试，作为域内评估；在其它四个数据集上测试，作为域外评估。
4.实验 4.1基础检测器 BM25：PySerini（用于BM25的默认配置） neural retrievers：DRAGON+、SPLADEv2、ColBERTv2，并在MS MARCO上训练 4.2两种将上下文引入神经检索器的方法 4.2.1加入BM25的混合检索 （1）融合检索
由于神经网络适合于检测512token内的段落，而BM25无限制，所以使用BM25检索整个文档，而使用神经检索器检索段落。"><meta property="og:locale" content="zh-CN"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-05-02T16:41:03+08:00"><meta property="article:modified_time" content="2025-05-02T16:41:03+08:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="DAPR A Benchmark on Document-Aware Passage Retrieval"><meta name=twitter:description content="0.目标
神经检索（neural retrieval）的工作主要集中在短文本排序，无法处理需要连接上下文的问题，在长篇文章中做检索效果并不好。
比如：在A剧场中演出过的演员有哪些？如果只检索“A剧场”，可能找不到答案，需要结合上下文找到“……在这里演出过……”的内容才是真正答案。
对SOTA检索器（DRAGON+,SPLADEv2, and ColBERTv2 and BM25）的错误进行了分析，发现一般的错误是由缺乏上下文导致的（相关段落非自包含），DAPR很有必要。
1.贡献

提出DAPR（文章感知段落检索）
构建了一个基准测试数据集（benchmark），包括了5个不同领域的数据集

2.相关工作

DocQA：要求模型回答关于输入文档的问题。通常假设相关文档在提问前就已给出。
Long-document retrieval（长文档检索）：

MaxP——将文档中段落相关性的最大值作为文档相关性；
FirstP——仅编码文档中的第一个段落；
等等；
但此前的方法都未在检索的同时考虑上下文。


Hybrid retrieval（混合检索）：

rank fusion（排名融合）——通过凸组合、互逆排名等方法将不同检索系统的个体排名合并为一个。
hierarchical retrieval（层次检索）——首先检索文档，然后从这些文档中检索段落。只适用于段落本身足以对查询做出响应的情况。
本文探讨了段落排名和文档排名结合的有效性。


和预训练任务的关系：

以前的方法只关注独立的句子/段落，而不注意上下文。


补充：

NQ：谷歌的一个问答数据集
NDCG：评价检索序列的相关性和位置
共指信息：描述文本中不同表达式指向同一实体或概念的语言现象，如*“玛丽打开了门，她随后拿起包。”* → “她”与“玛丽”共指同一人。
共指消解（Coreference Resolution）：自动识别文本中所有指向同一实体的表达式并分组。



3.DAPR任务
3.1错误的主要类型
对SOTA的检索器使用NQ数据集，发现一半的错误来自于不了解上下文。将这些数据命名为NQ-hard，并分为4类：

共指消解（CR）：关键的共指信息需要通过特定文档上下文来解析；
主要主题（MT）：只有了解文档的背景主题（通常是标题），才能回答查询；
多跳推理（MHR）：连接查询和查询相关段落中的实体的推理路径包括文档上下文中的其他节点；
缩写（AC）：在相关段落（或查询）中出现一个缩写，该缩写对应于查询（或相关段落）中的全称，文档上下文解释了这种映射；

3.2本文用到的数据集
MS MARCO、Natural Questions、MIRACL、Genomics 和 ConditionalQA（具体处理方式见附录A）
对于MS MARCO和Natural Questions，我们将原始开发集视为测试集，并保留了一组采样的训练示例作为我们的开发集。对于其他7个数据集，我们保留了它们的原始数据分割。对于除MS MARCO外的数据集，段落片段是可用的（共同构成段落集合C）；而对于MS MARCO，此类信息不存在，仅提供C中相关文档内的段落跨度。
来自不同领域，经过预处理
3.3评估
使用nDCG@10和recall@100，代码中使用pytrec_eval计算nDCG@10
零样本评估：在MS MARCO训练部分训练，在MS测试部分测试，作为域内评估；在其它四个数据集上测试，作为域外评估。
4.实验
4.1基础检测器

BM25：PySerini（用于BM25的默认配置）
neural retrievers：DRAGON+、SPLADEv2、ColBERTv2，并在MS MARCO上训练

4.2两种将上下文引入神经检索器的方法
4.2.1加入BM25的混合检索
（1）融合检索
由于神经网络适合于检测512token内的段落，而BM25无限制，所以使用BM25检索整个文档，而使用神经检索器检索段落。"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://Rook1eChan.github.io/posts/"},{"@type":"ListItem","position":2,"name":"DAPR A Benchmark on Document-Aware Passage Retrieval","item":"https://Rook1eChan.github.io/posts/dapr-a-benchmark-on-document-aware-passage-retrieval/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"DAPR A Benchmark on Document-Aware Passage Retrieval","name":"DAPR A Benchmark on Document-Aware Passage Retrieval","description":"0.目标 神经检索（neural retrieval）的工作主要集中在短文本排序，无法处理需要连接上下文的问题，在长篇文章中做检索效果并不好。\n比如：在A剧场中演出过的演员有哪些？如果只检索“A剧场”，可能找不到答案，需要结合上下文找到“……在这里演出过……”的内容才是真正答案。\n对SOTA检索器（DRAGON+,SPLADEv2, and ColBERTv2 and BM25）的错误进行了分析，发现一般的错误是由缺乏上下文导致的（相关段落非自包含），DAPR很有必要。\n1.贡献 提出DAPR（文章感知段落检索） 构建了一个基准测试数据集（benchmark），包括了5个不同领域的数据集 2.相关工作 DocQA：要求模型回答关于输入文档的问题。通常假设相关文档在提问前就已给出。 Long-document retrieval（长文档检索）： MaxP——将文档中段落相关性的最大值作为文档相关性； FirstP——仅编码文档中的第一个段落； 等等； 但此前的方法都未在检索的同时考虑上下文。 Hybrid retrieval（混合检索）： rank fusion（排名融合）——通过凸组合、互逆排名等方法将不同检索系统的个体排名合并为一个。 hierarchical retrieval（层次检索）——首先检索文档，然后从这些文档中检索段落。只适用于段落本身足以对查询做出响应的情况。 本文探讨了段落排名和文档排名结合的有效性。 和预训练任务的关系： 以前的方法只关注独立的句子/段落，而不注意上下文。 补充： NQ：谷歌的一个问答数据集 NDCG：评价检索序列的相关性和位置 共指信息：描述文本中不同表达式指向同一实体或概念的语言现象，如*“玛丽打开了门，她随后拿起包。”* → “她”与“玛丽”共指同一人。 共指消解（Coreference Resolution）：自动识别文本中所有指向同一实体的表达式并分组。 3.DAPR任务 3.1错误的主要类型 对SOTA的检索器使用NQ数据集，发现一半的错误来自于不了解上下文。将这些数据命名为NQ-hard，并分为4类：\n共指消解（CR）：关键的共指信息需要通过特定文档上下文来解析； 主要主题（MT）：只有了解文档的背景主题（通常是标题），才能回答查询； 多跳推理（MHR）：连接查询和查询相关段落中的实体的推理路径包括文档上下文中的其他节点； 缩写（AC）：在相关段落（或查询）中出现一个缩写，该缩写对应于查询（或相关段落）中的全称，文档上下文解释了这种映射； 3.2本文用到的数据集 MS MARCO、Natural Questions、MIRACL、Genomics 和 ConditionalQA（具体处理方式见附录A）\n对于MS MARCO和Natural Questions，我们将原始开发集视为测试集，并保留了一组采样的训练示例作为我们的开发集。对于其他7个数据集，我们保留了它们的原始数据分割。对于除MS MARCO外的数据集，段落片段是可用的（共同构成段落集合C）；而对于MS MARCO，此类信息不存在，仅提供C中相关文档内的段落跨度。\n来自不同领域，经过预处理\n3.3评估 使用nDCG@10和recall@100，代码中使用pytrec_eval计算nDCG@10\n零样本评估：在MS MARCO训练部分训练，在MS测试部分测试，作为域内评估；在其它四个数据集上测试，作为域外评估。\n4.实验 4.1基础检测器 BM25：PySerini（用于BM25的默认配置） neural retrievers：DRAGON+、SPLADEv2、ColBERTv2，并在MS MARCO上训练 4.2两种将上下文引入神经检索器的方法 4.2.1加入BM25的混合检索 （1）融合检索\n由于神经网络适合于检测512token内的段落，而BM25无限制，所以使用BM25检索整个文档，而使用神经检索器检索段落。\n","keywords":[],"articleBody":"0.目标 神经检索（neural retrieval）的工作主要集中在短文本排序，无法处理需要连接上下文的问题，在长篇文章中做检索效果并不好。\n比如：在A剧场中演出过的演员有哪些？如果只检索“A剧场”，可能找不到答案，需要结合上下文找到“……在这里演出过……”的内容才是真正答案。\n对SOTA检索器（DRAGON+,SPLADEv2, and ColBERTv2 and BM25）的错误进行了分析，发现一般的错误是由缺乏上下文导致的（相关段落非自包含），DAPR很有必要。\n1.贡献 提出DAPR（文章感知段落检索） 构建了一个基准测试数据集（benchmark），包括了5个不同领域的数据集 2.相关工作 DocQA：要求模型回答关于输入文档的问题。通常假设相关文档在提问前就已给出。 Long-document retrieval（长文档检索）： MaxP——将文档中段落相关性的最大值作为文档相关性； FirstP——仅编码文档中的第一个段落； 等等； 但此前的方法都未在检索的同时考虑上下文。 Hybrid retrieval（混合检索）： rank fusion（排名融合）——通过凸组合、互逆排名等方法将不同检索系统的个体排名合并为一个。 hierarchical retrieval（层次检索）——首先检索文档，然后从这些文档中检索段落。只适用于段落本身足以对查询做出响应的情况。 本文探讨了段落排名和文档排名结合的有效性。 和预训练任务的关系： 以前的方法只关注独立的句子/段落，而不注意上下文。 补充： NQ：谷歌的一个问答数据集 NDCG：评价检索序列的相关性和位置 共指信息：描述文本中不同表达式指向同一实体或概念的语言现象，如*“玛丽打开了门，她随后拿起包。”* → “她”与“玛丽”共指同一人。 共指消解（Coreference Resolution）：自动识别文本中所有指向同一实体的表达式并分组。 3.DAPR任务 3.1错误的主要类型 对SOTA的检索器使用NQ数据集，发现一半的错误来自于不了解上下文。将这些数据命名为NQ-hard，并分为4类：\n共指消解（CR）：关键的共指信息需要通过特定文档上下文来解析； 主要主题（MT）：只有了解文档的背景主题（通常是标题），才能回答查询； 多跳推理（MHR）：连接查询和查询相关段落中的实体的推理路径包括文档上下文中的其他节点； 缩写（AC）：在相关段落（或查询）中出现一个缩写，该缩写对应于查询（或相关段落）中的全称，文档上下文解释了这种映射； 3.2本文用到的数据集 MS MARCO、Natural Questions、MIRACL、Genomics 和 ConditionalQA（具体处理方式见附录A）\n对于MS MARCO和Natural Questions，我们将原始开发集视为测试集，并保留了一组采样的训练示例作为我们的开发集。对于其他7个数据集，我们保留了它们的原始数据分割。对于除MS MARCO外的数据集，段落片段是可用的（共同构成段落集合C）；而对于MS MARCO，此类信息不存在，仅提供C中相关文档内的段落跨度。\n来自不同领域，经过预处理\n3.3评估 使用nDCG@10和recall@100，代码中使用pytrec_eval计算nDCG@10\n零样本评估：在MS MARCO训练部分训练，在MS测试部分测试，作为域内评估；在其它四个数据集上测试，作为域外评估。\n4.实验 4.1基础检测器 BM25：PySerini（用于BM25的默认配置） neural retrievers：DRAGON+、SPLADEv2、ColBERTv2，并在MS MARCO上训练 4.2两种将上下文引入神经检索器的方法 4.2.1加入BM25的混合检索 （1）融合检索\n由于神经网络适合于检测512token内的段落，而BM25无限制，所以使用BM25检索整个文档，而使用神经检索器检索段落。\n首先，对BM25和神经检索器的原始分数进行归一化，使其落在[0,1]区间。归一化公式为：$\\hat{s}(q, c) = \\frac{s(q, c) - m_q}{M_q - m_q}$​\n$s(q, c)$：检索器对查询(q)和候选文本(c)（段落或文档）的原始分数。 $m_q和M_q$：当前查询(q)的Top候选结果中分数的最小值和最大值。 若候选文本(c)在某一检索器的结果中缺失（未进入Top列表），则其分数视为0。 将归一化后的BM25分数 $\\hat{s}_{\\text{BM25}}$ 和神经检索分数 $\\hat{s}_{\\text{neural}}$ 按权重 $\\alpha$ 线性组合:$s_{\\text{convex}}(q, p, d) = \\alpha \\hat{s}_{\\text{BM25}}(q, p) + (1 - \\alpha) \\hat{s}_{\\text{neural}}(q, d)$\n$\\alpha \\in [0,1]$：控制BM25和神经检索器的相对重要性。 $p$ 和 $d$：分别代表段落和文档。 如果某一候选文本仅出现在一个检索器的结果中，缺失的一侧分数直接设为0，确保融合时不会漏检。\n（2）层次检索\n第一步先BM25检索文档，第二步神经检索搜索段落，并在第二步应用带有分数归一化的排名融合。\n4.2.2上下文化的段落表示 对文档进行处理，检索方法使用SOTA神经方法\n（1）将文章标题放在每个段落的开头，并用特殊标记分割。但是有10%的文档无标题或标题无意义。\n（2）使用TopicRank算法提取出文档的十个关键词，放在每个段落之前。\n（3）共指消解：使用SpanBERT-large model，采用c2f-coref方法，在OntoNotes上微调。然后用模型对文档生成代词-先行词映射。将代词与文档中最早出现的先行词关联。将先行词放入括号，附在对应的代词后面。比如 “曾在该场地（xx剧场）”\n5.result 5.1混合检索\n排序融合略好于层次检索，但都不能解决NQ-Hard问题。说明这两种方法都只能提高自包含问题的表现。\n统计了检索性能随融合权重变化的曲线。发现NQ上的最佳融合权重不能直接转移到NQ-hard上。\n5.2上下文化段落表示\n添加标题和关键词的提升效果相当，共指消解最差。\n在NQ-Hard问题（需要连接上下文的问题）的表现显著优于混合检索。\n6.Disscution 1.为什么混合检索在Hard问题上表现不佳\n通过MaxP方法将查询-段落的指标转为查询-文档的指标，发现混合检索的文档级表现与上下文表示相当，说明它能找到相关文档，但段落排序表现差，说明它在段落级区分能力不足。\n2.为什么在Genomics上上下文表示结果变差\n计算了加/不加标题的文档与query的Jaccard相似度，只有Genomics加标题后值减小。说明添加标题引入了更多不相关的内容，帮倒忙。\nJaccard 相似度公式 $\\text{Jaccard}(A, B) = \\frac{|A \\cap B|}{|A \\cup B|}$\n$A $ 和$B $：两个文本的词集合（或更广义的集合）。 $|A \\cap B|$: A 和 B 中**共同词（交集）**的数量。 $|A \\cup B| $: A 和 B 中**所有唯一词（并集）**的数量。 取值范围 $[0, 1]$（0 表示无重叠，1 表示完全一致）。\n优点：\n简单直观，适用于短文本或集合型数据 不依赖词序或语义（仅统计词重叠） 缺点：\n忽略语义：同义词（如“电脑”和“计算机”）会被视为不同词。 敏感于词频：未考虑词的重要性（如TF-IDF），可以给词添加权重作为改进。 长文本效果差：并集会急剧增大，导致相似度被低估。 3.错误分析\n在两种融合检索、三种上下文化的方法下，多跳推理MHR最难解决，缩写最易解决。使用共指消解不如直接添加标题，因为标题往往含有核心词，而共指消解多次在段落中插入内容，反而干扰了匹配\n该文章中了ACL2024。在连接上下文方面使用的方法比较淳朴。主要是定义了NQ-Hard数据集，并在5个数据集、原始方法+2个混合检索+3个上下文检索上做了一系列实验，并很好的解释了现象。\n复现 把README里的loaddata和evaluation的代码复制到dapr根目录load.py和eval.py下\npip install -r requirements.txt\n有setup.py，在根目录下python setup.py build python setup.py install 解决module’dapr’ not found\nsudo apt-get update\nConditionalQA数据集 ConditionalQA给定提问者特定情况下的情景，回答与英国政策相关的问题。每个问答实例都标注了来自英国政府政策网页的证据。我们将原始数据集中的所有此类网页作为语料库。每个网页最初被解析为HTML标签，我们将其视为段落，移除HTML标签，仅保留纯自然语言。对于每个问答实例，我们将情景和问题连接起来形成一个查询，并将相应的证据视为黄金相关段落。\n预处理后的train\n{ \"query\": { \"id\": \"train-0\", //train条目编号 \"text\": \"My father, who was a widower and the owner of several large properties in Wales, died recently and apparently intestate. My paternal uncle is applying for probate, but I believe that I have a stronger claim. Do I have a greater right to probate in respect of my late father's estate?\" }, \"judged_chunks\": [ //判断点，一个问题可能有多个黄金段落 { \"chunk\": { \"id\": \"74-24\", \"text\": \"You can apply to become the estate’s administrator if you are 18 or over and you are the most ‘entitled’ inheritor of the deceased’s estate. This is usually the deceased’s closest living relative.\n\" }, \"judgement\": 1, //都为1 \"belonging_doc\": { //每个chunk都把\"belonging_doc\"详细写了一遍，导致文件很大 \"id\": \"74\", \"title\": \"Applying for probate\", \"chunks\": [ { \"id\": \"74-0\", \"text\": \"Overview\" }, ... { \"id\": \"74-138\", \"text\": \"Once you have probate you can start dealing with the estate.\" } ], \"candidate_chunk_ids\": [ \"74-5\", ... \"74-51\" ] } } ... ] } 预处理后的test\n{ \"query\": { \"id\": \"dev-0\", //问题编号 \"text\": \"My brother and his wife are in prison for carrying out a large fraud scheme. Their 7 and 8 year old children have been living with me for the last 4 years. I want to become their Special Guardian to look after them permanently How long will it be before I hear back from the court?\" }, //具体问题 \"judged_chunks\": [ { \"chunk\": { \"id\": \"86-41\", //黄金匹配段落 \"text\": \"Within 10 days of receiving your application the court will send you a case number and a date for a meeting to set out:\n\" }, \"judgement\": 1, //不知道什么意思，取值应该全部为1 \"belonging_doc\": { \"id\": \"86\", \"title\": \"Become a special guardian\", \"chunks\": [ //chunks是该问题相关的法条界面的文本分割后的结果。一段话设置为一个chunk { \"id\": \"86-0\", \"text\": \"What is a special guardian\" }, { \"id\": \"86-1\", \"text\": \"You can apply to be a child’s special guardian when they cannot live with their birth parents and adoption is not right for them.\" }, ... { \"id\": \"86-62\", \"text\": \"You might be able to get a special guardian allowance from the children’s services department of your local council.\" } ], \"candidate_chunk_ids\": [ //把chunkid重新排了一遍，不知道按照什么要求排的 \"86-6\", \"86-52\", ... \"86-57\", \"86-14\", \"86-2\", \"86-16\" ] } } ] } ","wordCount":"541","inLanguage":"en","datePublished":"2025-05-02T16:41:03+08:00","dateModified":"2025-05-02T16:41:03+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://Rook1eChan.github.io/posts/dapr-a-benchmark-on-document-aware-passage-retrieval/"},"publisher":{"@type":"Organization","name":"Chan's Blog","logo":{"@type":"ImageObject","url":"https://Rook1eChan.github.io/apple-touch-icon.png"}}}</script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]]}}</script><script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://Rook1eChan.github.io/ accesskey=h title="Chan's Blog (Alt + H)"><img src=https://Rook1eChan.github.io/apple-touch-icon.png alt aria-label=logo height=35>Chan's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://Rook1eChan.github.io/search/ title="search (Alt + /)" accesskey=/><span>search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://Rook1eChan.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://Rook1eChan.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">DAPR A Benchmark on Document-Aware Passage Retrieval</h1><div class=post-meta><span title='2025-05-02 16:41:03 +0800 +0800'>May 2, 2025</span></div></header><div class=post-content><h2 id=0目标>0.目标<a hidden class=anchor aria-hidden=true href=#0目标>#</a></h2><p>神经检索（neural retrieval）的工作主要集中在短文本排序，无法处理需要连接上下文的问题，在长篇文章中做检索效果并不好。</p><p>比如：在A剧场中演出过的演员有哪些？如果只检索“A剧场”，可能找不到答案，需要结合上下文找到“……在这里演出过……”的内容才是真正答案。</p><p>对SOTA检索器（DRAGON+,SPLADEv2, and ColBERTv2 and BM25）的错误进行了分析，发现一般的错误是由缺乏上下文导致的（相关段落非自包含），DAPR很有必要。</p><h2 id=1贡献>1.贡献<a hidden class=anchor aria-hidden=true href=#1贡献>#</a></h2><ol><li>提出DAPR（文章感知段落检索）</li><li>构建了一个基准测试数据集（benchmark），包括了5个不同领域的数据集</li></ol><h2 id=2相关工作>2.相关工作<a hidden class=anchor aria-hidden=true href=#2相关工作>#</a></h2><ul><li>DocQA：要求模型回答关于输入文档的问题。通常假设相关文档在提问前就已给出。</li><li>Long-document retrieval（长文档检索）：<ul><li>MaxP——将文档中段落相关性的最大值作为文档相关性；</li><li>FirstP——仅编码文档中的第一个段落；</li><li>等等；</li><li>但此前的方法都未在检索的同时考虑上下文。</li></ul></li><li>Hybrid retrieval（混合检索）：<ul><li>rank fusion（排名融合）——通过凸组合、互逆排名等方法将不同检索系统的个体排名合并为一个。</li><li>hierarchical retrieval（层次检索）——首先检索文档，然后从这些文档中检索段落。只适用于段落本身足以对查询做出响应的情况。</li><li>本文探讨了段落排名和文档排名结合的有效性。</li></ul></li><li>和预训练任务的关系：<ul><li>以前的方法只关注独立的句子/段落，而不注意上下文。</li></ul></li><li>补充：<ul><li>NQ：谷歌的一个问答数据集</li><li>NDCG：评价检索序列的相关性和位置</li><li>共指信息：描述文本中不同表达式指向同一实体或概念的语言现象，如*“玛丽打开了门，<strong>她</strong>随后拿起包。”* → “她”与“玛丽”共指同一人。</li><li>共指消解（Coreference Resolution）：自动识别文本中所有指向同一实体的表达式并分组。</li></ul></li></ul><h2 id=3dapr任务>3.DAPR任务<a hidden class=anchor aria-hidden=true href=#3dapr任务>#</a></h2><h3 id=31错误的主要类型>3.1错误的主要类型<a hidden class=anchor aria-hidden=true href=#31错误的主要类型>#</a></h3><p>对SOTA的检索器使用NQ数据集，发现一半的错误来自于不了解上下文。将这些数据命名为<strong>NQ-hard</strong>，并分为4类：</p><ol><li>共指消解（CR）：关键的共指信息需要通过特定文档上下文来解析；</li><li>主要主题（MT）：只有了解文档的背景主题（通常是标题），才能回答查询；</li><li>多跳推理（MHR）：连接查询和查询相关段落中的实体的推理路径包括文档上下文中的其他节点；</li><li>缩写（AC）：在相关段落（或查询）中出现一个缩写，该缩写对应于查询（或相关段落）中的全称，文档上下文解释了这种映射；</li></ol><h3 id=32本文用到的数据集>3.2本文用到的数据集<a hidden class=anchor aria-hidden=true href=#32本文用到的数据集>#</a></h3><p>MS MARCO、Natural Questions、MIRACL、Genomics 和 ConditionalQA（具体处理方式见附录A）</p><p>对于MS MARCO和Natural Questions，我们将原始开发集视为测试集，并保留了一组采样的训练示例作为我们的开发集。对于其他7个数据集，我们保留了它们的原始数据分割。对于除MS MARCO外的数据集，段落片段是可用的（共同构成段落集合C）；而对于MS MARCO，此类信息不存在，仅提供C中相关文档内的段落跨度。</p><p>来自不同领域，经过预处理</p><h3 id=33评估>3.3评估<a hidden class=anchor aria-hidden=true href=#33评估>#</a></h3><p>使用<strong>nDCG@10</strong>和recall@100，代码中使用pytrec_eval计算nDCG@10</p><p>零样本评估：在MS MARCO训练部分训练，在MS测试部分测试，作为域内评估；在其它四个数据集上测试，作为域外评估。</p><h2 id=4实验>4.实验<a hidden class=anchor aria-hidden=true href=#4实验>#</a></h2><h3 id=41基础检测器>4.1基础检测器<a hidden class=anchor aria-hidden=true href=#41基础检测器>#</a></h3><ul><li>BM25：PySerini（用于BM25的默认配置）</li><li>neural retrievers：DRAGON+、SPLADEv2、ColBERTv2，并在MS MARCO上训练</li></ul><h3 id=42两种将上下文引入神经检索器的方法>4.2两种将上下文引入神经检索器的方法<a hidden class=anchor aria-hidden=true href=#42两种将上下文引入神经检索器的方法>#</a></h3><h4 id=421加入bm25的混合检索>4.2.1加入BM25的混合检索<a hidden class=anchor aria-hidden=true href=#421加入bm25的混合检索>#</a></h4><p>（1）融合检索</p><p>由于神经网络适合于检测512token内的段落，而BM25无限制，所以使用BM25检索整个文档，而使用神经检索器检索段落。</p><p>首先，对BM25和神经检索器的原始分数进行归一化，使其落在[0,1]区间。归一化公式为：$\hat{s}(q, c) = \frac{s(q, c) - m_q}{M_q - m_q}$​</p><ul><li>$s(q, c)$：检索器对查询(q)和候选文本(c)（段落或文档）的原始分数。</li><li>$m_q和M_q$：当前查询(q)的Top候选结果中分数的最小值和最大值。</li><li>若候选文本(c)在某一检索器的结果中缺失（未进入Top列表），则其分数视为0。</li></ul><p>将归一化后的BM25分数 $\hat{s}_{\text{BM25}}$ 和神经检索分数 $\hat{s}_{\text{neural}}$ 按权重 $\alpha$ 线性组合:$s_{\text{convex}}(q, p, d) = \alpha \hat{s}_{\text{BM25}}(q, p) + (1 - \alpha) \hat{s}_{\text{neural}}(q, d)$</p><ul><li>$\alpha \in [0,1]$：控制BM25和神经检索器的相对重要性。</li><li>$p$ 和 $d$：分别代表段落和文档。</li></ul><p>如果某一候选文本仅出现在一个检索器的结果中，缺失的一侧分数直接设为0，确保融合时不会漏检。</p><p>（2）层次检索</p><p>第一步先BM25检索文档，第二步神经检索搜索段落，并在第二步应用带有分数归一化的排名融合。</p><h4 id=422上下文化的段落表示>4.2.2上下文化的段落表示<a hidden class=anchor aria-hidden=true href=#422上下文化的段落表示>#</a></h4><p>对文档进行处理，检索方法使用SOTA神经方法</p><p>（1）将文章标题放在每个段落的开头，并用特殊标记分割。但是有10%的文档无标题或标题无意义。</p><p>（2）使用TopicRank算法提取出文档的十个关键词，放在每个段落之前。</p><p>（3）共指消解：使用SpanBERT-large model，采用c2f-coref方法，在OntoNotes上微调。然后用模型对文档生成代词-先行词映射。将代词与文档中最早出现的先行词关联。将先行词放入括号，附在对应的代词后面。比如 “<em>曾在该场地（xx剧场）</em>”</p><h2 id=5result>5.result<a hidden class=anchor aria-hidden=true href=#5result>#</a></h2><p>5.1混合检索</p><p>排序融合略好于层次检索，但都不能解决NQ-Hard问题。说明这两种方法都只能提高自包含问题的表现。</p><p>统计了检索性能随融合权重变化的曲线。发现NQ上的最佳融合权重不能直接转移到NQ-hard上。</p><p>5.2上下文化段落表示</p><p>添加标题和关键词的提升效果相当，共指消解最差。</p><p>在NQ-Hard问题（需要连接上下文的问题）的表现显著优于混合检索。</p><h2 id=6disscution>6.Disscution<a hidden class=anchor aria-hidden=true href=#6disscution>#</a></h2><p>1.为什么混合检索在Hard问题上表现不佳</p><p>通过MaxP方法将查询-段落的指标转为查询-文档的指标，发现混合检索的文档级表现与上下文表示相当，说明它能找到相关文档，但段落排序表现差，说明它在段落级区分能力不足。</p><p>2.为什么在Genomics上上下文表示结果变差</p><p>计算了加/不加标题的文档与query的Jaccard相似度，只有Genomics加标题后值减小。说明添加标题引入了更多不相关的内容，帮倒忙。</p><blockquote><p>Jaccard 相似度公式
$\text{Jaccard}(A, B) = \frac{|A \cap B|}{|A \cup B|}$</p><ul><li>$A $ 和$B $：两个文本的词集合（或更广义的集合）。</li><li>$|A \cap B|$: A 和 B 中**共同词（交集）**的数量。</li><li>$|A \cup B| $: A 和 B 中**所有唯一词（并集）**的数量。</li></ul><p><strong>取值范围</strong> $[0, 1]$（0 表示无重叠，1 表示完全一致）。</p><p><strong>优点</strong>：</p><ul><li>简单直观，适用于短文本或集合型数据</li><li>不依赖词序或语义（仅统计词重叠）</li></ul><p><strong>缺点</strong>：</p><ul><li><strong>忽略语义</strong>：同义词（如“电脑”和“计算机”）会被视为不同词。</li><li><strong>敏感于词频</strong>：未考虑词的重要性（如TF-IDF），可以给词添加权重作为改进。</li><li><strong>长文本效果差</strong>：并集会急剧增大，导致相似度被低估。</li></ul></blockquote><p>3.错误分析</p><p>在两种融合检索、三种上下文化的方法下，多跳推理MHR最难解决，缩写最易解决。使用共指消解不如直接添加标题，因为标题往往含有核心词，而共指消解多次在段落中插入内容，反而干扰了匹配</p><p>该文章中了ACL2024。在连接上下文方面使用的方法比较淳朴。主要是定义了NQ-Hard数据集，并在5个数据集、原始方法+2个混合检索+3个上下文检索上做了一系列实验，并很好的解释了现象。</p><hr><h2 id=复现>复现<a hidden class=anchor aria-hidden=true href=#复现>#</a></h2><p>把README里的loaddata和evaluation的代码复制到dapr根目录load.py和eval.py下</p><p>pip install -r requirements.txt</p><p>有setup.py，在根目录下python setup.py build python setup.py install 解决module&rsquo;dapr&rsquo; not found</p><p>sudo apt-get update</p><h3 id=conditionalqa数据集>ConditionalQA数据集<a hidden class=anchor aria-hidden=true href=#conditionalqa数据集>#</a></h3><p>ConditionalQA给定提问者特定情况下的情景，回答与英国政策相关的问题。每个问答实例都标注了来自英国政府政策网页的证据。我们将原始数据集中的所有此类网页作为语料库。每个网页最初被解析为HTML标签，我们将其视为段落，移除HTML标签，仅保留纯自然语言。对于每个问答实例，我们将情景和问题连接起来形成一个查询，并将相应的证据视为黄金相关段落。</p><p>预处理后的train</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;query&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;id&#34;</span><span class=p>:</span> <span class=s2>&#34;train-0&#34;</span><span class=p>,</span>  <span class=c1>//train条目编号
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nt>&#34;text&#34;</span><span class=p>:</span> <span class=s2>&#34;My father, who was a widower and the owner of several large properties in Wales, died recently and apparently intestate. My paternal uncle is applying for probate, but I believe that I have a stronger claim. Do I have a greater right to probate in respect of my late father&#39;s estate?&#34;</span>
</span></span><span class=line><span class=cl>  <span class=p>},</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;judged_chunks&#34;</span><span class=p>:</span> <span class=p>[</span>  <span class=c1>//判断点，一个问题可能有多个黄金段落
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;chunk&#34;</span><span class=p>:</span> <span class=p>{</span>  
</span></span><span class=line><span class=cl>        <span class=nt>&#34;id&#34;</span><span class=p>:</span> <span class=s2>&#34;74-24&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=nt>&#34;text&#34;</span><span class=p>:</span> <span class=s2>&#34;&lt;p&gt;You can apply to become the estate’s administrator if you are 18 or over and you are the most ‘entitled’ inheritor of the deceased’s estate. This is usually the deceased’s closest living relative.&lt;/p&gt;&#34;</span>
</span></span><span class=line><span class=cl>      <span class=p>},</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;judgement&#34;</span><span class=p>:</span> <span class=mi>1</span><span class=p>,</span>   <span class=c1>//都为1
</span></span></span><span class=line><span class=cl><span class=c1></span>      <span class=nt>&#34;belonging_doc&#34;</span><span class=p>:</span> <span class=p>{</span>  <span class=c1>//每个chunk都把&#34;belonging_doc&#34;详细写了一遍，导致文件很大
</span></span></span><span class=line><span class=cl><span class=c1></span>        <span class=nt>&#34;id&#34;</span><span class=p>:</span> <span class=s2>&#34;74&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=nt>&#34;title&#34;</span><span class=p>:</span> <span class=s2>&#34;Applying for probate&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=nt>&#34;chunks&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>          <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=nt>&#34;id&#34;</span><span class=p>:</span> <span class=s2>&#34;74-0&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=nt>&#34;text&#34;</span><span class=p>:</span> <span class=s2>&#34;Overview&#34;</span>
</span></span><span class=line><span class=cl>          <span class=p>},</span>
</span></span><span class=line><span class=cl>          <span class=err>...</span>
</span></span><span class=line><span class=cl>          <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=nt>&#34;id&#34;</span><span class=p>:</span> <span class=s2>&#34;74-138&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=nt>&#34;text&#34;</span><span class=p>:</span> <span class=s2>&#34;Once you have probate you can start dealing with the estate.&#34;</span>
</span></span><span class=line><span class=cl>          <span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=nt>&#34;candidate_chunk_ids&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>          <span class=s2>&#34;74-5&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>          <span class=err>...</span>
</span></span><span class=line><span class=cl>          <span class=s2>&#34;74-51&#34;</span>
</span></span><span class=line><span class=cl>        <span class=p>]</span>
</span></span><span class=line><span class=cl>      <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=err>...</span>
</span></span><span class=line><span class=cl>  <span class=p>]</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>预处理后的test</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;query&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;id&#34;</span><span class=p>:</span> <span class=s2>&#34;dev-0&#34;</span><span class=p>,</span>  <span class=c1>//问题编号
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nt>&#34;text&#34;</span><span class=p>:</span> <span class=s2>&#34;My brother and his wife are in prison for carrying out a large fraud scheme. Their 7 and 8 year old children have been living with me for the last 4 years. I want to become their Special Guardian to look after them permanently How long will it be before I hear back from the court?&#34;</span>
</span></span><span class=line><span class=cl>  <span class=p>},</span>  <span class=c1>//具体问题
</span></span></span><span class=line><span class=cl><span class=c1></span>  <span class=nt>&#34;judged_chunks&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;chunk&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nt>&#34;id&#34;</span><span class=p>:</span> <span class=s2>&#34;86-41&#34;</span><span class=p>,</span> <span class=c1>//黄金匹配段落
</span></span></span><span class=line><span class=cl><span class=c1></span>        <span class=nt>&#34;text&#34;</span><span class=p>:</span> <span class=s2>&#34;&lt;p&gt;Within 10 days of receiving your application the court will send you a case number and a date for a meeting to set out:&lt;/p&gt;&#34;</span>
</span></span><span class=line><span class=cl>      <span class=p>},</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;judgement&#34;</span><span class=p>:</span> <span class=mi>1</span><span class=p>,</span>  <span class=c1>//不知道什么意思，取值应该全部为1
</span></span></span><span class=line><span class=cl><span class=c1></span>      <span class=nt>&#34;belonging_doc&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nt>&#34;id&#34;</span><span class=p>:</span> <span class=s2>&#34;86&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=nt>&#34;title&#34;</span><span class=p>:</span> <span class=s2>&#34;Become a special guardian&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=nt>&#34;chunks&#34;</span><span class=p>:</span> <span class=p>[</span> <span class=c1>//chunks是该问题相关的法条界面的文本分割后的结果。一段话设置为一个chunk
</span></span></span><span class=line><span class=cl><span class=c1></span>          <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=nt>&#34;id&#34;</span><span class=p>:</span> <span class=s2>&#34;86-0&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=nt>&#34;text&#34;</span><span class=p>:</span> <span class=s2>&#34;What is a special guardian&#34;</span>
</span></span><span class=line><span class=cl>          <span class=p>},</span>
</span></span><span class=line><span class=cl>          <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=nt>&#34;id&#34;</span><span class=p>:</span> <span class=s2>&#34;86-1&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=nt>&#34;text&#34;</span><span class=p>:</span> <span class=s2>&#34;You can apply to be a child’s special guardian when they cannot live with their birth parents and adoption is not right for them.&#34;</span>
</span></span><span class=line><span class=cl>          <span class=p>},</span>
</span></span><span class=line><span class=cl>          <span class=err>...</span>
</span></span><span class=line><span class=cl>          <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=nt>&#34;id&#34;</span><span class=p>:</span> <span class=s2>&#34;86-62&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=nt>&#34;text&#34;</span><span class=p>:</span> <span class=s2>&#34;You might be able to get a special guardian allowance from the children’s services department of your local council.&#34;</span>
</span></span><span class=line><span class=cl>          <span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=nt>&#34;candidate_chunk_ids&#34;</span><span class=p>:</span> <span class=p>[</span> <span class=c1>//把chunkid重新排了一遍，不知道按照什么要求排的
</span></span></span><span class=line><span class=cl><span class=c1></span>          <span class=s2>&#34;86-6&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>          <span class=s2>&#34;86-52&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>          <span class=err>...</span>
</span></span><span class=line><span class=cl>          <span class=s2>&#34;86-57&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>          <span class=s2>&#34;86-14&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>          <span class=s2>&#34;86-2&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>          <span class=s2>&#34;86-16&#34;</span>
</span></span><span class=line><span class=cl>        <span class=p>]</span>
</span></span><span class=line><span class=cl>      <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>  <span class=p>]</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><link href="https://fonts.googleapis.com/css2?family=Noto+Sans+SC:wght@400;700&family=JetBrains+Mono&display=swap" rel=stylesheet><footer class=footer><span>&copy; 2025 <a href=https://Rook1eChan.github.io/>Chan's Blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>