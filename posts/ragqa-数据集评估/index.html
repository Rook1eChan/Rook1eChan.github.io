<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><link href="https://fonts.googleapis.com/css2?family=Noto+Sans+SC:wght@400;700&family=JetBrains+Mono&display=swap" rel=stylesheet><meta name=robots content="index, follow"><title>RAG,QA相关数据集及评价标准 | Chan's Blog</title><meta name=keywords content><meta name=description content="
RAG，QA常用的数据集和评价标准
多为知识密集型、问答型数据集
数据集
1.UltraDomain
lightrag曾使用
使用MemoRAG提出的Benchmark。
在UltraDomain里，包含多个领域的数据，每个数据包括多本书。以cs为例，共含有100本书和100个对应的问题。该领域专注于计算机科学，涵盖数据科学和软件工程的关键领域。它特别强调机器学习和大数据处理，内容涉及推荐系统、分类算法以及使用Spark进行实时分析。：
{
	input: How does Spark Streaming enable real-time data processing?
	answers: ['Spark Streaming extends ...... ']
  	context: &#34;Whole Book......&#34;
	length: 131651
	context_id: 7bcef8714a477fd61fc8fb0d499b2cc3
	_id: b2fd8d9c6d1499d521d778ce3d6d06fa
	label: cs
	meta: {'title': 'Machine Learning With Spark', 'authors': 'Nick Pentreath'}
}
数据集地址：TommyChien/UltraDomain · Datasets at Hugging Face
Lightrag使用LLM生成问题-答案对
生成问题的方法来自于From Local to Global: A Graph RAG Approach to Query-Focused Summarization
提供文本，让大模型生成K个使用该数据集的用户身份（比如数据集是财经新闻，user就可能是收集金融市场趋势的财经记者），对于每个用户再生成N个任务，每个用户-任务提出M个高层次问题（理解整个数据集、无需提取具体事实）
 User: A tech journalist looking for insights and trends in the tech industry
 Task: Understanding how tech leaders view the role of policy and regulation
 Questions:
 1. Which episodes deal primarily with tech policy and government regulation?
 2. How do guests perceive the impact of privacy laws on technology development?
 3. Do any guests discuss the balance between innovation and ethical considerations?
 4. What are the suggested changes to current policies mentioned by the guests?
 5. Are collaborations between tech companies and governments discussed and how?

2.DAPR使用的数据集
MS MARCO、Natural Questions、MIRACL、Genomics 和 ConditionalQA"><meta name=author content><link rel=canonical href=https://Rook1eChan.github.io/posts/ragqa-%E6%95%B0%E6%8D%AE%E9%9B%86%E8%AF%84%E4%BC%B0/><link crossorigin=anonymous href=/assets/css/stylesheet.7f5d6d31e606c3178e091cb55298baed021a501ad4c10fd725847674935b1b15.css integrity="sha256-f11tMeYGwxeOCRy1Upi67QIaUBrUwQ/XJYR2dJNbGxU=" rel="preload stylesheet" as=style><link rel=icon href=https://Rook1eChan.github.io/apple-touch-icon.png><link rel=icon type=image/png sizes=16x16 href=https://Rook1eChan.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://Rook1eChan.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://Rook1eChan.github.io/apple-touch-icon.png><link rel=mask-icon href=https://Rook1eChan.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://Rook1eChan.github.io/posts/ragqa-%E6%95%B0%E6%8D%AE%E9%9B%86%E8%AF%84%E4%BC%B0/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://Rook1eChan.github.io/posts/ragqa-%E6%95%B0%E6%8D%AE%E9%9B%86%E8%AF%84%E4%BC%B0/"><meta property="og:site_name" content="Chan's Blog"><meta property="og:title" content="RAG,QA相关数据集及评价标准"><meta property="og:description" content=" RAG，QA常用的数据集和评价标准 多为知识密集型、问答型数据集
数据集 1.UltraDomain lightrag曾使用
使用MemoRAG提出的Benchmark。
在UltraDomain里，包含多个领域的数据，每个数据包括多本书。以cs为例，共含有100本书和100个对应的问题。该领域专注于计算机科学，涵盖数据科学和软件工程的关键领域。它特别强调机器学习和大数据处理，内容涉及推荐系统、分类算法以及使用Spark进行实时分析。：
{ input: How does Spark Streaming enable real-time data processing? answers: ['Spark Streaming extends ...... '] context: &#34;Whole Book......&#34; length: 131651 context_id: 7bcef8714a477fd61fc8fb0d499b2cc3 _id: b2fd8d9c6d1499d521d778ce3d6d06fa label: cs meta: {'title': 'Machine Learning With Spark', 'authors': 'Nick Pentreath'} } 数据集地址：TommyChien/UltraDomain · Datasets at Hugging Face
Lightrag使用LLM生成问题-答案对
生成问题的方法来自于From Local to Global: A Graph RAG Approach to Query-Focused Summarization
提供文本，让大模型生成K个使用该数据集的用户身份（比如数据集是财经新闻，user就可能是收集金融市场趋势的财经记者），对于每个用户再生成N个任务，每个用户-任务提出M个高层次问题（理解整个数据集、无需提取具体事实）
User: A tech journalist looking for insights and trends in the tech industry Task: Understanding how tech leaders view the role of policy and regulation Questions: 1. Which episodes deal primarily with tech policy and government regulation? 2. How do guests perceive the impact of privacy laws on technology development? 3. Do any guests discuss the balance between innovation and ethical considerations? 4. What are the suggested changes to current policies mentioned by the guests? 5. Are collaborations between tech companies and governments discussed and how? 2.DAPR使用的数据集 MS MARCO、Natural Questions、MIRACL、Genomics 和 ConditionalQA"><meta property="og:locale" content="zh-CN"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-05-04T09:12:03+08:00"><meta property="article:modified_time" content="2025-05-04T09:12:03+08:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="RAG,QA相关数据集及评价标准"><meta name=twitter:description content="
RAG，QA常用的数据集和评价标准
多为知识密集型、问答型数据集
数据集
1.UltraDomain
lightrag曾使用
使用MemoRAG提出的Benchmark。
在UltraDomain里，包含多个领域的数据，每个数据包括多本书。以cs为例，共含有100本书和100个对应的问题。该领域专注于计算机科学，涵盖数据科学和软件工程的关键领域。它特别强调机器学习和大数据处理，内容涉及推荐系统、分类算法以及使用Spark进行实时分析。：
{
	input: How does Spark Streaming enable real-time data processing?
	answers: ['Spark Streaming extends ...... ']
  	context: &#34;Whole Book......&#34;
	length: 131651
	context_id: 7bcef8714a477fd61fc8fb0d499b2cc3
	_id: b2fd8d9c6d1499d521d778ce3d6d06fa
	label: cs
	meta: {'title': 'Machine Learning With Spark', 'authors': 'Nick Pentreath'}
}
数据集地址：TommyChien/UltraDomain · Datasets at Hugging Face
Lightrag使用LLM生成问题-答案对
生成问题的方法来自于From Local to Global: A Graph RAG Approach to Query-Focused Summarization
提供文本，让大模型生成K个使用该数据集的用户身份（比如数据集是财经新闻，user就可能是收集金融市场趋势的财经记者），对于每个用户再生成N个任务，每个用户-任务提出M个高层次问题（理解整个数据集、无需提取具体事实）
 User: A tech journalist looking for insights and trends in the tech industry
 Task: Understanding how tech leaders view the role of policy and regulation
 Questions:
 1. Which episodes deal primarily with tech policy and government regulation?
 2. How do guests perceive the impact of privacy laws on technology development?
 3. Do any guests discuss the balance between innovation and ethical considerations?
 4. What are the suggested changes to current policies mentioned by the guests?
 5. Are collaborations between tech companies and governments discussed and how?

2.DAPR使用的数据集
MS MARCO、Natural Questions、MIRACL、Genomics 和 ConditionalQA"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://Rook1eChan.github.io/posts/"},{"@type":"ListItem","position":2,"name":"RAG,QA相关数据集及评价标准","item":"https://Rook1eChan.github.io/posts/ragqa-%E6%95%B0%E6%8D%AE%E9%9B%86%E8%AF%84%E4%BC%B0/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"RAG,QA相关数据集及评价标准","name":"RAG,QA相关数据集及评价标准","description":" RAG，QA常用的数据集和评价标准 多为知识密集型、问答型数据集\n数据集 1.UltraDomain lightrag曾使用\n使用MemoRAG提出的Benchmark。\n在UltraDomain里，包含多个领域的数据，每个数据包括多本书。以cs为例，共含有100本书和100个对应的问题。该领域专注于计算机科学，涵盖数据科学和软件工程的关键领域。它特别强调机器学习和大数据处理，内容涉及推荐系统、分类算法以及使用Spark进行实时分析。：\n{ input: How does Spark Streaming enable real-time data processing? answers: [\u0026#39;Spark Streaming extends ...... \u0026#39;] context: \u0026#34;Whole Book......\u0026#34; length: 131651 context_id: 7bcef8714a477fd61fc8fb0d499b2cc3 _id: b2fd8d9c6d1499d521d778ce3d6d06fa label: cs meta: {\u0026#39;title\u0026#39;: \u0026#39;Machine Learning With Spark\u0026#39;, \u0026#39;authors\u0026#39;: \u0026#39;Nick Pentreath\u0026#39;} } 数据集地址：TommyChien/UltraDomain · Datasets at Hugging Face\nLightrag使用LLM生成问题-答案对\n生成问题的方法来自于From Local to Global: A Graph RAG Approach to Query-Focused Summarization\n提供文本，让大模型生成K个使用该数据集的用户身份（比如数据集是财经新闻，user就可能是收集金融市场趋势的财经记者），对于每个用户再生成N个任务，每个用户-任务提出M个高层次问题（理解整个数据集、无需提取具体事实）\nUser: A tech journalist looking for insights and trends in the tech industry Task: Understanding how tech leaders view the role of policy and regulation Questions: 1. Which episodes deal primarily with tech policy and government regulation? 2. How do guests perceive the impact of privacy laws on technology development? 3. Do any guests discuss the balance between innovation and ethical considerations? 4. What are the suggested changes to current policies mentioned by the guests? 5. Are collaborations between tech companies and governments discussed and how? 2.DAPR使用的数据集 MS MARCO、Natural Questions、MIRACL、Genomics 和 ConditionalQA\n","keywords":[],"articleBody":" RAG，QA常用的数据集和评价标准 多为知识密集型、问答型数据集\n数据集 1.UltraDomain lightrag曾使用\n使用MemoRAG提出的Benchmark。\n在UltraDomain里，包含多个领域的数据，每个数据包括多本书。以cs为例，共含有100本书和100个对应的问题。该领域专注于计算机科学，涵盖数据科学和软件工程的关键领域。它特别强调机器学习和大数据处理，内容涉及推荐系统、分类算法以及使用Spark进行实时分析。：\n{ input: How does Spark Streaming enable real-time data processing? answers: ['Spark Streaming extends ...... '] context: \"Whole Book......\" length: 131651 context_id: 7bcef8714a477fd61fc8fb0d499b2cc3 _id: b2fd8d9c6d1499d521d778ce3d6d06fa label: cs meta: {'title': 'Machine Learning With Spark', 'authors': 'Nick Pentreath'} } 数据集地址：TommyChien/UltraDomain · Datasets at Hugging Face\nLightrag使用LLM生成问题-答案对\n生成问题的方法来自于From Local to Global: A Graph RAG Approach to Query-Focused Summarization\n提供文本，让大模型生成K个使用该数据集的用户身份（比如数据集是财经新闻，user就可能是收集金融市场趋势的财经记者），对于每个用户再生成N个任务，每个用户-任务提出M个高层次问题（理解整个数据集、无需提取具体事实）\nUser: A tech journalist looking for insights and trends in the tech industry Task: Understanding how tech leaders view the role of policy and regulation Questions: 1. Which episodes deal primarily with tech policy and government regulation? 2. How do guests perceive the impact of privacy laws on technology development? 3. Do any guests discuss the balance between innovation and ethical considerations? 4. What are the suggested changes to current policies mentioned by the guests? 5. Are collaborations between tech companies and governments discussed and how? 2.DAPR使用的数据集 MS MARCO、Natural Questions、MIRACL、Genomics 和 ConditionalQA\n3.HotpotQA 含有train（easy、medium、hard），test（distractor、full Wiki）\nDistractor：每个问题会提供 10 篇备选篇章，其中包含 2 段与问题答案相关的段落，8 段不相关的段落，这 10 篇文章限定了模型寻找答案的范围，相对较小。 Full Wiki：Full Wiki 属于开放域问答任务，模型需要从整个维基百科文档中抽取文档，然后再从文档中提取段落，最后从段落中抽取答案，数据范围是整个维基百科，范围要大得多，这使得任务更具挑战性。（实际上也是10篇文章，每篇的段落也没比distractor长多少）\n1.hotpot_train_v1.1.json\n总问题数量: 90447 问题类型分布: - comparison: 17456 (19.3%) - bridge: 72991 (80.7%) 难度分布: - medium: 56814 (62.8%) - hard: 15661 (17.3%) - easy: 17972 (19.9%) 问题长度分布: - 0-10: 0 (0.0%) - 11-20: 8 (0.0%) - 21-30: 96 (0.1%) - 31-40: 664 (0.7%) - 41-50: 3352 (3.7%) - 51-70: 18602 (20.6%) - 71-100: 31161 (34.5%) - 100+: 36564 (40.4%) 100左右最多 supporting_facts统计: - 几乎都是2，其次3、4，其他极少 context统计: - 几乎每个问题的上下文数量都在9-10 2.hotpot_dev_distractor_v1.json\n{ \"_id\": \"5a8b57f25542995d1e6f1371\", # 问题编号 \"answer\": \"yes\", # 回答（简短） \"question\": \"Were Scott Derrickson and Ed Wood of the same nationality?\", # 问题 \"supporting_facts\": [ # 黄金段落所在文档的标题以及句子的编号 [\"Scott Derrickson\", 0], [\"Ed Wood\", 0] ], \"context\": [ # 相关的文档，文档内包含多个段落 [ \"Ed Wood (film)\", [ \"Ed Wood is a 1994 American biographical period comedy-drama film directed and produced by Tim Burton, and starring Johnny Depp as cult filmmaker Ed Wood.\", \" The film concerns the period in Wood's life when he made his best-known films as well as his relationship with actor Bela Lugosi, played by Martin Landau.\", \" Sarah Jessica Parker, Patricia Arquette, Jeffrey Jones, Lisa Marie, and Bill Murray are among the supporting cast.\" ] ], [ \"Scott Derrickson\", [ \"Scott Derrickson (born July 16, 1966) is an American director, screenwriter and producer.\", \" He lives in Los Angeles, California.\", \" He is best known for directing horror films such as \\\"Sinister\\\", \\\"The Exorcism of Emily Rose\\\", and \\\"Deliver Us From Evil\\\", as well as the 2016 Marvel Cinematic Universe installment, \\\"Doctor Strange.\\\"\" ] ] ], \"type\": \"comparison\", # 问题类型 \"level\": \"hard\" # 问题等级 } 总问题数量: 7405 问题类型分布: - comparison: 1487 (20.1%) - bridge: 5918 (79.9%) 难度分布: - hard: 7405 (100.0%) supporting_facts统计: - 几乎都是2，其次3、4，其他极少 - 平均每个问题的支持性事实数量: 2.43 - 最多支持性事实数量: 8 - 最少支持性事实数量: 2 context统计: - 10篇文章，2篇相关，8篇不相关 3.hotpot_dev_fullwiki_v1.json\n问题类型分布: - comparison: 1487 (20.1%) - bridge: 5918 (79.9%) 难度分布: - hard: 7405 (100.0%) 问题长度分布: - 0-10: 0 (0.0%) - 11-20: 0 (0.0%) - 21-30: 0 (0.0%) - 31-40: 49 (0.7%) - 41-50: 282 (3.8%) - 51-70: 1612 (21.8%) - 71-100: 2919 (39.4%) - 100+: 2543 (34.3%) supporting_facts数量分布: - 包含 2 个supporting_facts的问题: 4990 (67.4%) - 包含 3 个supporting_facts的问题: 1774 (24.0%) - 包含 5 个supporting_facts的问题: 80 (1.1%) - 包含 4 个supporting_facts的问题: 537 (7.3%) - 包含 7 个supporting_facts的问题: 9 (0.1%) - 包含 6 个supporting_facts的问题: 14 (0.2%) - 包含 8 个supporting_facts的问题: 1 (0.0%) context数量分布: - 10篇文章，属于是open-domain的开放域问答任务（没有人为设置负样本？） 4.2WikiMultiHopQA 论文链接： Constructing A Multi-hop QA Dataset for Comprehensive Evaluation of Reasoning Steps - ACL Anthology\ngithub repo地址： Alab-NII/2wikimultihop\n数据地址：https://www.dropbox.com/s/npidmtadreo6df2/data.zip\n类似hotpotqa\n{ \"_id\": \"str\", \"type\": [\t// 以下四种之一作为值。问题类型有：比较、推理、组合和桥接比较 \"compositional\", \"inference\", \"bridge_comparison\", \"comparison\" ], \"question\": \"str\", \"context\": [ //可组成corpus [ \"str(Title)\", // 文档标题 [ \"str(Sent)\", // 句子内容 \"str(Sent)\" // 句子内容 // ... ] ] // ... ], \"supporting_facts\": [ //黄金段落 [\"str(title)\", \"int(sent_id)\"] // 支持文档的标题和对应句子的序号（第几句） ], \"evidences\": [ [\"str(subject entity)\", \"str(relation)\", \"str(object entity)\"] // 列表，每个元素是一个包含[主体实体, 关系, 客体实体]的三元组,有几组`supporting_facts`就有几组这个 ], \"answer\": \"str\" } 5.Qasper NLP论文相关的问答\nhf地址：https://huggingface.co/datasets/allenai/qasper\n数据集地址：https://qasper-dataset.s3.us-west-2.amazonaws.com/qasper-train-dev-v0.3.tgz\n评价标准 1.Lightrag使用LLM评价 包括几个维度，和GraphRAG一致：\n• Comprehensiveness. How much detail does the answer provide to cover all aspects and details of the question?\n• Diversity. How varied and rich is the answer in providing different perspectives and insights on the question?\n• Empowerment. How well does the answer help the reader understand and make informed judgments about the topic?\n2.NDCG 一、NDCG是什么？ NDCG的全称是：Normalized Discounted Cumulative Gain(归一化折损累计增益)\n在搜索和推荐任务中，系统常返回一个item列表。如何衡量这个返回的列表是否优秀呢？\n例如，当我们检索【推荐排序】，网页返回了与推荐排序相关的链接列表。列表可能会是[A,B,C,G,D,E,F],也可能是[C,F,A,E,D]，现在问题来了，当系统返回这些列表时，怎么评价哪个列表更好？\n没错，NDCG就是用来评估排序结果的。搜索和推荐任务中比较常见。\n二、一点点来理解NDCG~ G-CG-DCG-NDCG\nGain: 表示一个列表中所有item的相关性分数。$rel(i)$表示$item(i)$相关性得分。$$Gain=rel(i)$$ Cumulative Gain: 表示对K个item的Gain进行累加。$CG_{k}=\\sum_{i=1}^{k}{rel(i)}$ CG只是单纯累加相关性，不考虑位置信息。 如果返回一个list_1=[A,B,C,D,E]，那list_1的CG为0.5+0.9+0.3+0.6+0.1=2.4\n如果返回一个list_2=[D,A,E,C,B]，那list_2的CG为0.6+0.5+0.1+0.3+0.9=2.4\n所以，顺序不影响CG得分。如果我们想评估不同顺序的影响，就需要使用另一个指标DCG来评估。\nDiscounted Cumulative Gain: 考虑排序顺序的因素，使得排名靠前的item增益更高，对排名靠后的item进行折损。 CG与顺序无关，而DCG评估了顺序的影响。DCG的思想是：list中item的顺序很重要，不同位置的贡献不同，一般来说，排在前面的item影响更大，排在后面的item影响较小。（例如一个返回的网页，肯定是排在前面的item会有更多人点击）。所以，相对CG来说，DCG使排在前面的item增加其影响，排在后面的item减弱其影响。\n$$DCG_{k}=\\sum_{i=1}^{k}{\\frac{rel(i)}{log_{2}(i+1)}}$$怎么实现这个思想呢？DCG在CG的基础上，给每个item的相关性比上log2(i+1)，i越大，log2(i+1)的值越大，相当于给每个item的相关性打个折扣，item越靠后，折扣越大。\n还是上面那个例子：\nlist_1=[A,B,C,D,E], 其对应计算如下：\ni rel(i) log(i+1) rel(i)/log(i+1) 1 = A 0.5 1 0.5 2 = B 0.9 1.59 0.57 3 = C 0.3 2 0.15 4 = D 0.6 2.32 0.26 5 = E 0.1 2.59 0.04 list_1的 DCG_1= 0.5+0.57+0.15+0.26+0.04=1.52\nlist_2=[D,A,E,C,B]，其对应计算如下：\ni rel(i) log(i+1) rel(i)/log(i+1) 1 = D 0.6 1 0.6 2 = A 0.5 1.59 0.31 3 = E 0.1 2 0.05 4 = C 0.3 2.32 0.13 5 = B 0.9 2.59 0.35 list_2的 DCG_2= 0.6+0.31+0.05+0.13+0.35=1.44\nDCG_1 \u003e DCG_2, 所以在这个例子里list_1优于list_2。\n到这里，我们可以知道，使用DCG方法就可以对不同的list进行评估，那为什么后面还有一个NDCG呢？\nNDCG(Normalized DCG): 归一化折损累计增益 在NDCG之前，先了解一些IDGC(ideal DCG)–理想的DCG，IDCG的依据是：是根据rel(i)降序排列，即排列到最好状态。算出最好排列的DCG，就是IDCG。\nIDCG=最好排列的DCG\n对于上述的例子，按照rel(i)进行降序排列的最好状态为list_best=[B,D,A,C,E]\ni rel(i) log(i+1) rel(i)/log(i+1) 1 = B 0.9 1 0.9 2 = D 0.6 1.59 0.38 3 = A 0.5 2 0.25 4 = C 0.3 2.32 0.13 5 = E 0.1 2.59 0.04 IDCG = list_best的DCG_best = 0.9+0.38+0.25+0.13+0.04=1.7 (理所当然，IDCG\u003eDCG_1和DCG_2)\n因为不同query的搜索结果有多有少，所以不同query的DCG值就没有办法来做对比。所以提出NDCG。\n$$NDCG=\\frac{DCG}{IDCG}$$所以NDGC使用DCG/IDCG来表示，这样的话，NDCG就是一个相对值，那么不同query之间就可以通过NDCG值进行比较评估。\n3.Precision 所有检索到的结果中，有多少是应该是被检索到的\n$$Precision=\\frac{正确的结果}{返回的结果}$$4.Recall 5.F1 ","wordCount":"847","inLanguage":"en","datePublished":"2025-05-04T09:12:03+08:00","dateModified":"2025-05-04T09:12:03+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://Rook1eChan.github.io/posts/ragqa-%E6%95%B0%E6%8D%AE%E9%9B%86%E8%AF%84%E4%BC%B0/"},"publisher":{"@type":"Organization","name":"Chan's Blog","logo":{"@type":"ImageObject","url":"https://Rook1eChan.github.io/apple-touch-icon.png"}}}</script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]]}}</script><script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://Rook1eChan.github.io/ accesskey=h title="Chan's Blog (Alt + H)"><img src=https://Rook1eChan.github.io/apple-touch-icon.png alt aria-label=logo height=35>Chan's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://Rook1eChan.github.io/search/ title="search (Alt + /)" accesskey=/><span>search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://Rook1eChan.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://Rook1eChan.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">RAG,QA相关数据集及评价标准</h1><div class=post-meta><span title='2025-05-04 09:12:03 +0800 +0800'>May 4, 2025</span></div></header><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#%e6%95%b0%e6%8d%ae%e9%9b%86 aria-label=数据集>数据集</a><ul><li><a href=#1ultradomain aria-label=1.UltraDomain>1.UltraDomain</a></li><li><a href=#2dapr%e4%bd%bf%e7%94%a8%e7%9a%84%e6%95%b0%e6%8d%ae%e9%9b%86 aria-label=2.DAPR使用的数据集>2.DAPR使用的数据集</a></li><li><a href=#3hotpotqa aria-label=3.HotpotQA>3.HotpotQA</a></li><li><a href=#42wikimultihopqa aria-label=4.2WikiMultiHopQA>4.2WikiMultiHopQA</a></li><li><a href=#5qasper aria-label=5.Qasper>5.Qasper</a></li></ul></li><li><a href=#%e8%af%84%e4%bb%b7%e6%a0%87%e5%87%86 aria-label=评价标准>评价标准</a><ul><li><a href=#1lightrag%e4%bd%bf%e7%94%a8llm%e8%af%84%e4%bb%b7 aria-label=1.Lightrag使用LLM评价>1.Lightrag使用LLM评价</a></li><li><a href=#2ndcg aria-label=2.NDCG>2.NDCG</a><ul><ul><ul><li><a href=#%e4%b8%80ndcg%e6%98%af%e4%bb%80%e4%b9%88 aria-label=一、NDCG是什么？>一、NDCG是什么？</a></li><li><a href=#%e4%ba%8c%e4%b8%80%e7%82%b9%e7%82%b9%e6%9d%a5%e7%90%86%e8%a7%a3ndcg aria-label=二、一点点来理解NDCG~>二、一点点来理解NDCG~</a></li></ul></ul></ul></li><li><a href=#3precision aria-label=3.Precision>3.Precision</a></li><li><a href=#4recall aria-label=4.Recall>4.Recall</a></li><li><a href=#5f1 aria-label=5.F1>5.F1</a></li></ul></li></ul></div></details></div></aside><script>let activeElement,elements;window.addEventListener("DOMContentLoaded",function(){checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),activeElement=elements[0];const t=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active")},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{activeElement=Array.from(elements).find(e=>{if(getOffsetTop(e)-window.pageYOffset>0&&getOffsetTop(e)-window.pageYOffset<window.innerHeight/2)return e})||activeElement,elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase();e===activeElement?document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active"):document.querySelector(`.inner ul li a[href="#${t}"]`).classList.remove("active")})},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><blockquote><p>RAG，QA常用的数据集和评价标准
多为知识密集型、问答型数据集</p></blockquote><h1 id=数据集>数据集<a hidden class=anchor aria-hidden=true href=#数据集>#</a></h1><h2 id=1ultradomain>1.UltraDomain<a hidden class=anchor aria-hidden=true href=#1ultradomain>#</a></h2><p>lightrag曾使用</p><p>使用<a href=https://arxiv.org/abs/2409.05591>MemoRAG</a>提出的Benchmark。</p><p>在UltraDomain里，包含多个领域的数据，每个数据包括多本书。以cs为例，共含有100本书和100个对应的问题。该领域专注于计算机科学，涵盖数据科学和软件工程的关键领域。它特别强调机器学习和大数据处理，内容涉及推荐系统、分类算法以及使用Spark进行实时分析。：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-gdscript3 data-lang=gdscript3><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>	<span class=n>input</span><span class=p>:</span> <span class=n>How</span> <span class=n>does</span> <span class=n>Spark</span> <span class=n>Streaming</span> <span class=n>enable</span> <span class=n>real</span><span class=o>-</span><span class=n>time</span> <span class=n>data</span> <span class=n>processing</span><span class=err>?</span>
</span></span><span class=line><span class=cl>	<span class=n>answers</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;Spark Streaming extends ...... &#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>  	<span class=n>context</span><span class=p>:</span> <span class=s2>&#34;Whole Book......&#34;</span>
</span></span><span class=line><span class=cl>	<span class=n>length</span><span class=p>:</span> <span class=mi>131651</span>
</span></span><span class=line><span class=cl>	<span class=n>context_id</span><span class=p>:</span> <span class=mi>7</span><span class=n>bcef8714a477fd61fc8fb0d499b2cc3</span>
</span></span><span class=line><span class=cl>	<span class=n>_id</span><span class=p>:</span> <span class=n>b2fd8d9c6d1499d521d778ce3d6d06fa</span>
</span></span><span class=line><span class=cl>	<span class=n>label</span><span class=p>:</span> <span class=n>cs</span>
</span></span><span class=line><span class=cl>	<span class=n>meta</span><span class=p>:</span> <span class=p>{</span><span class=s1>&#39;title&#39;</span><span class=p>:</span> <span class=s1>&#39;Machine Learning With Spark&#39;</span><span class=p>,</span> <span class=s1>&#39;authors&#39;</span><span class=p>:</span> <span class=s1>&#39;Nick Pentreath&#39;</span><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>数据集地址：<a href=https://huggingface.co/datasets/TommyChien/UltraDomain>TommyChien/UltraDomain · Datasets at Hugging Face</a></p><p>Lightrag使用LLM生成问题-答案对</p><p>生成问题的方法来自于<a href=https://arxiv.org/abs/2404.16130>From Local to Global: A Graph RAG Approach to Query-Focused Summarization</a></p><p>提供文本，让大模型生成K个使用该数据集的用户身份（比如数据集是财经新闻，user就可能是收集金融市场趋势的财经记者），对于每个用户再生成N个任务，每个用户-任务提出M个高层次问题（理解整个数据集、无需提取具体事实）</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl> User: A tech journalist looking for insights and trends in the tech industry
</span></span><span class=line><span class=cl> Task: Understanding how tech leaders view the role of policy and regulation
</span></span><span class=line><span class=cl> Questions:
</span></span><span class=line><span class=cl> 1. Which episodes deal primarily with tech policy and government regulation?
</span></span><span class=line><span class=cl> 2. How do guests perceive the impact of privacy laws on technology development?
</span></span><span class=line><span class=cl> 3. Do any guests discuss the balance between innovation and ethical considerations?
</span></span><span class=line><span class=cl> 4. What are the suggested changes to current policies mentioned by the guests?
</span></span><span class=line><span class=cl> 5. Are collaborations between tech companies and governments discussed and how?
</span></span></code></pre></div><br><h2 id=2dapr使用的数据集>2.DAPR使用的数据集<a hidden class=anchor aria-hidden=true href=#2dapr使用的数据集>#</a></h2><p>MS MARCO、Natural Questions、MIRACL、Genomics 和 ConditionalQA</p><br><h2 id=3hotpotqa>3.HotpotQA<a hidden class=anchor aria-hidden=true href=#3hotpotqa>#</a></h2><p>含有train（easy、medium、hard），test（distractor、full Wiki）</p><p>Distractor：每个问题会提供 10 篇备选篇章，其中包含 2 段与问题答案相关的段落，8 段不相关的段落，这 10 篇文章限定了模型寻找答案的范围，相对较小。
Full Wiki：Full Wiki 属于开放域问答任务，模型需要从整个维基百科文档中抽取文档，然后再从文档中提取段落，最后从段落中抽取答案，数据范围是整个维基百科，范围要大得多，这使得任务更具挑战性。（实际上也是10篇文章，每篇的段落也没比distractor长多少）</p><p>1.hotpot_train_v1.1.json</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>总问题数量: 90447
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>问题类型分布:
</span></span><span class=line><span class=cl>  - comparison: 17456 (19.3%)
</span></span><span class=line><span class=cl>  - bridge: 72991 (80.7%)
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>难度分布:
</span></span><span class=line><span class=cl>  - medium: 56814 (62.8%)
</span></span><span class=line><span class=cl>  - hard: 15661 (17.3%)
</span></span><span class=line><span class=cl>  - easy: 17972 (19.9%)
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>问题长度分布:
</span></span><span class=line><span class=cl>  - 0-10: 0 (0.0%)
</span></span><span class=line><span class=cl>  - 11-20: 8 (0.0%)
</span></span><span class=line><span class=cl>  - 21-30: 96 (0.1%)
</span></span><span class=line><span class=cl>  - 31-40: 664 (0.7%)
</span></span><span class=line><span class=cl>  - 41-50: 3352 (3.7%)
</span></span><span class=line><span class=cl>  - 51-70: 18602 (20.6%)
</span></span><span class=line><span class=cl>  - 71-100: 31161 (34.5%)
</span></span><span class=line><span class=cl>  - 100+: 36564 (40.4%) 100左右最多
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>supporting_facts统计:
</span></span><span class=line><span class=cl>  - 几乎都是2，其次3、4，其他极少
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>context统计:
</span></span><span class=line><span class=cl>  - 几乎每个问题的上下文数量都在9-10
</span></span></code></pre></div><p>2.hotpot_dev_distractor_v1.json</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;_id&#34;</span><span class=p>:</span> <span class=s2>&#34;5a8b57f25542995d1e6f1371&#34;</span><span class=p>,</span>  <span class=err>#</span> <span class=err>问题编号</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;answer&#34;</span><span class=p>:</span> <span class=s2>&#34;yes&#34;</span><span class=p>,</span>  <span class=err>#</span> <span class=err>回答（简短）</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;question&#34;</span><span class=p>:</span> <span class=s2>&#34;Were Scott Derrickson and Ed Wood of the same nationality?&#34;</span><span class=p>,</span>  <span class=err>#</span> <span class=err>问题</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;supporting_facts&#34;</span><span class=p>:</span> <span class=p>[</span>  <span class=err>#</span> <span class=err>黄金段落所在文档的标题以及句子的编号</span>
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=s2>&#34;Scott Derrickson&#34;</span><span class=p>,</span> <span class=mi>0</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=s2>&#34;Ed Wood&#34;</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>  <span class=p>],</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;context&#34;</span><span class=p>:</span> <span class=p>[</span>  <span class=err>#</span> <span class=err>相关的文档，文档内包含多个段落</span>
</span></span><span class=line><span class=cl>    <span class=p>[</span>
</span></span><span class=line><span class=cl>      <span class=s2>&#34;Ed Wood (film)&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;Ed Wood is a 1994 American biographical period comedy-drama film directed and produced by Tim Burton, and starring Johnny Depp as cult filmmaker Ed Wood.&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34; The film concerns the period in Wood&#39;s life when he made his best-known films as well as his relationship with actor Bela Lugosi, played by Martin Landau.&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34; Sarah Jessica Parker, Patricia Arquette, Jeffrey Jones, Lisa Marie, and Bill Murray are among the supporting cast.&#34;</span>
</span></span><span class=line><span class=cl>      <span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=p>[</span>
</span></span><span class=line><span class=cl>      <span class=s2>&#34;Scott Derrickson&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;Scott Derrickson (born July 16, 1966) is an American director, screenwriter and producer.&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34; He lives in Los Angeles, California.&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34; He is best known for directing horror films such as \&#34;Sinister\&#34;, \&#34;The Exorcism of Emily Rose\&#34;, and \&#34;Deliver Us From Evil\&#34;, as well as the 2016 Marvel Cinematic Universe installment, \&#34;Doctor Strange.\&#34;&#34;</span>
</span></span><span class=line><span class=cl>      <span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=p>]</span>
</span></span><span class=line><span class=cl>  <span class=p>],</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;comparison&#34;</span><span class=p>,</span>  <span class=err>#</span> <span class=err>问题类型</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;level&#34;</span><span class=p>:</span> <span class=s2>&#34;hard&#34;</span>  <span class=err>#</span> <span class=err>问题等级</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>总问题数量: 7405
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>问题类型分布:
</span></span><span class=line><span class=cl>  - comparison: 1487 (20.1%)
</span></span><span class=line><span class=cl>  - bridge: 5918 (79.9%)
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>难度分布:
</span></span><span class=line><span class=cl>  - hard: 7405 (100.0%)
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>supporting_facts统计:
</span></span><span class=line><span class=cl>  - 几乎都是2，其次3、4，其他极少
</span></span><span class=line><span class=cl>  - 平均每个问题的支持性事实数量: 2.43
</span></span><span class=line><span class=cl>  - 最多支持性事实数量: 8
</span></span><span class=line><span class=cl>  - 最少支持性事实数量: 2
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>context统计:
</span></span><span class=line><span class=cl>  - 10篇文章，2篇相关，8篇不相关
</span></span></code></pre></div><p>3.hotpot_dev_fullwiki_v1.json</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>问题类型分布:
</span></span><span class=line><span class=cl>  - comparison: 1487 (20.1%)
</span></span><span class=line><span class=cl>  - bridge: 5918 (79.9%)
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>难度分布:
</span></span><span class=line><span class=cl>  - hard: 7405 (100.0%)
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>问题长度分布:
</span></span><span class=line><span class=cl>  - 0-10: 0 (0.0%)
</span></span><span class=line><span class=cl>  - 11-20: 0 (0.0%)
</span></span><span class=line><span class=cl>  - 21-30: 0 (0.0%)
</span></span><span class=line><span class=cl>  - 31-40: 49 (0.7%)
</span></span><span class=line><span class=cl>  - 41-50: 282 (3.8%)
</span></span><span class=line><span class=cl>  - 51-70: 1612 (21.8%)
</span></span><span class=line><span class=cl>  - 71-100: 2919 (39.4%)
</span></span><span class=line><span class=cl>  - 100+: 2543 (34.3%)
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>supporting_facts数量分布:
</span></span><span class=line><span class=cl>  - 包含 2 个supporting_facts的问题: 4990 (67.4%)
</span></span><span class=line><span class=cl>  - 包含 3 个supporting_facts的问题: 1774 (24.0%)
</span></span><span class=line><span class=cl>  - 包含 5 个supporting_facts的问题: 80 (1.1%)
</span></span><span class=line><span class=cl>  - 包含 4 个supporting_facts的问题: 537 (7.3%)
</span></span><span class=line><span class=cl>  - 包含 7 个supporting_facts的问题: 9 (0.1%)
</span></span><span class=line><span class=cl>  - 包含 6 个supporting_facts的问题: 14 (0.2%)
</span></span><span class=line><span class=cl>  - 包含 8 个supporting_facts的问题: 1 (0.0%)
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>context数量分布:
</span></span><span class=line><span class=cl>  - 10篇文章，属于是open-domain的开放域问答任务（没有人为设置负样本？）
</span></span><span class=line><span class=cl> 
</span></span></code></pre></div><br><h2 id=42wikimultihopqa>4.2WikiMultiHopQA<a hidden class=anchor aria-hidden=true href=#42wikimultihopqa>#</a></h2><p>论文链接：<a href=https://aclanthology.org/2020.coling-main.580/> Constructing A Multi-hop QA Dataset for Comprehensive Evaluation of Reasoning Steps - ACL Anthology</a></p><p>github repo地址：<a href=https://github.com/Alab-NII/2wikimultihop> Alab-NII/2wikimultihop</a></p><p>数据地址：https://www.dropbox.com/s/npidmtadreo6df2/data.zip</p><p>类似hotpotqa</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl>  <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nt>&#34;_id&#34;</span><span class=p>:</span> <span class=s2>&#34;str&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=nt>&#34;type&#34;</span><span class=p>:</span> <span class=p>[</span>				 <span class=c1>// 以下四种之一作为值。问题类型有：比较、推理、组合和桥接比较
</span></span></span><span class=line><span class=cl><span class=c1></span>            <span class=s2>&#34;compositional&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;inference&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;bridge_comparison&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;comparison&#34;</span>
</span></span><span class=line><span class=cl>        <span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=nt>&#34;question&#34;</span><span class=p>:</span> <span class=s2>&#34;str&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=nt>&#34;context&#34;</span><span class=p>:</span> <span class=p>[</span>      <span class=c1>//可组成corpus
</span></span></span><span class=line><span class=cl><span class=c1></span>            <span class=p>[</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;str(Title)&#34;</span><span class=p>,</span> <span class=c1>// 文档标题
</span></span></span><span class=line><span class=cl><span class=c1></span>                <span class=p>[</span>
</span></span><span class=line><span class=cl>                    <span class=s2>&#34;str(Sent)&#34;</span><span class=p>,</span> <span class=c1>// 句子内容
</span></span></span><span class=line><span class=cl><span class=c1></span>                    <span class=s2>&#34;str(Sent)&#34;</span> <span class=c1>// 句子内容
</span></span></span><span class=line><span class=cl><span class=c1></span>                    <span class=c1>// ...
</span></span></span><span class=line><span class=cl><span class=c1></span>                <span class=p>]</span>
</span></span><span class=line><span class=cl>            <span class=p>]</span>
</span></span><span class=line><span class=cl>            <span class=c1>// ...
</span></span></span><span class=line><span class=cl><span class=c1></span>        <span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=nt>&#34;supporting_facts&#34;</span><span class=p>:</span> <span class=p>[</span>      <span class=c1>//黄金段落
</span></span></span><span class=line><span class=cl><span class=c1></span>            <span class=p>[</span><span class=s2>&#34;str(title)&#34;</span><span class=p>,</span> <span class=s2>&#34;int(sent_id)&#34;</span><span class=p>]</span>        <span class=c1>// 支持文档的标题和对应句子的序号（第几句）
</span></span></span><span class=line><span class=cl><span class=c1></span>        <span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=nt>&#34;evidences&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>			<span class=p>[</span><span class=s2>&#34;str(subject entity)&#34;</span><span class=p>,</span> <span class=s2>&#34;str(relation)&#34;</span><span class=p>,</span> <span class=s2>&#34;str(object entity)&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>            <span class=c1>// 列表，每个元素是一个包含[主体实体, 关系, 客体实体]的三元组,有几组`supporting_facts`就有几组这个
</span></span></span><span class=line><span class=cl><span class=c1></span>        <span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=nt>&#34;answer&#34;</span><span class=p>:</span> <span class=s2>&#34;str&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span></code></pre></div><br><h2 id=5qasper>5.Qasper<a hidden class=anchor aria-hidden=true href=#5qasper>#</a></h2><p>NLP论文相关的问答</p><p>hf地址：https://huggingface.co/datasets/allenai/qasper</p><p>数据集地址：https://qasper-dataset.s3.us-west-2.amazonaws.com/qasper-train-dev-v0.3.tgz</p><br><h1 id=评价标准>评价标准<a hidden class=anchor aria-hidden=true href=#评价标准>#</a></h1><h2 id=1lightrag使用llm评价>1.Lightrag使用LLM评价<a hidden class=anchor aria-hidden=true href=#1lightrag使用llm评价>#</a></h2><p>包括几个维度，和GraphRAG一致：</p><p>• Comprehensiveness. How much detail does the answer provide to cover all aspects and details of the question?</p><p>• Diversity. How varied and rich is the answer in providing different perspectives and insights on the question?</p><p>• Empowerment. How well does the answer help the reader understand and make informed judgments about the topic?</p><h2 id=2ndcg>2.NDCG<a hidden class=anchor aria-hidden=true href=#2ndcg>#</a></h2><h5 id=一ndcg是什么>一、NDCG是什么？<a hidden class=anchor aria-hidden=true href=#一ndcg是什么>#</a></h5><p>NDCG的全称是：<strong>Normalized Discounted Cumulative Gain(归一化折损累计增益)</strong></p><p>在搜索和推荐任务中，系统常返回一个item列表。如何衡量这个返回的列表是否优秀呢？</p><blockquote><p>例如，当我们检索【推荐排序】，网页返回了与推荐排序相关的链接列表。列表可能会是[A,B,C,G,D,E,F],也可能是[C,F,A,E,D]，现在问题来了，当系统返回这些列表时，怎么评价哪个列表更好？</p></blockquote><p>没错，<strong>NDCG就是用来评估排序结果的</strong>。搜索和推荐任务中比较常见。</p><br><h5 id=二一点点来理解ndcg>二、一点点来理解NDCG~<a hidden class=anchor aria-hidden=true href=#二一点点来理解ndcg>#</a></h5><p><strong>G-CG-DCG-NDCG</strong></p><ol><li><strong>Gain:</strong> 表示一个列表中所有item的相关性分数。$rel(i)$表示$item(i)$相关性得分。$$Gain=rel(i)$$</li><li><strong>Cumulative Gain:</strong> 表示对K个item的Gain进行累加。$CG_{k}=\sum_{i=1}^{k}{rel(i)}$ CG只是单纯累加相关性，不考虑位置信息。</li></ol><p>如果返回一个list_1=[A,B,C,D,E]，那list_1的CG为0.5+0.9+0.3+0.6+0.1=2.4</p><p>如果返回一个list_2=[D,A,E,C,B]，那list_2的CG为0.6+0.5+0.1+0.3+0.9=2.4</p><p>所以，顺序不影响CG得分。如果我们想评估不同顺序的影响，就需要使用另一个指标DCG来评估。</p><ol start=3><li><strong>Discounted Cumulative Gain:</strong> 考虑排序顺序的因素，使得排名靠前的item增益更高，对排名靠后的item进行折损。</li></ol><p>CG与顺序无关，而DCG评估了顺序的影响。DCG的思想是：list中item的顺序很重要，不同位置的贡献不同，一般来说，排在前面的item影响更大，排在后面的item影响较小。（例如一个返回的网页，肯定是排在前面的item会有更多人点击）。所以，相对CG来说，DCG使<strong>排在前面的item增加其影响，排在后面的item减弱其影响。</strong></p>$$DCG_{k}=\sum_{i=1}^{k}{\frac{rel(i)}{log_{2}(i+1)}}$$<p>怎么实现这个思想呢？DCG在CG的基础上，给每个item的相关性比上log2(i+1)，i越大，log2(i+1)的值越大，相当于给每个item的相关性打个折扣，item越靠后，折扣越大。</p><p>还是上面那个例子：</p><p><strong>list_1</strong>=[A,B,C,D,E], 其对应计算如下：</p><table><thead><tr><th>i</th><th>rel(i)</th><th>log(i+1)</th><th>rel(i)/log(i+1)</th></tr></thead><tbody><tr><td>1 = A</td><td>0.5</td><td>1</td><td>0.5</td></tr><tr><td>2 = B</td><td>0.9</td><td>1.59</td><td>0.57</td></tr><tr><td>3 = C</td><td>0.3</td><td>2</td><td>0.15</td></tr><tr><td>4 = D</td><td>0.6</td><td>2.32</td><td>0.26</td></tr><tr><td>5 = E</td><td>0.1</td><td>2.59</td><td>0.04</td></tr></tbody></table><p>list_1的 DCG_1= 0.5+0.57+0.15+0.26+0.04=1.52</p><p><strong>list_2</strong>=[D,A,E,C,B]，其对应计算如下：</p><table><thead><tr><th>i</th><th>rel(i)</th><th>log(i+1)</th><th>rel(i)/log(i+1)</th></tr></thead><tbody><tr><td>1 = D</td><td>0.6</td><td>1</td><td>0.6</td></tr><tr><td>2 = A</td><td>0.5</td><td>1.59</td><td>0.31</td></tr><tr><td>3 = E</td><td>0.1</td><td>2</td><td>0.05</td></tr><tr><td>4 = C</td><td>0.3</td><td>2.32</td><td>0.13</td></tr><tr><td>5 = B</td><td>0.9</td><td>2.59</td><td>0.35</td></tr></tbody></table><p>list_2的 DCG_2= 0.6+0.31+0.05+0.13+0.35=1.44</p><p>DCG_1 > DCG_2, 所以在这个例子里list_1优于list_2。</p><p>到这里，我们可以知道，使用DCG方法就可以对不同的list进行评估，那为什么后面还有一个NDCG呢？</p><ol start=4><li><strong>NDCG(Normalized DCG): 归一化折损累计增益</strong></li></ol><p>在NDCG之前，先了解一些IDGC(ideal DCG)&ndash;理想的DCG，IDCG的依据是：是根据rel(i)降序排列，即排列到最好状态。算出最好排列的DCG，就是IDCG。</p><p><strong>IDCG=最好排列的DCG</strong></p><p>对于上述的例子，按照rel(i)进行降序排列的最好状态为list_best=[B,D,A,C,E]</p><table><thead><tr><th>i</th><th>rel(i)</th><th>log(i+1)</th><th>rel(i)/log(i+1)</th></tr></thead><tbody><tr><td>1 = B</td><td>0.9</td><td>1</td><td>0.9</td></tr><tr><td>2 = D</td><td>0.6</td><td>1.59</td><td>0.38</td></tr><tr><td>3 = A</td><td>0.5</td><td>2</td><td>0.25</td></tr><tr><td>4 = C</td><td>0.3</td><td>2.32</td><td>0.13</td></tr><tr><td>5 = E</td><td>0.1</td><td>2.59</td><td>0.04</td></tr></tbody></table><p>IDCG = list_best的DCG_best = 0.9+0.38+0.25+0.13+0.04=1.7 (理所当然，IDCG>DCG_1和DCG_2)</p><p>因为不同query的搜索结果有多有少，所以不同query的DCG值就没有办法来做对比。所以提出NDCG。</p>$$NDCG=\frac{DCG}{IDCG}$$<p>所以NDGC使用DCG/IDCG来表示，这样的话，NDCG就是一个相对值，那么不同query之间就可以通过NDCG值进行比较评估。</p><br><h2 id=3precision>3.Precision<a hidden class=anchor aria-hidden=true href=#3precision>#</a></h2><p>所有检索到的结果中，有多少是应该是被检索到的</p>$$Precision=\frac{正确的结果}{返回的结果}$$<h2 id=4recall>4.Recall<a hidden class=anchor aria-hidden=true href=#4recall>#</a></h2><h2 id=5f1>5.F1<a hidden class=anchor aria-hidden=true href=#5f1>#</a></h2></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><link href="https://fonts.googleapis.com/css2?family=Noto+Sans+SC:wght@400;700&family=JetBrains+Mono&display=swap" rel=stylesheet><footer class=footer><span>&copy; 2025 <a href=https://Rook1eChan.github.io/>Chan's Blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>