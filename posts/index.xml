<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Posts on Chan's Blog</title><link>https://Rook1eChan.github.io/posts/</link><description>Recent content in Posts on Chan's Blog</description><generator>Hugo -- 0.147.2</generator><language>zh-CN</language><lastBuildDate>Wed, 07 May 2025 15:49:00 +0800</lastBuildDate><atom:link href="https://Rook1eChan.github.io/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>RAG 数据集及评价标准</title><link>https://Rook1eChan.github.io/posts/rag-datasetsevaluation/</link><pubDate>Sun, 04 May 2025 09:12:03 +0800</pubDate><guid>https://Rook1eChan.github.io/posts/rag-datasetsevaluation/</guid><description>&lt;blockquote>
&lt;p>1.使用LLM生成问题及答案&lt;/p>
&lt;p>2.使用标注数据集&lt;/p>&lt;/blockquote>
&lt;h3 id="1lightrag">1.LightRAG&lt;/h3>
&lt;h4 id="数据集">数据集&lt;/h4>
&lt;p>使用&lt;a href="https://arxiv.org/abs/2409.05591">MemoRAG&lt;/a>提出的Benchmark。&lt;/p>
&lt;p>在UltraDomain里，包含多个领域的数据，每个数据包括多本书。以cs为例，共含有100本书和100个对应的问题。该领域专注于计算机科学，涵盖数据科学和软件工程的关键领域。它特别强调机器学习和大数据处理，内容涉及推荐系统、分类算法以及使用Spark进行实时分析。：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-gdscript3" data-lang="gdscript3">&lt;span class="line">&lt;span class="cl">&lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">input&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">How&lt;/span> &lt;span class="n">does&lt;/span> &lt;span class="n">Spark&lt;/span> &lt;span class="n">Streaming&lt;/span> &lt;span class="n">enable&lt;/span> &lt;span class="n">real&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="n">time&lt;/span> &lt;span class="n">data&lt;/span> &lt;span class="n">processing&lt;/span>&lt;span class="err">?&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">answers&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="s1">&amp;#39;Spark Streaming extends ...... &amp;#39;&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">context&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;Whole Book......&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">length&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="mi">131651&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">context_id&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="n">bcef8714a477fd61fc8fb0d499b2cc3&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">_id&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">b2fd8d9c6d1499d521d778ce3d6d06fa&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">label&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">cs&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">meta&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">{&lt;/span>&lt;span class="s1">&amp;#39;title&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;Machine Learning With Spark&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;authors&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;Nick Pentreath&amp;#39;&lt;/span>&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>数据集地址：&lt;a href="https://huggingface.co/datasets/TommyChien/UltraDomain">TommyChien/UltraDomain · Datasets at Hugging Face&lt;/a>&lt;/p>
&lt;h4 id="问题生成">问题生成&lt;/h4>
&lt;p>生成问题的方法来自于&lt;a href="https://arxiv.org/abs/2404.16130">From Local to Global: A Graph RAG Approach to Query-Focused Summarization&lt;/a>&lt;/p>
&lt;p>提供文本，让大模型生成K个使用该数据集的用户身份（比如数据集是财经新闻，user就可能是收集金融市场趋势的财经记者），对于每个用户再生成N个任务，每个用户-任务提出M个高层次问题（理解整个数据集、无需提取具体事实）&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> User: A tech journalist looking for insights and trends in the tech industry
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Task: Understanding how tech leaders view the role of policy and regulation
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Questions:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 1. Which episodes deal primarily with tech policy and government regulation?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 2. How do guests perceive the impact of privacy laws on technology development?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 3. Do any guests discuss the balance between innovation and ethical considerations?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 4. What are the suggested changes to current policies mentioned by the guests?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 5. Are collaborations between tech companies and governments discussed and how?
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="评价标准">评价标准&lt;/h4>
&lt;p>不使用黄金标准答案，使用LLM评价。包括&lt;/p></description></item><item><title>RAGTruth: A Hallucination Corpus for Developing Trustworthy Retrieval-Augmented Language Models</title><link>https://Rook1eChan.github.io/posts/ragtruth/</link><pubDate>Wed, 07 May 2025 15:49:00 +0800</pubDate><guid>https://Rook1eChan.github.io/posts/ragtruth/</guid><description>&lt;h1 id="1motivation">1.Motivation&lt;/h1>
&lt;p>尽管有了RAG的帮助，LLM仍有可能给出与所提供知识不符的回答。因此需要构建一个数据集来检测幻觉。&lt;/p>
&lt;br>
&lt;h1 id="2contributions">2.Contributions&lt;/h1>
&lt;ol>
&lt;li>提出RAGTruth，一个大规模词级别的幻觉检测数据集，由LLM自然产生（作者认为故意触发的幻觉与自然产生的幻觉存在差异）&lt;/li>
&lt;li>对现有幻觉检测方法进行比较&lt;/li>
&lt;li>提出了微调LLM用于幻觉检测的基线。Llama-2-13B在RAGTruth training data上微调后比得上GPT4&lt;/li>
&lt;li>证明了使用微调得到的幻觉检测器，能降低幻觉&lt;/li>
&lt;/ol>
&lt;h1 id="3related-work">3.Related Work&lt;/h1>
&lt;h1 id="4methods">4.Methods&lt;/h1>
&lt;h2 id="1hallucination-taxonomy幻觉类型">1.Hallucination Taxonomy幻觉类型&lt;/h2>
&lt;p>本文将幻觉类型分为：&lt;/p>
&lt;ol>
&lt;li>&lt;strong>Evident Conflict明显冲突&lt;/strong>：与提供的文本明显相反，容易辨别，如事实错误、拼写错误、数字错误。&lt;/li>
&lt;li>&lt;strong>Subtle Conflict轻微冲突&lt;/strong>：生成的信息与提供的文本有歧义，比如术语的替换，需要结合上下文判断。&lt;/li>
&lt;li>&lt;strong>Evident Introduction of Baseless Information明显引入无根据知识&lt;/strong>：生成的内容不在提供的信息之内。&lt;/li>
&lt;li>&lt;strong>Subtle Introduction of Baseless Information轻微引入无根据知识&lt;/strong>：生成内容超出了提供的信息，比如主观的假设或推断。&lt;/li>
&lt;/ol>
&lt;h2 id="2response-generation回答生成">2.Response Generation回答生成&lt;/h2>
&lt;p>选择三个任务: Question Answering,Data-to-text Writing, and News Summarization.（问题回答、数据到文本的写作、新闻摘要），生成回答并人工标注幻觉部分。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Question Answering&lt;/strong>：从MS MARCO选择与生活相关的QA，每个问题保留三段提取内容，然后使用LLM根据内容回答问题。&lt;/li>
&lt;li>&lt;strong>Data-to-text Writing&lt;/strong>：从Yelp数据集选择有关商家的结构化信息和用户的评论，用LLM生成对商家的描述。如果数据出现空值而大模型将其解释为“假”，认为这是出现了幻觉。&lt;/li>
&lt;li>&lt;strong>News Summarization&lt;/strong>：数据来自CNN/Daily Mail dataset+某新闻平台的新闻，使用LLM对每篇内容生成摘要。&lt;/li>
&lt;/ul>
&lt;p>使用的LLM：GPT-3.5-turbo-0613、GPT-4-0613、Mistral-7b-Instruct、Llama-2-7B-chat、 Llama-2-13B-chat、 Llama-2-70B-chat&lt;/p>
&lt;p>每个任务都用6个模型跑一遍，得到6个回答。&lt;/p>
&lt;h2 id="5result">5.Result&lt;/h2>
&lt;p>各项任务中幻觉类型的比例：&lt;/p>
&lt;p>&lt;img alt="f2" loading="lazy" src="https://Rook1eChan.github.io/RAGTRUTH/f2.png">&lt;/p>
&lt;p>如图2所示，在上下文中无根据的信息生成显著多于与上下文冲突的信息生成，尤其是在问答任务中。在两大类无根据信息和冲突信息中，更严重的幻觉，即明显的无根据信息和明显的冲突信息，占据了相当大的比例。这一观察结果说明即使有RAG，还是存在严重幻觉。&lt;/p>
&lt;BR>
&lt;p>&lt;img alt="t2" loading="lazy" src="https://Rook1eChan.github.io/RAGTRUTH/t2.png">&lt;/p>
&lt;p>数据转文本的任务幻觉率最高，可能与JSON格式有关。另外，较新的新闻的幻觉率不比过时新闻高，可能是由于较新的新闻的文本长度较短。&lt;/p>
&lt;BR>
&lt;p>各模型出现幻觉的比例：&lt;/p>
&lt;p>（span、density什么意思）&lt;/p>
&lt;p>&lt;img alt="t2" loading="lazy" src="https://Rook1eChan.github.io/RAGTRUTH/t3.png">&lt;/p>
&lt;p>表3显示，在我们收集的数据中，OpenAI的两个模型表现出显著较低的幻觉率。具体来说，GPT-4-0613的幻觉频率最低。为了更清晰地比较不同模型的幻觉率，我们计算了每个模型在三个任务中的幻觉密度。幻觉密度定义为每一百个单词响应中平均出现的幻觉跨度数。在Llama2系列中，除了数据总文本写作任务外，模型规模与幻觉密度之间存在明显的负相关关系。尽管Mistral-7B-Instruct模型在各种基准和排行榜上的表现强劲（Zheng等人，2023），但它生成的包含幻觉的回答数量最多。&lt;/p>
&lt;BR>
&lt;p>幻觉与文本长度的关系：&lt;/p>
&lt;p>&lt;img alt="t2" loading="lazy" src="https://Rook1eChan.github.io/RAGTRUTH/t4.png">&lt;/p>
&lt;p>对于上下文长度（CLB），只有新闻摘要呈现出上下文越长，越容易幻觉的特点。&lt;/p>
&lt;p>对于回答长度（RLB），都有回答越长，越容易幻觉的特点。&lt;/p>
&lt;BR>
&lt;p>幻觉与位置的关系：&lt;/p>
&lt;p>在问答和新闻摘要任务中，幻觉更倾向于出现在回答的末尾。数据到文本写作任务在前半部分较易出现幻觉。&lt;/p></description></item><item><title>CDF-RAG: Causal Dynamic Feedback for Adaptive Retrieval-Augmented Generation</title><link>https://Rook1eChan.github.io/posts/cdf-rag-causal-dynamic-feedback-for-adaptive-retrieval-augmented-generation/</link><pubDate>Fri, 02 May 2025 23:17:00 +0800</pubDate><guid>https://Rook1eChan.github.io/posts/cdf-rag-causal-dynamic-feedback-for-adaptive-retrieval-augmented-generation/</guid><description>&lt;p>&lt;a href="https://arxiv.org/abs/2504.12560">CDF-RAG: Causal Dynamic Feedback for Adaptive Retrieval-Augmented Generation&lt;/a>&lt;/p>
&lt;p>只挂了arxiv，粗看，了解一下各模块的实现方式。&lt;/p>
&lt;h2 id="1motivation">1.Motivation&lt;/h2>
&lt;p>现有的RAG框架主要是静态检索，且依赖于语义相似性和关联性，这些方法优先考虑主题相关的文档，而并非提供解释或因果关系的文档。这导致响应结果是基于事实的，但是没能理解因果关系。&lt;/p>
&lt;p>此外，基于大规模观察语料库训练的语言模型倾向于建模共现模式而非因果依赖，这使得它们容易将相关性与因果关系混淆——尤其是在存在不完整或模糊证据的情况下。这些局限性在多跳检索中尤为明显。&lt;/p>
&lt;p>另外，用户的提问可能是模糊的，现有机制缺乏动态适应和因果机制。&lt;/p>
&lt;h2 id="2contributions">2.Contributions&lt;/h2>
&lt;p>本文提出了CDFRAG框架，将强化学习查询优化、多跳因果图检索和基于对齐的幻觉检测整合到一个推理循环中。&lt;/p>
&lt;p>证明了基于强化学习的查询重写显著提升了多跳因果推理和检索质量，优于先前的细化方法。&lt;/p>
&lt;p>本方法在四个数据集中均sota，在因果正确性、一致性和可解释性方面均有所改进。&lt;/p>
&lt;h2 id="3method">3.Method&lt;/h2>
&lt;h3 id="1构建因果知识图谱">1.构建因果知识图谱&lt;/h3>
&lt;p>使用UniCausal提取因果对（Causal，Effect）。经过GPT4验证后，编码为（C，E，Relation）并存入有向图G。&lt;/p>
&lt;h3 id="2根据强化学习进行查询重写">2.根据强化学习进行查询重写&lt;/h3>
&lt;p>给定用户初始查询q，重写q的过程是一个马尔可夫决策过程（MDP），有三种操作：&lt;/p>
&lt;ol>
&lt;li>扩展：添加相关的因果因素&lt;/li>
&lt;li>简化：去除多余的细节&lt;/li>
&lt;li>分解：复杂查询拆解为子查询&lt;/li>
&lt;/ol>
&lt;p>策略通过SFT微调生成，然后使用PPO优化。&lt;/p>
&lt;ol>
&lt;li>&lt;strong>监督微调（Supervised Fine-Tuning, SFT）&lt;/strong>&lt;/li>
&lt;/ol>
&lt;ul>
&lt;li>&lt;strong>目的&lt;/strong>：用标注的示范数据（如人工修正的样本）初始化策略 $$\pi_\theta(a|s)$$，使其初步具备期望的行为模式。&lt;/li>
&lt;li>&lt;strong>方法&lt;/strong>：通过最大化对数似然来微调模型参数，损失函数为：
$$L_{\text{SFT}} = -\sum_{t=1}^{T} \log P_\phi(y_t \mid y_{&lt;t}, x)$$
&lt;ul>
&lt;li>$$y_t$$ 是时间步 $$t$$ 的正确动作（或词元）。&lt;/li>
&lt;li>$$y_{&lt;t}$$ 表示历史信息（之前的动作或上下文）。&lt;/li>
&lt;li>$$x$$ 是输入状态（如提示或环境状态）。&lt;/li>
&lt;li>核心是让模型输出的概率分布贴近人工标注的数据。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;ol start="2">
&lt;li>&lt;strong>近端策略优化（Proximal Policy Optimization, PPO）&lt;/strong>&lt;/li>
&lt;/ol>
&lt;ul>
&lt;li>&lt;strong>目的&lt;/strong>：在SFT的基础上，通过与环境交互进一步优化策略，平衡探索与利用，同时避免训练不稳定。&lt;/li>
&lt;li>&lt;strong>损失函数&lt;/strong>：
$$L_{\text{PPO}}(\theta) = \mathbb{E}_t \left[ \min\left( \text{比率项} \cdot A_t, \text{截断后的比率项} \cdot A_t \right) \right]$$
&lt;ul>
&lt;li>&lt;strong>比率项&lt;/strong>：新策略与旧策略的概率比&lt;/li>
&lt;li>$$\frac{\pi_\theta(a|s)}{\pi_{\theta_{old}}(at|st)}$$，衡量策略变化程度。&lt;/li>
&lt;li>&lt;strong>优势函数 $$A_t$$&lt;/strong>：评估动作 $$a$$ 在状态 $$s$$ 下比平均表现好多少（由评论家模型或蒙特卡洛估计）。&lt;/li>
&lt;li>&lt;strong>截断机制&lt;/strong>：限制比率项在 $$[1-\epsilon, 1+\epsilon]$$ 之间，防止单步更新过大，确保训练稳定。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="3语义因果双路径检索">3.语义+因果双路径检索&lt;/h3>
&lt;p>使用MiniLM对优化后的查询进行编码，在向量数据库进行相似性搜索。（整句话编码的稠密检索）&lt;/p></description></item><item><title>DAPR A Benchmark on Document-Aware Passage Retrieval</title><link>https://Rook1eChan.github.io/posts/dapr-a-benchmark-on-document-aware-passage-retrieval/</link><pubDate>Fri, 02 May 2025 16:41:03 +0800</pubDate><guid>https://Rook1eChan.github.io/posts/dapr-a-benchmark-on-document-aware-passage-retrieval/</guid><description>&lt;h2 id="1motivation">1.Motivation&lt;/h2>
&lt;p>现有的神经检索（neural retrieval）的方法主要集中在短文本排序，在长篇文章中做检索效果并不好（由于自注意力机制token数量的限制；或者返回的文档过长，不便于用户使用）。另外，作者发现在先进检索器的检索错误中，半数错误与缺少上下文有关。&lt;/p>
&lt;p>比如：在A剧场中演出过的演员有哪些？如果只检索关键字“A剧场”，可能找不到答案，需要结合上下文找到“……在这里演出过……”的内容才是真正答案。&lt;/p>
&lt;p>因此，作者针对上下文强关联的任务建立了一个数据集，使用两类方法（hybrid retrieval with BM25、 contextualized passage representations）进行实验，并详细解释了实验结果。&lt;/p>
&lt;BR>
&lt;h2 id="2related-work">2.Related work&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>Document Question Answering（DocQA）&lt;/strong>：要求模型回答关于输入文档的问题，通常假设文档在提问前就已给出。本文提出的(Document-Awarepassage Retrieval, DAPR)与DocQA类似，区别在于DAPR希望用户提问时不知道目标文档，由模型来寻找目标文档。&lt;/li>
&lt;li>&lt;strong>Long-document retrieval（长文档检索）&lt;/strong>：对于长文档检索有一些简单的方法：将文档中段落相关性的最大值作为文档的相关性（MaxP）；仅编码文档中的第一个段落（FirstP）……与DAPR相比，所有这些先前的工作都没有研究如何在考虑文档上下文的情况下检索段落。&lt;/li>
&lt;li>&lt;strong>Hybrid retrieval（混合检索）&lt;/strong>：对于一个查询使用多个检索系统（常常是BM25+神经检索）
&lt;ul>
&lt;li>rank fusion（排名融合）——通过凸组合、互逆排名等方法将不同检索系统的个体排名合并为一个。&lt;/li>
&lt;li>hierarchical retrieval（层次检索）——首先检索文档，然后从这些文档中检索段落。只适用于段落本身足以对查询做出响应的情况。&lt;/li>
&lt;li>本文探讨了段落排名和文档排名结合的有效性。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>Relation to pre-training tasks（和预训练任务的关系）&lt;/strong>：有的研究在预训练中加入上下文。但推理时仍然只关注独立的段落。&lt;/li>
&lt;li>补充：
&lt;ul>
&lt;li>NQ：谷歌的一个问答数据集&lt;/li>
&lt;li>NDCG：评价检索序列的相关性和位置&lt;/li>
&lt;li>共指信息：描述文本中不同表达式指向同一实体或概念的语言现象，如*“玛丽打开了门，&lt;strong>她&lt;/strong>随后拿起包。”* → “她”与“玛丽”共指同一人。&lt;/li>
&lt;li>共指消解（Coreference Resolution）：自动识别文本中所有指向同一实体的表达式并分组。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;BR>
&lt;h2 id="3method">3.Method&lt;/h2>
&lt;p>DAPR任务要求系统提取+排序。给出段落集合$C$，文档集合$D$，对于查询集合$q \in Q$，检索系统$s$应该提取出最好的$K$个段落集合$R$。&lt;/p>
&lt;h3 id="31nq-hard">3.1NQ-Hard&lt;/h3>
&lt;p>对SOTA的检索器（DRAGON+,SPLADEv2, and ColBERTv2)使用NQ数据集，发现一半的错误来自于不了解上下文。将这些数据命名为&lt;strong>NQ-hard&lt;/strong>，并分为4类：&lt;/p>
&lt;ol>
&lt;li>共指消解（CR）：关键的共指信息需要通过特定文档上下文来解析；&lt;/li>
&lt;li>主要主题（MT）：只有了解文档的背景主题（通常是标题），才能回答查询；&lt;/li>
&lt;li>多跳推理（MHR）：连接查询和查询相关段落中的实体的推理路径包括文档上下文中的其他节点；&lt;/li>
&lt;li>缩写（AC）：在相关段落（或查询）中出现一个缩写，该缩写对应于查询（或相关段落）中的全称，文档上下文解释了这种映射；&lt;/li>
&lt;/ol>
&lt;p>&lt;img alt="nqques" loading="lazy" src="https://Rook1eChan.github.io/DAPR/NQques.png">&lt;/p>
&lt;BR>
&lt;h3 id="32datasets">3.2Datasets&lt;/h3>
&lt;p>MS MARCO、Natural Questions、MIRACL、Genomics 和 ConditionalQA（具体处理方式见附录A）&lt;/p>
&lt;BR>
&lt;h3 id="33evaluation">3.3Evaluation&lt;/h3>
&lt;p>使用&lt;strong>nDCG@10&lt;/strong>和recall@100做指标。&lt;/p>
&lt;p>将binary/3-scale转换为0-1/0-1-2，然后使用pytrec_eval计算指标。&lt;/p>
&lt;p>考虑到现实世界中的检索系统多用于零样本、跨领域的情景，本文进行了一项测试：在MS MARCO训练集训练，然后在MS MARCO测试集测试，作为域内评估；在其它四个数据集上测试，作为域外评估。&lt;/p>
&lt;BR>
&lt;h2 id="4experiments">4.Experiments&lt;/h2>
&lt;h3 id="41基础检索器">4.1基础检索器&lt;/h3>
&lt;ul>
&lt;li>BM25（使用PySerini的默认配置）&lt;/li>
&lt;li>neural retrievers：DRAGON+、SPLADEv2、ColBERTv2（在MS MARCO上训练）&lt;/li>
&lt;/ul>
&lt;BR>
&lt;h3 id="42两种将上下文引入神经检索器的方法">4.2两种将上下文引入神经检索器的方法&lt;/h3>
&lt;h4 id="421加入bm25的混合检索">4.2.1加入BM25的混合检索&lt;/h4>
&lt;p>&lt;strong>（1）Rank fusion融合检索&lt;/strong>&lt;/p></description></item><item><title>从0开始建立Github个人博客(hugo&amp;PaperMod)</title><link>https://Rook1eChan.github.io/posts/%E4%BB%8E0%E5%BC%80%E5%A7%8B%E5%BB%BA%E7%AB%8Bgithub%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2hugopapermod/</link><pubDate>Fri, 02 May 2025 12:39:00 +0800</pubDate><guid>https://Rook1eChan.github.io/posts/%E4%BB%8E0%E5%BC%80%E5%A7%8B%E5%BB%BA%E7%AB%8Bgithub%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2hugopapermod/</guid><description>&lt;p>github提供给每个用户一个网址，用户可以建立自己的静态网站。&lt;/p>
&lt;h2 id="一hugo">一、Hugo&lt;/h2>
&lt;p>hugo是一个快速搭建网站的工具，由go语言编写。&lt;/p>
&lt;h3 id="1安装hugo">1.安装hugo&lt;/h3>
&lt;p>到hugo的github标签页&lt;a href="https://github.com/gohugoio/hugo/tags">Tags · gohugoio/hugo&lt;/a>选择一个版本，下载对应的安装包。比如&lt;code>hugo_extended_withdeploy_0.147.0_windows-amd64.zip&lt;/code>。&lt;/p>
&lt;p>解压后，在根目录打开cmd，输入&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-cmd" data-lang="cmd">&lt;span class="line">&lt;span class="cl">hugo new site YourSiteName
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>为你的网站建立文件夹。&lt;code>YourSiteName&lt;/code>更改为你的网站的名字。
根目录会出现YourSiteName文件夹。&lt;/p>
&lt;p>3.将根目录的hugo.exe复制到YourSiteName里。
在YourSiteName文件夹里打开cmd，输入&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-cmd" data-lang="cmd">&lt;span class="line">&lt;span class="cl">hugo server -D
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>会返回如下信息：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-cmd" data-lang="cmd">&lt;span class="line">&lt;span class="cl"> &lt;span class="p">|&lt;/span> EN
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">-------------------+-----
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Pages &lt;span class="p">|&lt;/span> 11
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Paginator pages &lt;span class="p">|&lt;/span> 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Non-page files &lt;span class="p">|&lt;/span> 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Static files &lt;span class="p">|&lt;/span> 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Processed images &lt;span class="p">|&lt;/span> 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Aliases &lt;span class="p">|&lt;/span> 2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Cleaned &lt;span class="p">|&lt;/span> 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Built in 79 ms
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Environment: &lt;span class="s2">&amp;#34;development&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Serving pages from disk
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Running in Fast Render Mode. For full rebuilds on change: hugo server --disableFastRender
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Web Server is available at http://localhost:1313/ (bind address 127.0.0.1)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Press Ctrl+C to stop
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>在浏览器中输入&lt;code>http://localhost:1313/&lt;/code>，显示Page Not Found，说明服务器正常运行，但是此时网站还没有页面。&lt;/p></description></item><item><title>Neural-IR Models（博客）</title><link>https://Rook1eChan.github.io/posts/neural-ir-models/</link><pubDate>Fri, 02 May 2025 01:18:03 +0800</pubDate><guid>https://Rook1eChan.github.io/posts/neural-ir-models/</guid><description>&lt;p>原文：&lt;a href="https://medium.com/@mhammadkhan/neural-re-ranking-models-c0a67278f626">Neural-IR Models.. Neural IR(Information Retrieval) is a… | by Muhammad Hammad Khan | Medium&lt;/a>&lt;/p>
&lt;p>译文：&lt;a href="https://zhuanlan.zhihu.com/p/545429612">【翻译】一文详解神经信息检索领域的最新进展 - 知乎&lt;/a>&lt;/p>
&lt;p>神经信息检索(Neural Information Retrieval, Neural IR)是信息检索领域的一个重要研究课题。自从谷歌在2018年发布BERT以来，它在11个NLP任务上获得了最先进的结果，一举改变了整个NLP领域的研究范式。2019年1月，Nogueira和Cho在MS MARCO Passage Ranking测试集上首次使用BERT。从那时起，人们开始研究神经信息检索的范式，也提出了许多基于BERT的文本排序方法。这些方法用于&lt;strong>多阶段搜索架构的重排阶段(Re-Ranker)&lt;/strong>。如下图所示。&lt;/p>
&lt;p>&lt;img alt="image" loading="lazy" src="https://Rook1eChan.github.io/Neural-IR-Models-1.jpg">&lt;/p>
&lt;p>Figure1 展示了一个简化的多阶段搜索结构。第一步：倒排索引（Inverted Index）+BM25得分进行排序，得到topK文档，这一步也叫候选项生成（Candidates Generation）。第二步，通过基于BERT的上下文排序模型来确定前N个文档的最终排序。&lt;/p>
&lt;p>神经重排模型(Neural re-ranking models)一般可以分为以下四种，如Figure2所示：&lt;/p>
&lt;ul>
&lt;li>基于表征(representation-focused)&lt;/li>
&lt;li>基于交互(interaction-focused)&lt;/li>
&lt;li>全交互（也被称作交叉编码器,）(all-to-all interaction(cross encoder) )&lt;/li>
&lt;li>迟交互(late interaction)&lt;/li>
&lt;/ul>
&lt;p>&lt;img alt="image" loading="lazy" src="https://Rook1eChan.github.io/Neural-IR-Models-2.jpg">&lt;/p>
&lt;h2 id="1基于表征双塔模型bi-encoder-models">1.基于表征——双塔模型(Bi-encoder Models)&lt;/h2>
&lt;p>双塔模型将Query和Doc分别表征为密集的向量嵌入，用向量相似度分数来估计Q和D的相关性。在训练时&lt;strong>需要正负样本进行对比学习&lt;/strong>，因为如果只给模型看正样本，它会偷懒——把所有向量都变成一样的，这样“相似度”永远最高。负样本强迫模型学会区分相关和不相关的内容。&lt;/p>
&lt;p>在将模型训练好后，doc和query的表征可以独立进行，不用像交叉编码器那样每次都要把Query和Doc拼在一起重新计算。&lt;/p>
&lt;h3 id="11密集段落检索器dense-passage-retriever-dpr">1.1密集段落检索器(Dense passage retriever, DPR)&lt;/h3>
&lt;blockquote>
&lt;p>论文：&lt;a href="https://aclanthology.org/2020.emnlp-main.550">Dense Passage Retrieval for Open-Domain Question Answering&lt;/a>
EMNLP 2020, Facebook Research
Code: &lt;a href="https://github.com/facebookresearch/DPR">github.com/facebookresearch/DPR&lt;/a>
讲解博客：&lt;a href="https://blog.csdn.net/qq_45668004/article/details/138256448">【IR 论文】DPR — 最早提出使用嵌入向量来检索文档的模型_dpr模型-CSDN博客&lt;/a>&lt;/p>&lt;/blockquote>
&lt;p>DPR是一个应用于问答领域的双塔模型，旨在最大限度地提高查询与相关文档的相似度，同时最小化与非相关文档的相似度。DPR是RAG中R的经典方案。&lt;/p>
&lt;p>正样本往往数据集已给定，而负样本比较难选择。为此，DPR提出了一种Batch内负采样的技术，从同一批次的其他样本中选择样本作为负样本。这种方法是有效且高效的。&lt;/p>
&lt;h3 id="12最近邻负对比估计-approximate-nearest-neighbour-negative-contrastive-estimation-ance">1.2最近邻负对比估计 (Approximate nearest neighbour Negative Contrastive Estimation, ANCE)&lt;/h3>
&lt;p>该论文证明了强负样本能够加速模型收敛，提升模型性能。负样本分为易区别的和不易区别的，显然不易区别（即强负样本）的对模型学习帮助更大。本文使用ANN寻找强负样本。&lt;/p></description></item></channel></rss>