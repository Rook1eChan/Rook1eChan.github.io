<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Posts on Chan's Blog</title><link>https://Rook1eChan.github.io/posts/</link><description>Recent content in Posts on Chan's Blog</description><generator>Hugo -- 0.147.1</generator><language>zh-CN</language><lastBuildDate>Mon, 05 May 2025 12:23:00 +0800</lastBuildDate><atom:link href="https://Rook1eChan.github.io/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>RAG 数据集及评价标准</title><link>https://Rook1eChan.github.io/posts/rag-datasetsevaluation/</link><pubDate>Sun, 04 May 2025 09:12:03 +0800</pubDate><guid>https://Rook1eChan.github.io/posts/rag-datasetsevaluation/</guid><description>&lt;h3 id="1lightrag">1.LightRAG&lt;/h3>
&lt;h4 id="数据集">数据集&lt;/h4>
&lt;p>使用&lt;a href="https://arxiv.org/abs/2409.05591">MemoRAG&lt;/a>提出的Benchmark。&lt;/p>
&lt;p>在UltraDomain里，包含多个领域的数据，每个数据包括多本书。以cs为例，共含有100本书和100个对应的问题。该领域专注于计算机科学，涵盖数据科学和软件工程的关键领域。它特别强调机器学习和大数据处理，内容涉及推荐系统、分类算法以及使用Spark进行实时分析。：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-gdscript3" data-lang="gdscript3">&lt;span class="line">&lt;span class="cl">&lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">input&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">How&lt;/span> &lt;span class="n">does&lt;/span> &lt;span class="n">Spark&lt;/span> &lt;span class="n">Streaming&lt;/span> &lt;span class="n">enable&lt;/span> &lt;span class="n">real&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="n">time&lt;/span> &lt;span class="n">data&lt;/span> &lt;span class="n">processing&lt;/span>&lt;span class="err">?&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">answers&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="s1">&amp;#39;Spark Streaming extends ...... &amp;#39;&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">context&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;Whole Book......&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">length&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="mi">131651&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">context_id&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="n">bcef8714a477fd61fc8fb0d499b2cc3&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">_id&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">b2fd8d9c6d1499d521d778ce3d6d06fa&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">label&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">cs&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">meta&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">{&lt;/span>&lt;span class="s1">&amp;#39;title&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;Machine Learning With Spark&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;authors&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;Nick Pentreath&amp;#39;&lt;/span>&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>数据集地址：&lt;a href="https://huggingface.co/datasets/TommyChien/UltraDomain">TommyChien/UltraDomain · Datasets at Hugging Face&lt;/a>&lt;/p>
&lt;h4 id="问题生成">问题生成&lt;/h4>
&lt;p>生成问题的方法来自于&lt;a href="https://arxiv.org/abs/2404.16130">From Local to Global: A Graph RAG Approach to Query-Focused Summarization&lt;/a>&lt;/p>
&lt;p>提供文本，让大模型生成K个使用该数据集的用户身份（比如数据集是财经新闻，user就可能是收集金融市场趋势的财经记者），对于每个用户再生成N个任务，每个用户-任务提出M个高层次问题（理解整个数据集、无需提取具体事实）&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> User: A tech journalist looking for insights and trends in the tech industry
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Task: Understanding how tech leaders view the role of policy and regulation
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Questions:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 1. Which episodes deal primarily with tech policy and government regulation?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 2. How do guests perceive the impact of privacy laws on technology development?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 3. Do any guests discuss the balance between innovation and ethical considerations?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 4. What are the suggested changes to current policies mentioned by the guests?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 5. Are collaborations between tech companies and governments discussed and how?
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="评价标准">评价标准&lt;/h4>
&lt;p>不使用黄金标准答案，使用LLM评价。包括&lt;/p></description></item><item><title>DAPR A Benchmark on Document-Aware Passage Retrieval</title><link>https://Rook1eChan.github.io/posts/dapr-a-benchmark-on-document-aware-passage-retrieval/</link><pubDate>Mon, 05 May 2025 12:23:00 +0800</pubDate><guid>https://Rook1eChan.github.io/posts/dapr-a-benchmark-on-document-aware-passage-retrieval/</guid><description>&lt;h2 id="0目标">0.目标&lt;/h2>
&lt;p>神经检索（neural retrieval）的工作主要集中在短文本排序，无法处理需要连接上下文的问题，在长篇文章中做检索效果并不好。&lt;/p>
&lt;p>比如：在A剧场中演出过的演员有哪些？如果只检索“A剧场”，可能找不到答案，需要结合上下文找到“……在这里演出过……”的内容才是真正答案。&lt;/p>
&lt;p>对SOTA检索器（DRAGON+,SPLADEv2, and ColBERTv2 and BM25）的错误进行了分析，发现一般的错误是由缺乏上下文导致的（相关段落非自包含），DAPR很有必要。&lt;/p>
&lt;h2 id="1贡献">1.贡献&lt;/h2>
&lt;ol>
&lt;li>提出DAPR（文章感知段落检索）&lt;/li>
&lt;li>构建了一个基准测试数据集（benchmark），包括了5个不同领域的数据集&lt;/li>
&lt;/ol>
&lt;h2 id="2相关工作">2.相关工作&lt;/h2>
&lt;ul>
&lt;li>DocQA：要求模型回答关于输入文档的问题。通常假设相关文档在提问前就已给出。&lt;/li>
&lt;li>Long-document retrieval（长文档检索）：
&lt;ul>
&lt;li>MaxP——将文档中段落相关性的最大值作为文档相关性；&lt;/li>
&lt;li>FirstP——仅编码文档中的第一个段落；&lt;/li>
&lt;li>等等；&lt;/li>
&lt;li>但此前的方法都未在检索的同时考虑上下文。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Hybrid retrieval（混合检索）：
&lt;ul>
&lt;li>rank fusion（排名融合）——通过凸组合、互逆排名等方法将不同检索系统的个体排名合并为一个。&lt;/li>
&lt;li>hierarchical retrieval（层次检索）——首先检索文档，然后从这些文档中检索段落。只适用于段落本身足以对查询做出响应的情况。&lt;/li>
&lt;li>本文探讨了段落排名和文档排名结合的有效性。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>和预训练任务的关系：
&lt;ul>
&lt;li>以前的方法只关注独立的句子/段落，而不注意上下文。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>补充：
&lt;ul>
&lt;li>NQ：谷歌的一个问答数据集&lt;/li>
&lt;li>NDCG：评价检索序列的相关性和位置&lt;/li>
&lt;li>共指信息：描述文本中不同表达式指向同一实体或概念的语言现象，如*“玛丽打开了门，&lt;strong>她&lt;/strong>随后拿起包。”* → “她”与“玛丽”共指同一人。&lt;/li>
&lt;li>共指消解（Coreference Resolution）：自动识别文本中所有指向同一实体的表达式并分组。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="3dapr任务">3.DAPR任务&lt;/h2>
&lt;h3 id="31错误的主要类型">3.1错误的主要类型&lt;/h3>
&lt;p>对SOTA的检索器使用NQ数据集，发现一半的错误来自于不了解上下文。将这些数据命名为&lt;strong>NQ-hard&lt;/strong>，并分为4类：&lt;/p>
&lt;ol>
&lt;li>共指消解（CR）：关键的共指信息需要通过特定文档上下文来解析；&lt;/li>
&lt;li>主要主题（MT）：只有了解文档的背景主题（通常是标题），才能回答查询；&lt;/li>
&lt;li>多跳推理（MHR）：连接查询和查询相关段落中的实体的推理路径包括文档上下文中的其他节点；&lt;/li>
&lt;li>缩写（AC）：在相关段落（或查询）中出现一个缩写，该缩写对应于查询（或相关段落）中的全称，文档上下文解释了这种映射；&lt;/li>
&lt;/ol>
&lt;h3 id="32本文用到的数据集">3.2本文用到的数据集&lt;/h3>
&lt;p>MS MARCO、Natural Questions、MIRACL、Genomics 和 ConditionalQA（具体处理方式见附录A）&lt;/p>
&lt;p>对于MS MARCO和Natural Questions，我们将原始开发集视为测试集，并保留了一组采样的训练示例作为我们的开发集。对于其他7个数据集，我们保留了它们的原始数据分割。对于除MS MARCO外的数据集，段落片段是可用的（共同构成段落集合C）；而对于MS MARCO，此类信息不存在，仅提供C中相关文档内的段落跨度。&lt;/p>
&lt;p>来自不同领域，经过预处理&lt;/p>
&lt;h3 id="33评估">3.3评估&lt;/h3>
&lt;p>使用&lt;strong>nDCG@10&lt;/strong>和recall@100，代码中使用pytrec_eval计算nDCG@10&lt;/p>
&lt;p>零样本评估：在MS MARCO训练部分训练，在MS测试部分测试，作为域内评估；在其它四个数据集上测试，作为域外评估。&lt;/p>
&lt;h2 id="4实验">4.实验&lt;/h2>
&lt;h3 id="41基础检测器">4.1基础检测器&lt;/h3>
&lt;ul>
&lt;li>BM25：PySerini（用于BM25的默认配置）&lt;/li>
&lt;li>neural retrievers：DRAGON+、SPLADEv2、ColBERTv2，并在MS MARCO上训练&lt;/li>
&lt;/ul>
&lt;h3 id="42两种将上下文引入神经检索器的方法">4.2两种将上下文引入神经检索器的方法&lt;/h3>
&lt;h4 id="421加入bm25的混合检索">4.2.1加入BM25的混合检索&lt;/h4>
&lt;p>（1）融合检索&lt;/p>
&lt;p>由于神经网络适合于检测512token内的段落，而BM25无限制，所以使用BM25检索整个文档，而使用神经检索器检索段落。&lt;/p></description></item><item><title>CDF-RAG: Causal Dynamic Feedback for Adaptive Retrieval-Augmented Generation</title><link>https://Rook1eChan.github.io/posts/cdf-rag-causal-dynamic-feedback-for-adaptive-retrieval-augmented-generation/</link><pubDate>Fri, 02 May 2025 23:17:00 +0800</pubDate><guid>https://Rook1eChan.github.io/posts/cdf-rag-causal-dynamic-feedback-for-adaptive-retrieval-augmented-generation/</guid><description>&lt;p>&lt;a href="https://arxiv.org/abs/2504.12560">CDF-RAG: Causal Dynamic Feedback for Adaptive Retrieval-Augmented Generation&lt;/a>&lt;/p>
&lt;p>只挂了arxiv，粗看，了解一下各模块的实现方式。&lt;/p>
&lt;h2 id="1motivation">1.Motivation&lt;/h2>
&lt;p>现有的RAG框架主要是静态检索，且依赖于语义相似性和关联性，这些方法优先考虑主题相关的文档，而并非提供解释或因果关系的文档。这导致响应结果是基于事实的，但是没能理解因果关系。&lt;/p>
&lt;p>此外，基于大规模观察语料库训练的语言模型倾向于建模共现模式而非因果依赖，这使得它们容易将相关性与因果关系混淆——尤其是在存在不完整或模糊证据的情况下。这些局限性在多跳检索中尤为明显。&lt;/p>
&lt;p>另外，用户的提问可能是模糊的，现有机制缺乏动态适应和因果机制。&lt;/p>
&lt;h2 id="2contributions">2.Contributions&lt;/h2>
&lt;p>本文提出了CDFRAG框架，将强化学习查询优化、多跳因果图检索和基于对齐的幻觉检测整合到一个推理循环中。&lt;/p>
&lt;p>证明了基于强化学习的查询重写显著提升了多跳因果推理和检索质量，优于先前的细化方法。&lt;/p>
&lt;p>本方法在四个数据集中均sota，在因果正确性、一致性和可解释性方面均有所改进。&lt;/p>
&lt;h2 id="3method">3.Method&lt;/h2>
&lt;h3 id="1构建因果知识图谱">1.构建因果知识图谱&lt;/h3>
&lt;p>使用UniCausal提取因果对（Causal，Effect）。经过GPT4验证后，编码为（C，E，Relation）并存入有向图G。&lt;/p>
&lt;h3 id="2根据强化学习进行查询重写">2.根据强化学习进行查询重写&lt;/h3>
&lt;p>给定用户初始查询q，重写q的过程是一个马尔可夫决策过程（MDP），有三种操作：&lt;/p>
&lt;ol>
&lt;li>扩展：添加相关的因果因素&lt;/li>
&lt;li>简化：去除多余的细节&lt;/li>
&lt;li>分解：复杂查询拆解为子查询&lt;/li>
&lt;/ol>
&lt;p>策略通过SFT微调生成，然后使用PPO优化。&lt;/p>
&lt;ol>
&lt;li>&lt;strong>监督微调（Supervised Fine-Tuning, SFT）&lt;/strong>&lt;/li>
&lt;/ol>
&lt;ul>
&lt;li>&lt;strong>目的&lt;/strong>：用标注的示范数据（如人工修正的样本）初始化策略 (\pi_\theta(a|s))，使其初步具备期望的行为模式。&lt;/li>
&lt;li>&lt;strong>方法&lt;/strong>：通过最大化对数似然来微调模型参数，损失函数为：
$L_{\text{SFT}} = -\sum_{t=1}^{T} \log P_\phi(y_t \mid y_{&amp;lt;t}, x)$
&lt;ul>
&lt;li>$y_t$ 是时间步 $t$ 的正确动作（或词元）。&lt;/li>
&lt;li>$y_{&amp;lt;t}$ 表示历史信息（之前的动作或上下文）。&lt;/li>
&lt;li>$x$ 是输入状态（如提示或环境状态）。&lt;/li>
&lt;li>核心是让模型输出的概率分布贴近人工标注的数据。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;ol start="2">
&lt;li>&lt;strong>近端策略优化（Proximal Policy Optimization, PPO）&lt;/strong>&lt;/li>
&lt;/ol>
&lt;ul>
&lt;li>&lt;strong>目的&lt;/strong>：在SFT的基础上，通过与环境交互进一步优化策略，平衡探索与利用，同时避免训练不稳定。&lt;/li>
&lt;li>&lt;strong>损失函数&lt;/strong>：
$L_{\text{PPO}}(\theta) = \mathbb{E}_t \left[ \min\left( \text{比率项} \cdot A_t, \text{截断后的比率项} \cdot A_t \right) \right]$
&lt;ul>
&lt;li>&lt;strong>比率项&lt;/strong>：新策略与旧策略的概率比&lt;/li>
&lt;li>$\frac{\pi_\theta(a|s)}{\pi_{\theta_{old}}(at|st)}$，衡量策略变化程度。&lt;/li>
&lt;li>&lt;strong>优势函数 $A_t$&lt;/strong>：评估动作 $a$ 在状态 $s$ 下比平均表现好多少（由评论家模型或蒙特卡洛估计）。&lt;/li>
&lt;li>&lt;strong>截断机制&lt;/strong>：限制比率项在 $[1-\epsilon, 1+\epsilon]$ 之间，防止单步更新过大，确保训练稳定。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="3语义因果双路径检索">3.语义+因果双路径检索&lt;/h3>
&lt;p>使用MiniLM对优化后的查询进行编码，在向量数据库进行相似性搜索。（整句话编码的稠密检索）&lt;/p></description></item><item><title>从0开始建立Github个人博客(hugo&amp;PaperMod)</title><link>https://Rook1eChan.github.io/posts/%E4%BB%8E0%E5%BC%80%E5%A7%8B%E5%BB%BA%E7%AB%8Bgithub%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2hugopapermod/</link><pubDate>Fri, 02 May 2025 12:39:00 +0800</pubDate><guid>https://Rook1eChan.github.io/posts/%E4%BB%8E0%E5%BC%80%E5%A7%8B%E5%BB%BA%E7%AB%8Bgithub%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2hugopapermod/</guid><description>&lt;p>github提供给每个用户一个网址，用户可以建立自己的静态网站。&lt;/p>
&lt;h2 id="一hugo">一、Hugo&lt;/h2>
&lt;p>hugo是一个快速搭建网站的工具，由go语言编写。&lt;/p>
&lt;h3 id="1安装hugo">1.安装hugo&lt;/h3>
&lt;p>到hugo的github标签页&lt;a href="https://github.com/gohugoio/hugo/tags">Tags · gohugoio/hugo&lt;/a>选择一个版本，下载对应的安装包。比如&lt;code>hugo_extended_withdeploy_0.147.0_windows-amd64.zip&lt;/code>。&lt;/p>
&lt;p>解压后，在根目录打开cmd，输入&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-cmd" data-lang="cmd">&lt;span class="line">&lt;span class="cl">hugo new site YourSiteName
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>为你的网站建立文件夹。&lt;code>YourSiteName&lt;/code>更改为你的网站的名字。
根目录会出现YourSiteName文件夹。&lt;/p>
&lt;p>3.将根目录的hugo.exe复制到YourSiteName里。
在YourSiteName文件夹里打开cmd，输入&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-cmd" data-lang="cmd">&lt;span class="line">&lt;span class="cl">hugo server -D
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>会返回如下信息：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-cmd" data-lang="cmd">&lt;span class="line">&lt;span class="cl"> &lt;span class="p">|&lt;/span> EN
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">-------------------+-----
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Pages &lt;span class="p">|&lt;/span> 11
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Paginator pages &lt;span class="p">|&lt;/span> 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Non-page files &lt;span class="p">|&lt;/span> 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Static files &lt;span class="p">|&lt;/span> 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Processed images &lt;span class="p">|&lt;/span> 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Aliases &lt;span class="p">|&lt;/span> 2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Cleaned &lt;span class="p">|&lt;/span> 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Built in 79 ms
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Environment: &lt;span class="s2">&amp;#34;development&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Serving pages from disk
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Running in Fast Render Mode. For full rebuilds on change: hugo server --disableFastRender
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Web Server is available at http://localhost:1313/ (bind address 127.0.0.1)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Press Ctrl+C to stop
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>在浏览器中输入&lt;code>http://localhost:1313/&lt;/code>，显示Page Not Found，说明服务器正常运行，但是此时网站还没有页面。&lt;/p></description></item><item><title>Neural-IR Models（博客）</title><link>https://Rook1eChan.github.io/posts/neural-ir-models/</link><pubDate>Fri, 02 May 2025 01:18:03 +0800</pubDate><guid>https://Rook1eChan.github.io/posts/neural-ir-models/</guid><description>&lt;p>原文：&lt;a href="https://medium.com/@mhammadkhan/neural-re-ranking-models-c0a67278f626">Neural-IR Models.. Neural IR(Information Retrieval) is a… | by Muhammad Hammad Khan | Medium&lt;/a>&lt;/p>
&lt;p>译文：&lt;a href="https://zhuanlan.zhihu.com/p/545429612">【翻译】一文详解神经信息检索领域的最新进展 - 知乎&lt;/a>&lt;/p>
&lt;p>神经信息检索(Neural Information Retrieval, Neural IR)是信息检索领域的一个重要研究课题。自从谷歌在2018年发布BERT以来，它在11个NLP任务上获得了最先进的结果，一举改变了整个NLP领域的研究范式。2019年1月，Nogueira和Cho在MS MARCO Passage Ranking测试集上首次使用BERT。从那时起，人们开始研究神经信息检索的范式，也提出了许多基于BERT的文本排序方法。这些方法用于&lt;strong>多阶段搜索架构的重排阶段(Re-Ranker)&lt;/strong>。如下图所示。&lt;/p>
&lt;p>&lt;img alt="image" loading="lazy" src="https://Rook1eChan.github.io/Neural-IR-Models-1.jpg">&lt;/p>
&lt;p>Figure1 展示了一个简化的多阶段搜索结构。第一步：倒排索引（Inverted Index）+BM25得分进行排序，得到topK文档，这一步也叫候选项生成（Candidates Generation）。第二步，通过基于BERT的上下文排序模型来确定前N个文档的最终排序。&lt;/p>
&lt;p>神经重排模型(Neural re-ranking models)一般可以分为以下四种，如Figure2所示：&lt;/p>
&lt;ul>
&lt;li>基于表征(representation-focused)&lt;/li>
&lt;li>基于交互(interaction-focused)&lt;/li>
&lt;li>全交互（也被称作交叉编码器,）(all-to-all interaction(cross encoder) )&lt;/li>
&lt;li>迟交互(late interaction)&lt;/li>
&lt;/ul>
&lt;p>&lt;img alt="image" loading="lazy" src="https://Rook1eChan.github.io/Neural-IR-Models-2.jpg">&lt;/p>
&lt;h2 id="1基于表征双塔模型bi-encoder-models">1.基于表征——双塔模型(Bi-encoder Models)&lt;/h2>
&lt;p>双塔模型将Query和Doc分别表征为密集的向量嵌入，用向量相似度分数来估计Q和D的相关性。在训练时&lt;strong>需要正负样本进行对比学习&lt;/strong>，因为如果只给模型看正样本，它会偷懒——把所有向量都变成一样的，这样“相似度”永远最高。负样本强迫模型学会区分相关和不相关的内容。&lt;/p>
&lt;p>在将模型训练好后，doc和query的表征可以独立进行，不用像交叉编码器那样每次都要把Query和Doc拼在一起重新计算。&lt;/p>
&lt;h3 id="11密集段落检索器dense-passage-retriever-dpr">1.1密集段落检索器(Dense passage retriever, DPR)&lt;/h3>
&lt;blockquote>
&lt;p>论文：&lt;a href="https://aclanthology.org/2020.emnlp-main.550">Dense Passage Retrieval for Open-Domain Question Answering&lt;/a>
EMNLP 2020, Facebook Research
Code: &lt;a href="https://github.com/facebookresearch/DPR">github.com/facebookresearch/DPR&lt;/a>
讲解博客：&lt;a href="https://blog.csdn.net/qq_45668004/article/details/138256448">【IR 论文】DPR — 最早提出使用嵌入向量来检索文档的模型_dpr模型-CSDN博客&lt;/a>&lt;/p>&lt;/blockquote>
&lt;p>DPR是一个应用于问答领域的双塔模型，旨在最大限度地提高查询与相关文档的相似度，同时最小化与非相关文档的相似度。DPR是RAG中R的经典方案。&lt;/p>
&lt;p>正样本往往数据集已给定，而负样本比较难选择。为此，DPR提出了一种Batch内负采样的技术，从同一批次的其他样本中选择样本作为负样本。这种方法是有效且高效的。&lt;/p>
&lt;h3 id="12最近邻负对比估计-approximate-nearest-neighbour-negative-contrastive-estimation-ance">1.2最近邻负对比估计 (Approximate nearest neighbour Negative Contrastive Estimation, ANCE)&lt;/h3>
&lt;p>该论文证明了强负样本能够加速模型收敛，提升模型性能。负样本分为易区别的和不易区别的，显然不易区别（即强负样本）的对模型学习帮助更大。本文使用ANN寻找强负样本。&lt;/p></description></item></channel></rss>