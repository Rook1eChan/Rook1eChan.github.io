<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Posts on Chan's Blog</title><link>https://Rook1eChan.github.io/posts/</link><description>Recent content in Posts on Chan's Blog</description><generator>Hugo -- 0.147.1</generator><language>zh-CN</language><lastBuildDate>Fri, 02 May 2025 23:17:00 +0800</lastBuildDate><atom:link href="https://Rook1eChan.github.io/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>CDF-RAG: Causal Dynamic Feedback for Adaptive Retrieval-Augmented Generation</title><link>https://Rook1eChan.github.io/posts/cdf-rag-causal-dynamic-feedback-for-adaptive-retrieval-augmented-generation/</link><pubDate>Fri, 02 May 2025 23:17:00 +0800</pubDate><guid>https://Rook1eChan.github.io/posts/cdf-rag-causal-dynamic-feedback-for-adaptive-retrieval-augmented-generation/</guid><description>&lt;p>&lt;a href="https://arxiv.org/abs/2504.12560">CDF-RAG: Causal Dynamic Feedback for Adaptive Retrieval-Augmented Generation&lt;/a>&lt;/p>
&lt;p>只挂了arxiv，粗看，了解一下各模块的实现方式。&lt;/p>
&lt;h2 id="1motivation">1.Motivation&lt;/h2>
&lt;p>现有的RAG框架主要是静态检索，且依赖于语义相似性和关联性，这些方法优先考虑主题相关的文档，而并非提供解释或因果关系的文档。这导致响应结果是基于事实的，但是没能理解因果关系。&lt;/p>
&lt;p>此外，基于大规模观察语料库训练的语言模型倾向于建模共现模式而非因果依赖，这使得它们容易将相关性与因果关系混淆——尤其是在存在不完整或模糊证据的情况下。这些局限性在多跳检索中尤为明显。&lt;/p>
&lt;p>另外，用户的提问可能是模糊的，现有机制缺乏动态适应和因果机制。&lt;/p>
&lt;h2 id="2contributions">2.Contributions&lt;/h2>
&lt;p>本文提出了CDFRAG框架，将强化学习查询优化、多跳因果图检索和基于对齐的幻觉检测整合到一个推理循环中。&lt;/p>
&lt;p>证明了基于强化学习的查询重写显著提升了多跳因果推理和检索质量，优于先前的细化方法。&lt;/p>
&lt;p>本方法在四个数据集中均sota，在因果正确性、一致性和可解释性方面均有所改进。&lt;/p>
&lt;h2 id="3method">3.Method&lt;/h2>
&lt;h3 id="1构建因果知识图谱">1.构建因果知识图谱&lt;/h3>
&lt;p>使用UniCausal提取因果对（Causal，Effect）。经过GPT4验证后，编码为（C，E，Relation）并存入有向图G。&lt;/p>
&lt;h3 id="2根据强化学习进行查询重写">2.根据强化学习进行查询重写&lt;/h3>
&lt;p>给定用户初始查询q，重写q的过程是一个马尔可夫决策过程（MDP），有三种操作：&lt;/p>
&lt;ol>
&lt;li>扩展：添加相关的因果因素&lt;/li>
&lt;li>简化：去除多余的细节&lt;/li>
&lt;li>分解：复杂查询拆解为子查询&lt;/li>
&lt;/ol>
&lt;p>策略通过SFT微调生成，然后使用PPO优化。&lt;/p>
&lt;ol>
&lt;li>&lt;strong>监督微调（Supervised Fine-Tuning, SFT）&lt;/strong>&lt;/li>
&lt;/ol>
&lt;ul>
&lt;li>&lt;strong>目的&lt;/strong>：用标注的示范数据（如人工修正的样本）初始化策略 (\pi_\theta(a|s))，使其初步具备期望的行为模式。&lt;/li>
&lt;li>&lt;strong>方法&lt;/strong>：通过最大化对数似然来微调模型参数，损失函数为：
$L_{\text{SFT}} = -\sum_{t=1}^{T} \log P_\phi(y_t \mid y_{&amp;lt;t}, x)$
&lt;ul>
&lt;li>$y_t$ 是时间步 $t$ 的正确动作（或词元）。&lt;/li>
&lt;li>$y_{&amp;lt;t}$ 表示历史信息（之前的动作或上下文）。&lt;/li>
&lt;li>$x$ 是输入状态（如提示或环境状态）。&lt;/li>
&lt;li>核心是让模型输出的概率分布贴近人工标注的数据。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;ol start="2">
&lt;li>&lt;strong>近端策略优化（Proximal Policy Optimization, PPO）&lt;/strong>&lt;/li>
&lt;/ol>
&lt;ul>
&lt;li>&lt;strong>目的&lt;/strong>：在SFT的基础上，通过与环境交互进一步优化策略，平衡探索与利用，同时避免训练不稳定。&lt;/li>
&lt;li>&lt;strong>损失函数&lt;/strong>：
$L_{\text{PPO}}(\theta) = \mathbb{E}_t \left[ \min\left( \text{比率项} \cdot A_t, \text{截断后的比率项} \cdot A_t \right) \right]$
&lt;ul>
&lt;li>&lt;strong>比率项&lt;/strong>：新策略与旧策略的概率比&lt;/li>
&lt;li>$\frac{\pi_\theta(a|s)}{\pi_{\theta_{old}}(at|st)}$，衡量策略变化程度。&lt;/li>
&lt;li>&lt;strong>优势函数 $A_t$&lt;/strong>：评估动作 $a$ 在状态 $s$ 下比平均表现好多少（由评论家模型或蒙特卡洛估计）。&lt;/li>
&lt;li>&lt;strong>截断机制&lt;/strong>：限制比率项在 $[1-\epsilon, 1+\epsilon]$ 之间，防止单步更新过大，确保训练稳定。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="3语义因果双路径检索">3.语义+因果双路径检索&lt;/h3>
&lt;p>使用MiniLM对优化后的查询进行编码，在向量数据库进行相似性搜索。（整句话编码的稠密检索）&lt;/p></description></item><item><title>从0开始建立Github个人博客(hugo&amp;PaperMod)</title><link>https://Rook1eChan.github.io/posts/%E4%BB%8E0%E5%BC%80%E5%A7%8B%E5%BB%BA%E7%AB%8Bgithub%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2hugopapermod/</link><pubDate>Fri, 02 May 2025 12:39:00 +0800</pubDate><guid>https://Rook1eChan.github.io/posts/%E4%BB%8E0%E5%BC%80%E5%A7%8B%E5%BB%BA%E7%AB%8Bgithub%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2hugopapermod/</guid><description>&lt;p>github提供给每个用户一个网址，用户可以建立自己的静态网站。&lt;/p>
&lt;h2 id="一hugo">一、Hugo&lt;/h2>
&lt;p>hugo是一个快速搭建网站的工具，由go语言编写。&lt;/p>
&lt;h3 id="1安装hugo">1.安装hugo&lt;/h3>
&lt;p>到hugo的github标签页&lt;a href="https://github.com/gohugoio/hugo/tags">Tags · gohugoio/hugo&lt;/a>选择一个版本，下载对应的安装包。比如&lt;code>hugo_extended_withdeploy_0.147.0_windows-amd64.zip&lt;/code>。&lt;/p>
&lt;p>解压后，在根目录打开cmd，输入&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-cmd" data-lang="cmd">&lt;span class="line">&lt;span class="cl">hugo new site YourSiteName
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>为你的网站建立文件夹。&lt;code>YourSiteName&lt;/code>更改为你的网站的名字。
根目录会出现YourSiteName文件夹。&lt;/p>
&lt;p>3.将根目录的hugo.exe复制到YourSiteName里。
在YourSiteName文件夹里打开cmd，输入&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-cmd" data-lang="cmd">&lt;span class="line">&lt;span class="cl">hugo server -D
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>会返回如下信息：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-cmd" data-lang="cmd">&lt;span class="line">&lt;span class="cl"> &lt;span class="p">|&lt;/span> EN
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">-------------------+-----
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Pages &lt;span class="p">|&lt;/span> 11
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Paginator pages &lt;span class="p">|&lt;/span> 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Non-page files &lt;span class="p">|&lt;/span> 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Static files &lt;span class="p">|&lt;/span> 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Processed images &lt;span class="p">|&lt;/span> 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Aliases &lt;span class="p">|&lt;/span> 2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Cleaned &lt;span class="p">|&lt;/span> 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Built in 79 ms
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Environment: &lt;span class="s2">&amp;#34;development&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Serving pages from disk
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Running in Fast Render Mode. For full rebuilds on change: hugo server --disableFastRender
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Web Server is available at http://localhost:1313/ (bind address 127.0.0.1)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Press Ctrl+C to stop
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>在浏览器中输入&lt;code>http://localhost:1313/&lt;/code>，显示Page Not Found，说明服务器正常运行，但是此时网站还没有页面。&lt;/p></description></item><item><title>Neural-IR Models（博客）</title><link>https://Rook1eChan.github.io/posts/neural-ir-models/</link><pubDate>Fri, 02 May 2025 01:18:03 +0800</pubDate><guid>https://Rook1eChan.github.io/posts/neural-ir-models/</guid><description>&lt;p>原文：&lt;a href="https://medium.com/@mhammadkhan/neural-re-ranking-models-c0a67278f626">Neural-IR Models.. Neural IR(Information Retrieval) is a… | by Muhammad Hammad Khan | Medium&lt;/a>&lt;/p>
&lt;p>译文：&lt;a href="https://zhuanlan.zhihu.com/p/545429612">【翻译】一文详解神经信息检索领域的最新进展 - 知乎&lt;/a>&lt;/p>
&lt;p>神经信息检索(Neural Information Retrieval, Neural IR)是信息检索领域的一个重要研究课题。自从谷歌在2018年发布BERT以来，它在11个NLP任务上获得了最先进的结果，一举改变了整个NLP领域的研究范式。2019年1月，Nogueira和Cho在MS MARCO Passage Ranking测试集上首次使用BERT。从那时起，人们开始研究神经信息检索的范式，也提出了许多基于BERT的文本排序方法。这些方法用于&lt;strong>多阶段搜索架构的重排阶段(Re-Ranker)&lt;/strong>。如下图所示。&lt;/p>
&lt;p>&lt;img alt="image" loading="lazy" src="https://Rook1eChan.github.io/Neural-IR-Models-1.jpg">&lt;/p>
&lt;p>Figure1 展示了一个简化的多阶段搜索结构。第一步：倒排索引（Inverted Index）+BM25得分进行排序，得到topK文档，这一步也叫候选项生成（Candidates Generation）。第二步，通过基于BERT的上下文排序模型来确定前N个文档的最终排序。&lt;/p>
&lt;p>神经重排模型(Neural re-ranking models)一般可以分为以下四种，如Figure2所示：&lt;/p>
&lt;ul>
&lt;li>基于表征(representation-focused)&lt;/li>
&lt;li>基于交互(interaction-focused)&lt;/li>
&lt;li>全交互（也被称作交叉编码器,）(all-to-all interaction(cross encoder) )&lt;/li>
&lt;li>迟交互(late interaction)&lt;/li>
&lt;/ul>
&lt;p>&lt;img alt="image" loading="lazy" src="https://Rook1eChan.github.io/Neural-IR-Models-2.jpg">&lt;/p>
&lt;h2 id="1基于表征双塔模型bi-encoder-models">1.基于表征——双塔模型(Bi-encoder Models)&lt;/h2>
&lt;p>双塔模型将Query和Doc分别表征为密集的向量嵌入，用向量相似度分数来估计Q和D的相关性。在训练时&lt;strong>需要正负样本进行对比学习&lt;/strong>，因为如果只给模型看正样本，它会偷懒——把所有向量都变成一样的，这样“相似度”永远最高。负样本强迫模型学会区分相关和不相关的内容。&lt;/p>
&lt;p>在将模型训练好后，doc和query的表征可以独立进行，不用像交叉编码器那样每次都要把Query和Doc拼在一起重新计算。&lt;/p>
&lt;h3 id="11密集段落检索器dense-passage-retriever-dpr">1.1密集段落检索器(Dense passage retriever, DPR)&lt;/h3>
&lt;blockquote>
&lt;p>论文：&lt;a href="https://aclanthology.org/2020.emnlp-main.550">Dense Passage Retrieval for Open-Domain Question Answering&lt;/a>
EMNLP 2020, Facebook Research
Code: &lt;a href="https://github.com/facebookresearch/DPR">github.com/facebookresearch/DPR&lt;/a>
讲解博客：&lt;a href="https://blog.csdn.net/qq_45668004/article/details/138256448">【IR 论文】DPR — 最早提出使用嵌入向量来检索文档的模型_dpr模型-CSDN博客&lt;/a>&lt;/p>&lt;/blockquote>
&lt;p>DPR是一个应用于问答领域的双塔模型，旨在最大限度地提高查询与相关文档的相似度，同时最小化与非相关文档的相似度。DPR是RAG中R的经典方案。&lt;/p>
&lt;p>正样本往往数据集已给定，而负样本比较难选择。为此，DPR提出了一种Batch内负采样的技术，从同一批次的其他样本中选择样本作为负样本。这种方法是有效且高效的。&lt;/p>
&lt;h3 id="12最近邻负对比估计-approximate-nearest-neighbour-negative-contrastive-estimation-ance">1.2最近邻负对比估计 (Approximate nearest neighbour Negative Contrastive Estimation, ANCE)&lt;/h3>
&lt;p>该论文证明了强负样本能够加速模型收敛，提升模型性能。负样本分为易区别的和不易区别的，显然不易区别（即强负样本）的对模型学习帮助更大。本文使用ANN寻找强负样本。&lt;/p></description></item></channel></rss>