<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Posts on Chan's Bolg</title><link>https://Rook1eChan.github.io/posts/</link><description>Recent content in Posts on Chan's Bolg</description><generator>Hugo -- 0.147.1</generator><language>zh-cn</language><lastBuildDate>Fri, 02 May 2025 12:39:00 +0800</lastBuildDate><atom:link href="https://Rook1eChan.github.io/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>从0开始建立Github个人博客(hugo&amp;PaperMod)</title><link>https://Rook1eChan.github.io/posts/%E4%BB%8E0%E5%BC%80%E5%A7%8B%E5%BB%BA%E7%AB%8Bgithub%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2hugopapermod/</link><pubDate>Fri, 02 May 2025 12:39:00 +0800</pubDate><guid>https://Rook1eChan.github.io/posts/%E4%BB%8E0%E5%BC%80%E5%A7%8B%E5%BB%BA%E7%AB%8Bgithub%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2hugopapermod/</guid><description>&lt;p>github提供给每个用户一个网址，用户可以建立自己的静态网站。&lt;/p>
&lt;h2 id="一hugo">一、Hugo&lt;/h2>
&lt;p>hugo是一个快速搭建网站的工具，由go语言编写。&lt;/p>
&lt;h3 id="1安装hugo">1.安装hugo&lt;/h3>
&lt;p>到hugo的github标签页&lt;a href="https://github.com/gohugoio/hugo/tags">Tags · gohugoio/hugo&lt;/a>选择一个版本，下载对应的安装包。比如&lt;code>hugo_extended_withdeploy_0.147.0_windows-amd64.zip&lt;/code>。&lt;/p>
&lt;p>解压后，在根目录打开cmd，输入&lt;/p>
&lt;pre tabindex="0">&lt;code>hugo new site YourSiteName
&lt;/code>&lt;/pre>&lt;p>为你的网站建立文件夹。&lt;code>YourSiteName&lt;/code>更改为你的网站的名字。
根目录会出现YourSiteName文件夹。&lt;/p>
&lt;p>3.将根目录的hugo.exe复制到YourSiteName里。
在YourSiteName文件夹里打开cmd，输入&lt;/p>
&lt;pre tabindex="0">&lt;code>hugo server -D
&lt;/code>&lt;/pre>&lt;p>会返回如下信息：&lt;/p>
&lt;pre tabindex="0">&lt;code> | EN
-------------------+-----
Pages | 11
Paginator pages | 0
Non-page files | 0
Static files | 0
Processed images | 0
Aliases | 2
Cleaned | 0
Built in 79 ms
Environment: &amp;#34;development&amp;#34;
Serving pages from disk
Running in Fast Render Mode. For full rebuilds on change: hugo server --disableFastRender
Web Server is available at http://localhost:1313/ (bind address 127.0.0.1)
Press Ctrl+C to stop
&lt;/code>&lt;/pre>&lt;p>在浏览器中输入&lt;code>http://localhost:1313/&lt;/code>，显示Page Not Found，说明服务器正常运行，但是此时网站还没有页面。&lt;/p></description></item><item><title>Neural-IR Models（博客）</title><link>https://Rook1eChan.github.io/posts/neural-ir-models/</link><pubDate>Fri, 02 May 2025 01:18:03 +0800</pubDate><guid>https://Rook1eChan.github.io/posts/neural-ir-models/</guid><description>&lt;p>原文：&lt;a href="https://medium.com/@mhammadkhan/neural-re-ranking-models-c0a67278f626">Neural-IR Models.. Neural IR(Information Retrieval) is a… | by Muhammad Hammad Khan | Medium&lt;/a>&lt;/p>
&lt;p>译文：&lt;a href="https://zhuanlan.zhihu.com/p/545429612">【翻译】一文详解神经信息检索领域的最新进展 - 知乎&lt;/a>&lt;/p>
&lt;p>神经信息检索(Neural Information Retrieval, Neural IR)是信息检索领域的一个重要研究课题。自从谷歌在2018年发布BERT以来，它在11个NLP任务上获得了最先进的结果，一举改变了整个NLP领域的研究范式。2019年1月，Nogueira和Cho在MS MARCO Passage Ranking测试集上首次使用BERT。从那时起，人们开始研究神经信息检索的范式，也提出了许多基于BERT的文本排序方法。这些方法用于&lt;strong>多阶段搜索架构的重排阶段(Re-Ranker)&lt;/strong>。如下图所示。&lt;/p>
&lt;p>&lt;img alt="image" loading="lazy" src="https://Rook1eChan.github.io/Neural-IR-Models-1.jpg">&lt;/p>
&lt;p>Figure1 展示了一个简化的多阶段搜索结构。第一步：倒排索引（Inverted Index）+BM25得分进行排序，得到topK文档，这一步也叫候选项生成（Candidates Generation）。第二步，通过基于BERT的上下文排序模型来确定前N个文档的最终排序。&lt;/p>
&lt;p>神经重排模型(Neural re-ranking models)一般可以分为以下四种，如Figure2所示：&lt;/p>
&lt;ul>
&lt;li>基于表征(representation-focused)&lt;/li>
&lt;li>基于交互(interaction-focused)&lt;/li>
&lt;li>全交互（也被称作交叉编码器,）(all-to-all interaction(cross encoder) )&lt;/li>
&lt;li>迟交互(late interaction)&lt;/li>
&lt;/ul>
&lt;p>&lt;img alt="image" loading="lazy" src="https://Rook1eChan.github.io/Neural-IR-Models-2.jpg">&lt;/p>
&lt;h2 id="1基于表征双塔模型bi-encoder-models">1.基于表征——双塔模型(Bi-encoder Models)&lt;/h2>
&lt;p>双塔模型将Query和Doc分别表征为密集的向量嵌入，用向量相似度分数来估计Q和D的相关性。在训练时&lt;strong>需要正负样本进行对比学习&lt;/strong>，因为如果只给模型看正样本，它会偷懒——把所有向量都变成一样的，这样“相似度”永远最高。负样本强迫模型学会区分相关和不相关的内容。&lt;/p>
&lt;p>在将模型训练好后，doc和query的表征可以独立进行，不用像交叉编码器那样每次都要把Query和Doc拼在一起重新计算。&lt;/p>
&lt;h3 id="11密集段落检索器dense-passage-retriever-dpr">1.1密集段落检索器(Dense passage retriever, DPR)&lt;/h3>
&lt;blockquote>
&lt;p>论文：&lt;a href="https://aclanthology.org/2020.emnlp-main.550">Dense Passage Retrieval for Open-Domain Question Answering&lt;/a>
EMNLP 2020, Facebook Research
Code: &lt;a href="https://github.com/facebookresearch/DPR">github.com/facebookresearch/DPR&lt;/a>
讲解博客：&lt;a href="https://blog.csdn.net/qq_45668004/article/details/138256448">【IR 论文】DPR — 最早提出使用嵌入向量来检索文档的模型_dpr模型-CSDN博客&lt;/a>&lt;/p>&lt;/blockquote>
&lt;p>DPR是一个应用于问答领域的双塔模型，旨在最大限度地提高查询与相关文档的相似度，同时最小化与非相关文档的相似度。DPR是RAG中R的经典方案。&lt;/p>
&lt;p>正样本往往数据集已给定，而负样本比较难选择。为此，DPR提出了一种Batch内负采样的技术，从同一批次的其他样本中选择样本作为负样本。这种方法是有效且高效的。&lt;/p>
&lt;h3 id="12最近邻负对比估计-approximate-nearest-neighbour-negative-contrastive-estimation-ance">1.2最近邻负对比估计 (Approximate nearest neighbour Negative Contrastive Estimation, ANCE)&lt;/h3>
&lt;p>该论文证明了强负样本能够加速模型收敛，提升模型性能。负样本分为易区别的和不易区别的，显然不易区别（即强负样本）的对模型学习帮助更大。本文使用ANN寻找强负样本。&lt;/p></description></item></channel></rss>